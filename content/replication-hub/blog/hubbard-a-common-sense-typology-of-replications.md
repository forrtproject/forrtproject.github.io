---
title: "HUBBARD: A Common-Sense Typology of Replications"
date: 2017-04-03
author: "The Replication Network"
tags:
  - "GUEST BLOGS"
  - "Open Science Collaboration"
  - "Raymond Hubbard"
  - "replications"
  - "Reproducibility crisis"
  - "Typology"
draft: false
type: blog
---

###### *[NOTE: This entry is based on the book “Corrupt Research: The Case for Reconceptualizing Empirical Management and Social Science” by Raymond Hubbard]*

###### Psychology’s “reproducibility crisis” (Open Science Collaboration, 2015) has drawn attention to the need for replication research. However, focusing on the reproducibility of findings, while clearly important, is a much too narrow interpretation of replication’s role in the scientific enterprise. This account outlines some additional roles.

###### Based on the two dimensions of (1) data sources and (2) research methods, the table below lists six different kinds of replications, each with its own part to play.

![Hubbard](/replication-network-blog/hubbard.webp)

###### (1)   *Checking of Analysis: Determining the Accuracy of Results*

###### Independent reexaminations of the original data, using the same methods of analysis. Are the results error-free?

###### (2)   *Reanalysis of Data: Determining Whether Results Hold Up Using Different Analytical Methods*

###### Independent reexaminations of the original data, using different methods of analysis. Are the results the “same”?

###### Using the above approaches, many “landmark” results—e.g., the Hawthorne effect, J.B. Watson’s conditioning of Little Albert, Sir Cyril Burt’s “twins” research, and Durkheim’s theory of suicide—have been found to be invalid.

###### I do not consider (1) and (2) to be authentic forms of replication. They clearly, however, play a vital role in protecting the integrity of the empirical literature.

###### (3)   *Exact Replications: Determining Whether Results are Reproducible*

###### An authentic form of replication, one which most people see as THE definition of replication. Here, we follow as closely as possible the same procedures used in the earlier study on a new sample drawn from the same population. This was the approach adopted by the Open Science Collaboration (2015) project.

###### (4)   *Conceptual Extensions: Determining Whether Results Hold Up When Constructs and Their Interrelationships are Measured/Analyzed Differently*

###### These differences lie in how theoretical constructs are measured, and how they interrelate with other constructs. Conceptual extensions address the issue of the *construct validity* of the entities involved. This can only be done by replications assessing a construct’s (a) Convergent, (b) Discriminant, and (c) Nomological validities.

###### Otherwise expressed, replication research is crucial to *theory development.* First, it is replication research which is essential to the initial measurement, and further refinement, of the theoretical constructs themselves. Second, it is replication research which is responsible for monitoring the linkages (theoretical consistency) between these constructs. Third, it is replication research which judges the adequacy of this system of constructs for explaining some of what we see in the world around us.

###### (5)   *Empirical Generalizations: Determining Whether Results Hold Up in New Domains*

###### Here the focus is on the external validity, or generalizability, of results when changes in persons, settings, treatments, outcomes, and time periods are made (Shadish, Cook, and Campbell, 2002). For example, Helmig, et al.’s (2012) successful replication using Swiss data of Jacobs and Glass’s (2002) U.S. study on media publicity and nonprofit organizations.

###### (6)   *Generalizations and Extensions: Determining Whether Results Hold Up in New Domains and With New Methods of Measurement and/or Analysis*

###### Typically, these do not constitute authentic replications. Many of them are mainstream studies dealing with theory testing. That is, the emphasis is on *theory* extension, and not on extensions to previous *empirical* findings (Hubbard and Lindsay, 2002, p. 399).

###### *Replication and Validity Generalization*

###### Replication research underlies the validity generalization process.

###### Exact Replications allow appraisal of the *internal* validity of a study. They also enable the establishment of facts and the causal theories underlying them.

###### Conceptual Replications extend the development of causal theory by examining the validity of hypothetical constructs and their interrelationships. Specifically, they make possible the evaluation of a construct’s *convergent, discriminant,* and *nomological* validity. What could be more important than this?

###### Empirical Generalizations permit investigations of whether the same (similar) findings hold up across (sub)populations so addressing the neglected topic of a study’s *external* validity.

###### It is for good reason that replication research is said to be at the heart of scientific progress.

###### *Raymond Hubbard is Thomas F. Sheehan Distinguished Professor of Marketing, Emeritus, at Drake University. Correspondence about this blog should be addressed to* [*drabbuhyar@aol.com*](mailto:drabbuhyar@aol.com)*.*

###### REFERENCES

###### Helmig, B., Spraul, K., & Tremp, K. (2012). Replication studies in nonprofit research: A generalization and extension of findings regarding the media publicity of nonprofit organizations. *Nonprofit and Voluntary Sector Quarterly,* 41, 360‑385.

###### Hubbard, R. (2016). *Corrupt Research: The Case for Reconceptualizing Empirical Management and Social Science.* (2016). Sage Publications: Thousand Oaks, CA.

###### Hubbard, R. & Lindsay, R.M. (2002). How the emphasis on “original” empirical marketing research impedes knowledge development. *Marketing Theory,* 2, 381‑402.

###### Jacobs, R.N. & Glass, D.J. (2002). Media publicity and the voluntary sector: The case of nonprofit organizations in New York City. *Voluntas: International Journal of Voluntary and Nonprofit Organizations,* 13, 235‑252.

###### Open Science Collaboration (2015). Estimating the reproducibility of psychological science. *Science,* 349, aac4716‑1‑8.

###### Shadish, W.R., Cook, T.D., & Campbell, D.T. (2002). *Experimental and quasi-experimental designs for generalized causal inference.* Houghton Mifflin: Boston, MA.

###### Tsang, E.W.K. & Kwan, K.-M. (1999). Replication and theory development in organizational science: A critical realist perspective. *Academy of Management Review,* 24, 759‑780.

### Share this:

* [Click to share on X (Opens in new window)
  X](https://replicationnetwork.com/2017/04/03/hubbard-a-common-sense-typology-of-replications/?share=twitter)
* [Click to share on Facebook (Opens in new window)
  Facebook](https://replicationnetwork.com/2017/04/03/hubbard-a-common-sense-typology-of-replications/?share=facebook)

Like Loading...