{
    "timestamp": "2020-05-24T12:00:43.880Z",
    "title": "A Unified Framework to Quantify the Credibility of Scientific Findings",
    "link_to_resource": "https://journals.sagepub.com/doi/10.1177/2515245918787489",
    "creators": [
        "Etienne P. LeBel",
        "Randy J. McCarthy",
        "Brian D. Earp",
        "Malte Elson and Wolf Vanpaemel"
    ],
    "material_type": [
        "Primary Source",
        "Reading",
        "Paper"
    ],
    "education_level": [
        "College / Upper Division (Undergraduates)"
    ],
    "abstract": "Societies invest in scientific studies to better understand the world and attempt to harness such improved understanding to address pressing societal problems. Published research, however, can be useful for theory or application only if it is credible. In science, a credible finding is one that has repeatedly survived risky falsification attempts. However, state-of-the-art meta-analytic approaches cannot determine the credibility of an effect because they do not account for the extent to which each included study has survived such attempted falsification. To overcome this problem, we outline a unified framework for estimating the credibility of published research by examining four fundamental falsifiability-related dimensions: (a) transparency of the methods and data, (b) reproducibility of the results when the same data-processing and analytic decisions are reapplied, (c) robustness of the results to different data-processing and analytic decisions, and (d) replicability of the effect. This framework includes a standardized workflow in which the degree to which a finding has survived scrutiny is quantified along these four facets of credibility. The framework is demonstrated by applying it to published replications in the psychology literature. Finally, we outline a Web implementation of the framework and conclude by encouraging the community of researchers to contribute to the development and crowdsourcing of this platform.",
    "language": [
        "English"
    ],
    "conditions_of_use": "I don't see any of these",
    "primary_user": [
        "Student"
    ],
    "subject_areas": [
        "Applied Science",
        "Social Science"
    ],
    "FORRT_clusters": [
        "Reproducibility and Replicability Knowledge",
        "Reproducible Analyses",
        "Preregistration",
        "Open Data and Materials",
        "Replication Research"
    ],
    "tags": [
        "Transparency",
        "Reproducibility Crisis and Credibility Revolution",
        "Open Science"
    ]
}