{
    "timestamp": "2020-05-28T13:32:15.023Z",
    "title": "Small telescopes Detectability and the evaluation of replication results. ",
    "link_to_resource": "https://doi.org/10.1177/0956797614567341",
    "creators": [
        "Uri Simonsohn"
    ],
    "material_type": [
        "Primary Source",
        "Reading",
        "Paper"
    ],
    "education_level": [
        "College / Upper Division (Undergraduates)"
    ],
    "abstract": "This article introduces a new approach for evaluating replication results. It combines effect-size estimation with hypothesis testing, assessing the extent to which the replication results are consistent with an effect size big enough to have been detectable in the original study. The approach is demonstrated by examining replications of three well-known findings. Its benefits include the following: (a) differentiating \u201cunsuccessful\u201d replication attempts (i.e., studies yielding p > .05) that are too noisy from those that actively indicate the effect is undetectably different from zero, (b) \u201cprotecting\u201d true findings from underpowered replications, and (c) arriving at intuitively compelling inferences in general and for the revisited replications in particular",
    "language": [
        "English"
    ],
    "conditions_of_use": "I don't see any of these",
    "primary_user": [
        "Student"
    ],
    "subject_areas": [
        "Applied Science",
        "Math & Statistics",
        "Social Science"
    ],
    "FORRT_clusters": [
        "Reproducibility and Replicability Knowledge",
        "Conceptual and Statistical Knowledge",
        "Reproducible Analyses",
        "Replication Research"
    ],
    "tags": [
        "Reproducibility Crisis and Credibility Revolution",
        "Open Science"
    ]
}