{
    "timestamp": "2020-05-24T12:04:53.667Z",
    "title": "Investigating Variation in Replicability: A \u201cMany Labs\u201d Replication Project",
    "link_to_resource": "https://psycnet.apa.org/fulltext/2014-20922-002.html",
    "creators": [
        "Klein et al."
    ],
    "material_type": [
        "Primary Source",
        "Reading",
        "Reading"
    ],
    "education_level": [
        "College / Upper Division (Undergraduates)"
    ],
    "abstract": "Although replication is a central tenet of science, direct replications are rare in psychology. This research tested variation in the replicability of 13 classic and contemporary effects across 36 independent samples totaling 6,344 participants. In the aggregate, 10 effects replicated consistently. One effect \u2013 imagined contact reducing prejudice \u2013 showed weak support for replicability. And two effects \u2013 flag priming influencing conservatism and currency priming influencing system justification \u2013 did not replicate. We compared whether the conditions such as lab versus online or US versus international sample predicted effect magnitudes. By and large they did not. The results of this small sample of effects suggest that replicability is more dependent on the effect itself than on the sample and setting used to investigate the effect.",
    "language": [
        "English"
    ],
    "conditions_of_use": "I don't see any of these",
    "primary_user": [
        "Student"
    ],
    "subject_areas": [
        "Applied Science",
        "Social Science"
    ],
    "FORRT_clusters": [
        "Reproducibility and Replicability Knowledge",
        "Reproducible Analyses",
        "Replication Research"
    ],
    "tags": [
        "Reproducibility Crisis and Credibility Revolution",
        "Open Science"
    ]
}