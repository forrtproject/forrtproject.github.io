{
    "timestamp": "2020-05-26T14:49:40.450Z",
    "title": "Publication bias in the social sciences: Unlocking the file drawer",
    "link_to_resource": "https://doi.org/10.1126/science.1255484",
    "creators": [
        "Annie Franco",
        "Neil Malhotra",
        "Gabor Simonovits"
    ],
    "material_type": [
        "Primary Source",
        "Reading",
        "Paper"
    ],
    "education_level": [
        "College / Upper Division (Undergraduates)"
    ],
    "abstract": "We studied publication bias in the social sciences by analyzing a known population of conducted studies\u2014221 in total\u2014in which there is a full accounting of what is published and unpublished. We leveraged Time-sharing Experiments in the Social Sciences (TESS), a National Science Foundation\u2013sponsored program in which researchers propose survey-based experiments to be run on representative samples of American adults. Because TESS proposals undergo rigorous peer review, the studies in the sample all exceed a substantial quality threshold. Strong results are 40 percentage points more likely to be published than are null results and 60 percentage points more likely to be written up. We provide direct evidence of publication bias and identify the stage of research production at which publication bias occurs: Authors do not write up and submit null findings",
    "language": [
        "English"
    ],
    "conditions_of_use": "I don't see any of these",
    "primary_user": [
        "Student"
    ],
    "subject_areas": [
        "Applied Science",
        "Social Science"
    ],
    "FORRT_clusters": [
        "Reproducibility and Replicability Knowledge",
        "Reproducible Analyses",
        "Replication Research"
    ],
    "tags": [
        "Reproducibility Crisis and Credibility Revolution",
        "Open Science"
    ]
}