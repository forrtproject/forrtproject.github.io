{
    "timestamp": "01/01/2020",
    "title": "Research practices and statistical reporting quality in 250 economic psychology master's theses: a meta-research investigation",
    "link_to_resource": "https://royalsocietypublishing.org/doi/10.1098/rsos.190738",
    "creators": [
        "Erich Kirchler",
        "Jerome Olsen",
        "Johanna Mosen",
        "Martin Voracek"
    ],
    "material_type": [
        "Reading"
    ],
    "education_level": [
        "Graduate / Professional"
    ],
    "abstract": "The replicability of research findings has recently been disputed across multiple scientific disciplines. In constructive reaction, the research culture in psychology is facing fundamental changes, but investigations of research practices that led to these improvements have almost exclusively focused on academic researchers. By contrast, we investigated the statistical reporting quality and selected indicators of questionable research practices (QRPs) in psychology students' master's theses. In a total of 250 theses, we investigated utilization and magnitude of standardized effect sizes, along with statistical power, the consistency and completeness of reported results, and possible indications of p-hacking and further testing. Effect sizes were reported for 36% of focal tests (median r = 0.19), and only a single formal power analysis was reported for sample size determination (median observed power 1 \u2212 \u03b2 = 0.67). Statcheck revealed inconsistent p-values in 18% of cases, while 2% led to decision errors. There were no clear indications of p-hacking or further testing. We discuss our findings in the light of promoting open science standards in teaching and student supervision.",
    "language": [
        "English"
    ],
    "conditions_of_use": "cc-by",
    "primary_user": [
        "student",
        "teacher"
    ],
    "subject_areas": [
        "Psychology"
    ],
    "FORRT_clusters": [
        ""
    ],
    "tags": [
        "Reproducibility"
    ]
}