{
    "timestamp": "2020-06-08T18:07:14.930Z",
    "title": "Logical and methodological issues affecting genetic studies of humans reported in top neuroscience journals. ",
    "link_to_resource": "https://doi.org/10.1162/jocn_a_01192",
    "creators": [
        "Grabitz",
        "C.R. et al."
    ],
    "material_type": [
        "Primary Source",
        "Reading",
        "Paper"
    ],
    "education_level": [
        "College / Upper Division (Undergraduates)"
    ],
    "abstract": "Genetics and neuroscience are two areas of science that pose particular methodological problems because they involve detecting weak signals (i.e., small effects) in noisy data. In recent years, increasing numbers of studies have attempted to bridge these disciplines by looking for genetic factors associated with individual differences in behavior, cognition, and brain structure or function. However, different methodological approaches to guarding against false positives have evolved in the two disciplines. To explore methodological issues affecting neurogenetic studies, we conducted an in-depth analysis of 30 consecutive articles in 12 top neuroscience journals that reported on genetic associations in nonclinical human samples. It was often difficult to estimate effect sizes in neuroimaging paradigms. Where effect sizes could be calculated, the studies reporting the largest effect sizes tended to have two features: (i) they had the smallest samples and were generally underpowered to detect genetic effects, and (ii) they did not fully correct for multiple comparisons. Furthermore, only a minority of studies used statistical methods for multiple comparisons that took into account correlations between phenotypes or genotypes, and only nine studies included a replication sample or explicitly set out to replicate a prior finding. Finally, presentation of methodological information was not standardized and was often distributed across Methods sections and Supplementary Material, making it challenging to assemble basic information from many studies. Space limits imposed by journals could mean that highly complex statistical methods were described in only a superficial fashion. In summary, methods that have become standard in the genetics literature\u2014stringent statistical standards, use of large samples, and replication of findings\u2014are not always adopted when behavioral, cognitive, or neuroimaging phenotypes are used, leading to an increased risk of false-positive findings. Studies need to correct not just for the number of phenotypes collected but also for the number of genotypes examined, genetic models tested, and subsamples investigated. The field would benefit from more widespread use of methods that take into account correlations between the factors corrected for, such as spectral decomposition, or permutation approaches. Replication should become standard practice; this, together with the need for larger sample sizes, will entail greater emphasis on collaboration between research groups. We conclude with some specific suggestions for standardized reporting in this area.",
    "language": [
        "English"
    ],
    "conditions_of_use": "I don't see any of these",
    "primary_user": [
        "Student"
    ],
    "subject_areas": [
        "Life Science",
        "Math & Statistics",
        "Social Science"
    ],
    "FORRT_clusters": [
        "Reproducibility and Replicability Knowledge",
        "Conceptual and Statistical Knowledge",
        "Replication Research"
    ],
    "tags": [
        "Reproducibility Crisis and Credibility Revolution",
        "Open Science"
    ]
}