{
    "timestamp": "2020-06-04T19:27:40.678Z",
    "title": "Detecting and avoiding likely false-positive findings: A practical guide",
    "link_to_resource": "https://doi.org/10.1111/brv.12315",
    "creators": [
        "Wolfgang Forstmeier",
        "Eric-Jan Wagenmakers and Timothy H. Parker"
    ],
    "material_type": [
        "Primary Source",
        "Reading",
        "Paper"
    ],
    "education_level": [
        "College / Upper Division (Undergraduates)"
    ],
    "abstract": "Recently there has been a growing concern that many published research \ufb01ndings do not hold up in attempts to replicate them. We argue that this problem may originate from a culture of \u2018you can publish if you found a signi\ufb01cant effect\u2019. This culture creates a systematic bias against the null hypothesis which renders meta-analyses questionable and may even lead to a situation where hypotheses become dif\ufb01cult to falsify. In order to pinpoint the sources of errorand possible solutions, we review current scienti\ufb01c practices with regard to their effect on the probability of drawing a false-positive conclusion. We explain why the proportion of published false-positive \ufb01ndings is expected to increase with(i) decreasing sample size, (ii) increasing pursuit of novelty, (iii) various forms of multiple testing and researcher \ufb02exibility,and (iv) incorrect P-values, especially due to unaccounted pseudoreplication, i.e. the non-independence of data points(clustered data). We provide examples showing how statistical pitfalls and psychological traps lead to conclusions that are biased and unreliable, and we show how these mistakes can be avoided. Ultimately, we hope to contribute to a culture of \u2018you can publish if your study is rigorous\u2019. To this end, we highlight promising strategies towards making science more objective. Speci\ufb01cally, we enthusiastically encourage scientists to preregister their studies (including a priori hypotheses and complete analysis plans), to blind observers to treatment groups during data collection and analysis,and unconditionally to report all results. Also, we advocate reallocating some efforts away from seeking novelty and discovery and towards replicating important research \ufb01ndings of one\u2019s own and of others for the bene\ufb01t of the scienti\ufb01c community as a whole. We believe these efforts will be aided by a shift in evaluation criteria away from the current system which values metrics of \u2018impact\u2019 almost exclusively and towards a system which explicitly values indices of scienti\ufb01c rigour",
    "language": [
        "English"
    ],
    "conditions_of_use": "I don't see any of these",
    "primary_user": [
        "Student"
    ],
    "subject_areas": [
        "Life Science"
    ],
    "FORRT_clusters": [
        "Reproducibility and Replicability Knowledge",
        "Replication Research"
    ],
    "tags": [
        "Reproducibility Crisis and Credibility Revolution",
        "Open Science"
    ]
}