{
    "timestamp": "6/24/2024 16:05:13",
    "title": "Establishing trust in automated reasoning",
    "link_to_resource": "https://doi.org/10.31222/osf.io/nt96q",
    "creators": [
        "Konrad Hinsen"
    ],
    "material_type": [
        "Reading"
    ],
    "education_level": [
        "College / Upper Division (Undergraduates)"
    ],
    "abstract": "Since its beginnings in the 1940s, automated reasoning by computers has become a tool of ever growing importance in scientific research.So far, the rules underlying automated reasoning have mainly beenformulated by humans, in the form of program source code. Rulesderived from large amounts of data, via machine learning techniques,are a complementary approach currently under intense development.The question of why we should trust these systems, and the resultsobtained with their help, has been discussed by philosophers of sciencebut has so far received little attention by practitioners. The presentwork focuses on independent reviewing, an important source of trustin science, and identifies the characteristics of automated reasoningsystems that affect their reviewability. It also discusses possible stepstowards increasing reviewability and trustworthiness via a combinationof technical and social measure",
    "language": [
        "English"
    ],
    "conditions_of_use": "Public Domain",
    "primary_user": [
        "Student",
        "Teacher",
        "Researcher"
    ],
    "subject_areas": [
        "Social Science"
    ],
    "FORRT_clusters": [
        "Reproducibility and Replicability Knowledge",
        "Reproducible Analyses"
    ],
    "tags": [
        "computational science",
        "machine learning",
        "reliability",
        "reviewability",
        "software"
    ]
}