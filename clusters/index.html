<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.8.0"><meta name=description content><link rel=alternate hreflang=en-us href=https://forrt.org/clusters/><meta name=theme-color content="#004055"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Century Schoolbook:400,700%7CCentury Schoolbook:400,400italic,700%7CCentury Schoolbook&display=swap" type=text/css><link rel=stylesheet href=/css/academic.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-2BTFVS6SPM"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2BTFVS6SPM")</script><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_hu157d5c18119aadbeae18d128d49811b3_36734_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/images/icon_hu157d5c18119aadbeae18d128d49811b3_36734_192x192_fill_lanczos_center_3.png><link rel=canonical href=https://forrt.org/clusters/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@FORRTproject"><meta property="twitter:creator" content="@FORRTproject"><meta property="og:site_name" content="FORRT - Framework for Open and Reproducible Research Training"><meta property="og:url" content="https://forrt.org/clusters/"><meta property="og:title" content><meta property="og:description" content><meta property="og:image" content="https://forrt.org/img/FORRT_banner.svg"><meta property="twitter:image" content="https://forrt.org/img/FORRT_banner.svg"><meta property="og:locale" content="en-us"><meta property="article:modified_time" content="2020-09-20T23:49:04-04:00"><script src=https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin=anonymous><script>window.addEventListener("load",function(){window.cookieconsent.initialise({palette:{popup:{background:"#004055",text:"#fefdf6"},button:{background:"#fefdf6",text:"#004055"}},theme:"classic",content:{message:"This website uses cookies to ensure you get the best experience on our website.",dismiss:"Got it!",link:"Learn more",href:"https://www.cookiesandyou.com"}})})</script><title>| FORRT - Framework for Open and Reproducible Research Training</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main><script>const isSiteThemeDark=!1</script><script src=/js/load-theme.js></script><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><label for=search-query class=sr-only>Search: </label><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/images/logo.svg alt="FORRT - Framework for Open and Reproducible Research Training Logo. Link to homepage"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/images/logo.svg alt="FORRT - Framework for Open and Reproducible Research Training"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-center" id=navbar-content><ul class="navbar-nav d-md-inline-flex font-weight-bold text-uppercase"><li class="nav-item dropdown px-2"><a href=# class="nav-link dropdown-toggle" data-hover=dropdown aria-haspopup=true><span>About FORRT</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/about/us><span>About FORRT</span></a>
<a class=dropdown-item href=/awards><span>Awards</span></a>
<a class=dropdown-item href=/about/get-involved/#calendar><span>Calendar</span></a>
<a class=dropdown-item href=/coc><span>Code of Conduct</span></a>
<a class=dropdown-item href=/about/community><span>Community</span></a>
<a class=dropdown-item href=/contributors><span>Contributors</span></a>
<a class=dropdown-item href=/cv><span>Curriculum Vitae</span></a>
<a class=dropdown-item href=/feedback><span>Feedback</span></a>
<a class=dropdown-item href=/about/get-involved><span>Get Involved</span></a>
<a class=dropdown-item href=/about/mission/><span>Mission & Advocacy</span></a>
<a class=dropdown-item href=/newsletters><span>Newsletters</span></a>
<a class=dropdown-item href=/about/partnerships/><span>Partners</span></a>
<a class=dropdown-item href=/about/principles/><span>Principles</span></a>
<a class=dropdown-item href=/talk/><span>Talks</span></a>
<a class=dropdown-item href=/about/teams/><span>Teams</span></a></div></li><li class="nav-item dropdown px-2"><a href=# class="nav-link dropdown-toggle" data-hover=dropdown aria-haspopup=true><span>Educational NEXUS</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/nexus><span>About Educational Nexus</span></a>
<a class=dropdown-item href=/adopting><span>Adopting Principled Education</span></a>
<a class=dropdown-item href=/clusters><span>Clusters</span></a>
<a class=dropdown-item href=/resources><span>Curated Resources</span></a>
<a class=dropdown-item href=/os-developing-world><span>Developing Countries & OS</span></a>
<a class=dropdown-item href=/educators-corner><span>Educators' Corner</span></a>
<a class=dropdown-item href=/equityinos><span>Equity in Open Science</span></a>
<a class=dropdown-item href=/glossary><span>Glossary</span></a>
<a class=dropdown-item href=/impact><span>Impact of OS on students</span></a>
<a class=dropdown-item href=/lesson-plans><span>Lesson Plans</span></a>
<a class=dropdown-item href=/neurodiversity><span>Neurodiversity Team</span></a>
<a class=dropdown-item href=/pedagogies><span>Pedagogies</span></a>
<a class=dropdown-item href=/self-assessment><span>Self-Assessment</span></a>
<a class=dropdown-item href=/dei><span>Social Justice Initiatives</span></a>
<a class=dropdown-item href=/summaries><span>Summaries</span></a>
<a class=dropdown-item href=/syllabus><span>Syllabi</span></a>
<a class=dropdown-item href=/awop><span>Wheel of Privilege</span></a></div></li><li class="nav-item dropdown px-2"><a href=# class="nav-link dropdown-toggle" data-hover=dropdown aria-haspopup=true><span>Replication Hub</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/replication-hub><span>About Replication Hub</span></a>
<a class=dropdown-item href=https://forrt-replications.shinyapps.io/fred_explorer/><span>FReD Explorer</span></a>
<a class=dropdown-item href=https://forrt-replications.shinyapps.io/fred_annotator/><span>FReD Annotator</span></a>
<a class=dropdown-item href=/reversals><span>Replications & Reversals</span></a>
<a class=dropdown-item href=/positive-changes-replication-crisis><span>Positive Changes from the Replication Crisis</span></a></div></li><li class="nav-item px-2"><a class=nav-link href=/publications/><span>Publications</span></a></li><li class=nav-item><a href=/about/get-involved/ class="nav-link btn btn-primary nav-btn">üöÄ&nbsp;Get&nbsp;involved!</a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# alt="Opens search bar"><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/forrtproject/forrt alt="Link to FORRT's GitHub repository"><i class="fab fa-github" aria-hidden=true></i></a></li></ul></div></nav><span class="js-widget-page d-none"></span><section id=1-hero class="home-section wg-hero-welcome"><div class=container><div class=row><div class="col-lg-5 col-md-6 order-md-1 text-left text-lg-right mr-auto"><h1 class="hero-title d-inline-block float-lg-left" style="font-family:New Century Schoolbook;line-height:1.25">Framework for<br>Open and<br>Reproducible<br>Research<br>Training</h1></div><div class="my-auto mx-auto col-lg-7 col-md-6 order-md-2 hero-media border-left border-dark"><img width=100% src=/img/FORRT.svg alt="Logo of FORRT is a fort."></div></div></div></section><section id=intro-clusters class="home-section wg-blank" style="padding:60px 0;font-size:1.25rem"><div class=container><div class=row><div class="col-lg-12 text-center"></div></div><div class=row><div class=col-lg-12><h1 id=forrts-clusters>FORRT&rsquo;s Clusters</h1><br><p>In order to teach open and reproducible science effectively, educators need to make sense of almost a decade of literature, across several fields, and be informed about ongoing (and often dynamic) debates. This is a tall ask for most educators. So FORRT sought to develop strategies and propose solutions to mitigate the effects of competing academic interests and help scholars implement open and reproducible science tenets in their teaching and mentoring workflow. In an effort to reduce some of the burden on educators wishing to learn or teach these concepts, FORRT has draw on the expertise of more than 50 experts from its community to provide educators with a comprehensive but straightforward accessible didactic framework. FORRT clusters is a result of a comprehensive literature review guided by <em><strong>educational, pedagogical and didactic considerations</strong></em> aiming at providing a pathway towards the incremental adoption of Open and Reproducible Science tenets into educators/scholars teaching and mentoring. The focus lies not on simply aggregating the literature into bins, but on making sense of existing works, weaving connections where none exist, and providing a sensible learning-oriented Open and Reproducible Science taxonomy. FORRT taxonomy is composed of 7 clusters:</p><ol><li>Reproducibility and replicability knowledge</li><li>Conceptual and statistical knowledge</li><li>Reproducible analyses</li><li>Preregistration</li><li>FAIR data and materials</li><li>Replication research</li><li>Academic life and culture</li></ol><p>We further breakdown each cluster into sub-categories to provide educators/scholars with useful information on the extant of open science scholarship, and how they are connected to one another. The idea behind specifying clusters and sub-clusters it to highlight we have drawn fuzzy boundaries between clusters while allowing for diversification and heterogeneity in how each educator integrates these cluster/sub-clusters with their respective field content. The breakdown of each cluster into sub-categories provides scholars with useful information on the extant of open science scholarship, and how they are connected to one another. To have a look at the sub-clusters within each cluster, please click on the clusters above.</p><p>See below for each cluster, its description, sub-clusters, and associated works geared for teaching. And here&rsquo;s an attempt to visualize FORRT&rsquo;s clusters:</p><br><p><img alt="FORRT&rsquo;s Clusters" src=FORRT_Clusters.png title="FORRT's Clusters"></p><br><h2 id=Syllabus>FORRT&rsquo;s Syllabus</h2><p>Building on the clusters we created a <em><strong>&ldquo;Open and Reproducible Science&rdquo; Syllabus</strong></em>. We hope it can serve as starting point for your class.
<a href=FORRT_O&amp;R_101_Syllabus.pdf>.pdf download</a> or
<a href=https://docs.google.com/document/d/1pfFro5MbwBHzzXTeM_lE1gjFuq7AnnKWSDWkVwOBAtE/edit# target=_blank rel=noopener>editable G-doc version</a>. Check out the
<a href=/syllabus/>FORRT&rsquo;s syllabus page</a>.</p><br></div></div></div></div></section><section id=cluster1 class="home-section wg-blank" style="background-color:#cacfdc;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 1: Reproducibility Crisis and Credibility Revolution</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of foundational knowledge on the emergence of, and importance of, reproducible and open research (i.e., grounding the motivations and theoretical underpinnings of Open and Reproducible Science). Integration with field specific content (i.e., grounded in the history of replicability). There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>History of the reproducibility crisis & credibility revolution.</li><li>Exploratory and confirmatory analyses.</li><li>Questionable research practices and their prevalence.</li><li>Proposed improvement science initiatives on statistics, measurement, teaching, data sharing, code sharing, pre-registration, replication.</li><li>Ongoing debates (e.g., incentives for and against open science).</li><li>Ethical considerations for improved practices.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C1S1-tab data-toggle=tab href=#C1S1 role=tab aria-controls=C1S1 aria-selected=true>History</a></li><li class=nav-item><a class=nav-link id=C1S2-tab data-toggle=tab href=#C1S2 role=tab aria-controls=C1S2 aria-selected=false>Analyses</a></li><li class=nav-item><a class=nav-link id=C1S3-tab data-toggle=tab href=#C1S3 role=tab aria-controls=C1S3 aria-selected=false>QRPs</a></li><li class=nav-item><a class=nav-link id=C1S4-tab data-toggle=tab href=#C1S4 role=tab aria-controls=C1S4 aria-selected=false>Improvements</a></li><li class=nav-item><a class=nav-link id=C1S5-tab data-toggle=tab href=#C1S5 role=tab aria-controls=C1S5 aria-selected=false>Ongoing debates</a></li><li class=nav-item><a class=nav-link id=C1S6-tab data-toggle=tab href=#C1S6 role=tab aria-controls=C1S6 aria-selected=false>Ethics</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C1S1 role=tabpanel aria-labelledby=C1S1-tab><br><h2 id=history-of-the-reproducibility-crisis--credibility-revolution>History of the reproducibility crisis & credibility revolution</h2><ul><li><p>Baker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature News, 533(7604), 452. doi:
<a href=https://doi.org/10.1038/533452a target=_blank rel=noopener>https://doi.org/10.1038/533452a</a></p></li><li><p>Baker, M. (2016). Is there a reproducibility crisis? Nature, 533(7604), 3‚Äì5. doi:
<a href=https://doi.org/10.1038/d41586-019-00067-3 target=_blank rel=noopener>https://doi.org/10.1038/d41586-019-00067-3</a></p></li><li><p>Chambers, C. (2017). The seven deadly sins of psychology: A manifesto for reforming the culture of scientific practice. Princeton University Press.
<a href=http://dx.doi.org/10.1515/9781400884940 target=_blank rel=noopener>http://dx.doi.org/10.1515/9781400884940</a></p></li><li><p>Cr√ºwell, S., van Doorn, J., Etz, A., Makel, M. C., Moshontz, H., Niebaum, J., ‚Ä¶ SchulteMecklenbeck, M. (2018, November 16). 7 easy steps to open science: An annotated reading list.
<a href=https://doi.org/10.31234/osf.io/cfzyx target=_blank rel=noopener>https://doi.org/10.31234/osf.io/cfzyx</a></p></li><li><p>Edwards, M. A., & Roy, S. (2016). Academic research in the 21st century: Maintaining scientific integrity in a climate of perverse incentives and hypercompetition. Environmental Engineering Science, 34(1), 51-61. DOI:
<a href=https://doi.org/10.1089/ees.2016.0223 target=_blank rel=noopener>https://doi.org/10.1089/ees.2016.0223</a></p></li><li><p>Merton, R., K. (1968). The Matthew effect in science. Science, 159(3810), 56-63.
10.1126/science.159.3810.56</p></li><li><p>Merton, R., K. (1988). The Matthew Effect in Science, II: Cumulative Advantage and the Symbolism of Intellectual Property. ISIS, 79(4), 606-623. 10.1086/354848</p></li><li><p>Munafo, M. R., et al. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 0021. DOI: 10.0138/s41562-016-0021</p></li><li><p>Vazire, S. (2018). Implications of the Credibility Revolution for Productivity, Creativity, and Progress. Perspectives on Psychological Science, 13(4), 411-417.
<a href=https://doi.org/10.1177/1745691617751884 target=_blank rel=noopener>https://doi.org/10.1177/1745691617751884</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S2 role=tabpanel aria-labelledby=C1S2-tab><br><h2 id=exploratory-and-confirmatory-analyses>Exploratory and confirmatory analyses</h2><p><em><strong>Confirmatory analyses refer to tests of hypotheses that are formulated prior to data collection. Exploratory analyses refer to everything else.</strong></em></p><ul><li><p>Chambers, C. (2017). The seven deadly sins of psychology: A manifesto for reforming the culture of scientific practice. Princeton University Press.
<a href=http://dx.doi.org/10.1515/9781400884940 target=_blank rel=noopener>http://dx.doi.org/10.1515/9781400884940</a></p></li><li><p>Lin, W., & Green, D. P. (2016). Standard operating procedures: A safety net for pre-analysis plans. PS: Political Science & Politics, 49(3), 495-500.</p></li><li><p>Wagenmakers, E.-J., Wetzels, R., Borsboom, D., van der Mass, H. L. J., & Kievit, R. A. (2012). An agenda for purely confirmatory research. Perspectives on Psychological Science, 7(6), 632‚Äì638. doi:10.1177/1745691612463078</p></li><li><p>Wagenmakers‚Äâ, E.-J., Dutilh, G., & Sarafoglou, A. (2018). The Creativity-Verification Cycle in Psychological Science: New Methods to Combat Old Idols. Perspectives on Psychological Science, 13(4), 418‚Äì427.
<a href=https://doi.org/10.1177/1745691618771357 target=_blank rel=noopener>https://doi.org/10.1177/1745691618771357</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S3 role=tabpanel aria-labelledby=C1S3-tab><br><h2 id=questionable-research-practices-and-their-prevalence>Questionable research practices and their prevalence</h2><p><em><strong>The ways in which researchers engage in behaviors and decision-making that increase the probability of their (consciously or unconsciously) desired result.</strong></em></p><ul><li><p>Gelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ‚Äúfishing expedition‚Äù or ‚Äúp-hacking‚Äù and the research hypothesis was posited ahead of time. Unpublished manuscript.
<a href=http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf target=_blank rel=noopener>http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf</a></p></li><li><p>John, L. K., Loewenstein, G., & Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth telling. Psychological Science, 23(5), 524-532.
<a href=https://doi.org/10.1177/0956797611430953 target=_blank rel=noopener>https://doi.org/10.1177/0956797611430953</a></p></li><li><p>Simmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359‚Äì1366.https://doi.org/10.1177/0956797611417632</p></li><li><p>Smaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.https://doi.org/10.1098/rsos.160384</p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R. C., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in psychology, 7.</p></li></ul><br></div><div class="tab-pane fade" id=C1S4 role=tabpanel aria-labelledby=C1S4-tab><br><h2 id=proposed-improvement-science-initiatives-on-statistics-measurement-teaching-data-sharing-code-sharing-pre-registration-replication>Proposed improvement science initiatives on statistics, measurement, teaching, data sharing, code sharing, pre-registration, replication</h2><p><em><strong>Published checklists and other resources that can be used to shift behavior more toward improved practices.</strong></em></p><ul><li><p>Cr√ºwell, S., van Doorn, J., Etz, A., Makel, M. C., Moshontz, H., Niebaum, J., ‚Ä¶ SchulteMecklenbeck, M. (2018, November 16). 7 easy steps to open science: An annotated reading list.
<a href=https://doi.org/10.31234/osf.io/cfzyx target=_blank rel=noopener>https://doi.org/10.31234/osf.io/cfzyx</a></p></li><li><p>Lindsay (2020) Seven steps toward transparency and replicability in psychological science. Canadian Psychology/Psychologie canadienne.</p></li><li><p>Ioannidis, J. P., Munafo, M. R., Fusar-Poli, P., Nosek, B. A., & David, S. P. (2014). Publication and other reporting biases in cognitive sciences: detection, prevalence, and prevention. Trends in cognitive sciences, 18(5), 235-241.</p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., ‚Ä¶ Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443‚Äì490.
<a href=https://doi.org/10.1177/2515245918810225 target=_blank rel=noopener>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Munafo, M. R., et al. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 0021. DOI: 10.0138/s41562-016-0021</p></li><li><p>Peng, R. (2015). The reproducibility crisis in science: A statistical counterattack. Significance, 12(3).
<a href=https://doi.org/10.1111/j.1740-9713.2015.00827.x target=_blank rel=noopener>https://doi.org/10.1111/j.1740-9713.2015.00827.x</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S5 role=tabpanel aria-labelledby=C1S5-tab><br><h2 id=ongoing-debates-eg-incentives-for-and-against-open-science>Ongoing debates (e.g., incentives for and against open science)</h2><ul><li><p>Bahlai et al. (2019). Open science isn&rsquo;t always open to all scientists. American Scientist, 107(2), 78. DOI:
<a href=https://doi.org/10.1511/2019.107.2.78 target=_blank rel=noopener>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Chen, X., Dallmeier-Tiessen, S., Dasler, R., Feger, S., Fokianos, P., Gonzalez, J. B., &mldr; & Rodriguez, D. R. et al. (2019). Open is not enough. Nature : Physics, 15 (2), 113-119.
<a href=https://doi.org/10.1038/s41567-018-0342-2 target=_blank rel=noopener>https://doi.org/10.1038/s41567-018-0342-2</a></p></li><li><p>Drummond, C. (2018).; Reproducible research: a minority opinion. Journal of Experimental & Theoretical Artificial Intelligence, 30(1), 1-11.
<a href=https://doi.org/10.1080/0952813X.2017.1413140 target=_blank rel=noopener>https://doi.org/10.1080/0952813X.2017.1413140</a></p></li><li><p>Fanelli, D. (2018). Opinion: Is science really facing a reproducibility crisis, and do we need it to? Proceedings of the National Academy of Sciences, 115(11), 2628-2631.
<a href=https://doi.org/10.1073/pnas.1708272114 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1708272114</a></p></li><li><p>Fanelli, D., & Ioannidis, J. P. (2013). US studies may overestimate effect sizes in softer research. Proceedings of the National Academy of Sciences, 110(37), 15031-15036.
<a href=https://doi.org/10.1073/pnas.1302997110 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1302997110</a></p></li><li><p>Fell, M. J. (2019). The economic impacts of open science: A rapid evidence assessment. Publications, 7(3), 46.
<a href=https://doi.org/10.3390/publications7030046 target=_blank rel=noopener>https://doi.org/10.3390/publications7030046</a></p></li><li><p>Pashler, H., & Harris, C. R. (2012). Is the replicability crisis overblown? Three arguments examined. Perspectives on Psychological Science, 7, 531‚Äë536.
<a href=https://doi.org/10.1177/1745691612463401 target=_blank rel=noopener>https://doi.org/10.1177/1745691612463401</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S6 role=tabpanel aria-labelledby=C1S6-tab><br><h2 id=ethical-considerations-for-improved-practices>Ethical considerations for improved practices</h2><ul><li><p>Brabeck, M. M. (2021). Open science and feminist ethics: Promises and challenges of open access. Psychology of Women Quarterly, 45(4), 457-474.
<a href=https://doi.org/10.1177/03616843211030926 target=_blank rel=noopener>https://doi.org/10.1177/03616843211030926</a></p></li><li><p>Bol, T., de Vaan, M., & van de Rijt, A. (2018). The Matthew effect in science funding. Proceedings of the National Academy of Sciences, 115(19), 4887-4890.
<a href=https://doi.org/10.1073/pnas.1719557115 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1719557115</a></p></li><li><p>Chopik, W. J., Bremner, R. H., Defever, A. M., & Keller, V. N. (2018). How (and whether) to teach undergraduates about the replication crisis in psychological science. Teaching of Psychology, 45(2), 158‚Äì163.
<a href=https://doi.org/10.1177/0098628318762900 target=_blank rel=noopener>https://doi.org/10.1177/0098628318762900</a></p></li><li><p>Edwards, M. A., & Roy, S. (2016). Academic research in the 21st century: Maintaining scientific integrity in a climate of perverse incentives and hypercompetition. Environmental Engineering Science, 34(1), 51-61. DOI:
<a href=https://doi.org/10.1089/ees.2016.0223 target=_blank rel=noopener>https://doi.org/10.1089/ees.2016.0223</a></p></li><li><p>Fell, M. J. (2019). The economic impacts of open science: A rapid evidence assessment. Publications, 7(3), 46.
<a href=https://doi.org/10.3390/publications7030046 target=_blank rel=noopener>https://doi.org/10.3390/publications7030046</a></p></li><li><p>Jones, NL. (2007). A code of ethics for the life sciences. Science and Engineering Ethics, 13, 25-43. DOI:https://doi.org/ 0.1007/s11948-006-0007-x</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster2 class="home-section wg-blank" style="background-color:#eadce6;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 2: Conceptual and Statistical Knowledge</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in fundamental statistics, measurement, and its implications encompassing conceptual knowledge, application, interpretation and communication of statistical analyses. There are 5 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>The logic of null hypothesis testing, p-values, Type I and II errors (and when and why they might happen).</li><li>Limitations and benefits of NHST, Bayesian and Likelihood approaches.</li><li>Effect sizes, Statistical power, Confidence Intervals.</li><li>Research Design, Sample Methods, and its implications for inferences.</li><li>Questionable measurement practices (QMPs), validity and reliability issues.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C2S1-tab data-toggle=tab href=#C2S1 role=tab aria-controls=C2S1 aria-selected=true>NHST</a></li><li class=nav-item><a class=nav-link id=C2S2-tab data-toggle=tab href=#C2S2 role=tab aria-controls=C2S2 aria-selected=false>Approaches</a></li><li class=nav-item><a class=nav-link id=C2S3-tab data-toggle=tab href=#C2S3 role=tab aria-controls=C2S3 aria-selected=false>Effect-sizes & cia</a></li><li class=nav-item><a class=nav-link id=C2S4-tab data-toggle=tab href=#C2S4 role=tab aria-controls=C2S4 aria-selected=false>Research Design</a></li><li class=nav-item><a class=nav-link id=C2S5-tab data-toggle=tab href=#C2S5 role=tab aria-controls=C2S5 aria-selected=false>QMPs</a></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C2S1 role=tabpanel aria-labelledby=C2S1-tab><br><h2 id=the-logic-of-null-hypothesis-testing-p-values-type-i-and-ii-errors-and-when-and-why-they-might-happen>The logic of null hypothesis testing, p-values, Type I and II errors (and when and why they might happen).</h2><ul><li><p>Banerjee, A., Chitnis, UB., Jadhav, SL., Bhawalkar, JS., Chaudhury, S. (2009). Hypothesis testing, type I and type II errors. Industrial Psychiatry Journal, 18(2), 127-131.
<a href=https://doi.org/10.1111/j.1740-9713.2015.00827.x target=_blank rel=noopener>https://doi.org/10.1111/j.1740-9713.2015.00827.x</a></p></li><li><p>Gelman, A., & Carlin, J. (2014). Beyond power calculations: Assessing Type S (sign) and Type M (magnitude) errors. Perspectives on Psychological Science, 9(6), 641-651. doi: 10.1177/1745691614551642</p></li><li><p>Lakens, D. Improving your statistical inferences. Online course.
<a href=https://www.coursera.org/learn/statistical-inferences target=_blank rel=noopener>https://www.coursera.org/learn/statistical-inferences</a></p></li></ul><br></div><div class="tab-pane fade" id=C2S2 role=tabpanel aria-labelledby=C2S2-tab><br><h2 id=limitations-and-benefits-of-nhst-bayesian-and-likelihood-approaches>Limitations and benefits of NHST, Bayesian and Likelihood approaches.</h2><ul><li><p>Cumming, G. (2014). The new statistics: Why and how. Psychological Science, 25(1), 7-29.
<a href=https://doi.org/10.1177/0956797613504966 target=_blank rel=noopener>https://doi.org/10.1177/0956797613504966</a></p></li><li><p>Etz, A., Gronau, Q.F., Dablander, F. et al. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin Review, 25, 219‚Äì234.
<a href=https://doi.org/10.3758/s13423-017-1317-5 target=_blank rel=noopener>https://doi.org/10.3758/s13423-017-1317-5</a></p></li><li><p>Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, p values, confidence intervals, and power: Aa guide to misinterpretations. European Journal of Epidemiology, 31(4), 337‚Äì50.
<a href=http://doi.org/10.1007/s10654-016-0149-3 target=_blank rel=noopener>http://doi.org/10.1007/s10654-016-0149-3</a></p></li><li><p>Nuzzo, R. (2014). Statistical errors: P values, the ‚Äògold standard‚Äô of statistical validity, are not as reliable as many scientists assume. Nature, 506(7487), 150-152. doi:10.1038/506150a</p></li><li><p>Wagenmakers‚Äâ, E.-J., Dutilh, G., & Sarafoglou, A. (2018). The Creativity-Verification Cycle in Psychological Science: New Methods to Combat Old Idols. Perspectives on Psychological Science, 13(4), 418‚Äì427.
<a href=https://doi.org/10.1177/1745691618771357 target=_blank rel=noopener>https://doi.org/10.1177/1745691618771357</a></p></li></ul><br></div><div class="tab-pane fade" id=C2S3 role=tabpanel aria-labelledby=C2S3-tab><br><h2 id=effect-sizes-statistical-power-confidence-intervals>Effect sizes, Statistical power, Confidence Intervals.</h2><ul><li><p>Brysbaert, M. and Stevens, M. (2018). Power analysis and effect size in mixed effects models: A Tutorial. Journal of Cognition, 1(1): 9, pp. 1‚Äì20, DOI:
<a href=https://doi.org/10.5334/joc.10 target=_blank rel=noopener>https://doi.org/10.5334/joc.10</a></p></li><li><p>Button, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munaf√≤, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365-376.
<a href=https://doi.org/10.1038/nrn3475 target=_blank rel=noopener>https://doi.org/10.1038/nrn3475</a></p></li><li><p>Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, p values, confidence intervals, and power: A guide to misinterpretations. European Journal of Epidemiology, 31(4), 337‚Äì50.
<a href=http://doi.org/10.1007/s10654-016-0149-3 target=_blank rel=noopener>http://doi.org/10.1007/s10654-016-0149-3</a></p></li><li><p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs. Frontiers in Psychology, 4, 863. 10.3389/fpsyg.2013.00863</p></li><li><p>Pek, J., & Flora, D. B. (2018). Reporting effect sizes in original psychological research: A discussion and tutorial. Psychological Methods, 23(2), 208-225.
<a href=http://doi.org/10.1037/met0000126 target=_blank rel=noopener>http://doi.org/10.1037/met0000126</a></p></li><li><p>Perugini, M., Gallucci, M., & Costantini, G. (2014). Safeguard power as a protection against imprecise power estimates. Perspectives on Psychological Science, 9, 319-332.</p></li></ul><br></div><div class="tab-pane fade" id=C2S4 role=tabpanel aria-labelledby=C2S4-tab><br><h2 id=research-design-sample-methods-and-its-implications-for-inferences>Research Design, Sample Methods, and its implications for inferences.</h2><ul><li><p>Gervais et al. (2015). A powerful nudge? Presenting calculable consequences of underpowered research shifts incentives towards adequately powered designs. Social Psychological and Personality Science, 6, 847-854.
<a href=https://doi.org/10.1177/1948550615584199 target=_blank rel=noopener>https://doi.org/10.1177/1948550615584199</a></p></li><li><p>Perugini, M., Gallucci, M., & Costantini, G. (2014). Safeguard power as a protection against imprecise power estimates. Perspectives on Psychological Science, 9, 319-332.</p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.doi: 10.3389/fpsyg.2016.01832</p></li></ul><br></div><div class="tab-pane fade" id=C2S5 role=tabpanel aria-labelledby=C2S5-tab><br><h2 id=questionable-measurement-practices-qmps-validity-and-reliability-issues>Questionable measurement practices (QMPs), validity and reliability issues.</h2><ul><li><p>Flake, J. K., & Fried, E. I. (2019, January 17). Measurement schmeasurement: Questionable measurement practices and how to avoid them.
<a href=https://doi.org/10.31234/osf.io/hs7wm target=_blank rel=noopener>https://doi.org/10.31234/osf.io/hs7wm</a></p></li><li><p>Flake, J. K., Pek, J., & Hehman, E. (2017). Construct validation in social and personality research: Current practice and recommendations. Social Psychological and Personality Science, 8(4), 370‚Äì378.
<a href=https://doi.org/10.1177/1948550617693063 target=_blank rel=noopener>https://doi.org/10.1177/1948550617693063</a></p></li><li><p>Hussey, I., & Hughes, S. (2018, November 19). Hidden invalidity among fifteen commonly used measures in social and personality psychology.
<a href=https://doi.org/10.31234/osf.io/7rbfp target=_blank rel=noopener>https://doi.org/10.31234/osf.io/7rbfp</a></p></li><li><p>Rodebaugh, T. L., Scullin, R. B., Langer, J. K., Dixon, D. J., Huppert, J. D., Bernstein, A., . . . Lenze, E. J. (2016). Unreliability as a threat to understanding psychopathology: The cautionary tale of attentional bias. Journal of Abnormal Psychology, 125(6), 840-851.
<a href=http://dx.doi.org/10.1037/abn0000184 target=_blank rel=noopener>http://dx.doi.org/10.1037/abn0000184</a></p></li></ul><br></div></div></div></div></div></div></section><section id=cluster3 class="home-section wg-blank" style="background-color:#dad5dd;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 3: Reproducible analyses</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of the <em>how-to</em> basics of reproducible reports and analyses. It requires students to move towards transparent and scripted analysis practices. There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Strengths of reproducible pipelines.</li><li>Scripted analyses compared with GUI.</li><li>Data wrangling.</li><li>Programming reproducible data analyses.</li><li>Open source and free software.</li><li>Tools to check yourself and others.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C3S1-tab data-toggle=tab href=#C3S1 role=tab aria-controls=C3S1 aria-selected=true>Reproducible pipelines</a></li><li class=nav-item><a class=nav-link id=C3S2-tab data-toggle=tab href=#C3S2 role=tab aria-controls=C3S2 aria-selected=false>Scripted Analyses</a></li><li class=nav-item><a class=nav-link id=C3S3-tab data-toggle=tab href=#C3S3 role=tab aria-controls=C3S3 aria-selected=false>Data wrangling</a></li><li class=nav-item><a class=nav-link id=C3S4-tab data-toggle=tab href=#C3S4 role=tab aria-controls=C3S4 aria-selected=false>Reproducible Analyses</a></li><li class=nav-item><a class=nav-link id=C3S5-tab data-toggle=tab href=#C3S5 role=tab aria-controls=C3S5 aria-selected=false>Open source</a></li><li class=nav-item><a class=nav-link id=C3S6-tab data-toggle=tab href=#C3S6 role=tab aria-controls=C3S6 aria-selected=false>Tools</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C3S1 role=tabpanel aria-labelledby=C3S1-tab><br><h2 id=strengths-of-reproducible-pipelines>Strengths of reproducible pipelines.</h2><p><em><strong>Automating data analysis to make the process easier</strong></em></p><ul><li><p>Gandrud, C. (2016). Reproducible research with R and R Sstudio. New York; CRC Press</p></li><li><p>Wilson G, Bryan J, Cranston K, Kitzes J, Nederbragt L, et al. (2017) Good enough practices in scientific computing. PLOS Computational Biology 13(6): e1005510.
<a href=https://doi.org/10.1371/journal.pcbi.1005510 target=_blank rel=noopener>https://doi.org/10.1371/journal.pcbi.1005510</a></p></li><li><p><a href=https://datacarpentry.org/rr-workshop/ target=_blank rel=noopener>Reproducible Research in R Workshop Overview</a></p></li><li><p><a href=https://github.com/MonashDataFluency target=_blank rel=noopener>Monash&rsquo;s</a> Data Fluency
<a href=https://monashdatafluency.github.io/r-rep-res/index.html target=_blank rel=noopener>Reproducible Research in R (RRR)</a></p></li><li><p><a href=https://www.projecttier.org target=_blank rel=noopener>ProjectTier</a></p></li></ul><br></div><div class="tab-pane fade" id=C3S2 role=tabpanel aria-labelledby=C3S2-tab><br><h2 id=scripted-analyses-compared-with-gui>Scripted analyses compared with GUI.</h2><p><em><strong>Writing analyses in programming language compared to performing them with a point-and-click menu.</strong></em></p><ul><li>Gandrud, C. (2016). Reproducible research with R and R Sstudio. New York; CRC Press</li></ul><br></div><div class="tab-pane fade" id=C3S3 role=tabpanel aria-labelledby=C3S3-tab><br><h2 id=data-wrangling>Data wrangling</h2><p><em><strong>Processing and restructuring data so that it is more useful for analyse.</strong></em></p><p>Nick Fox&rsquo;s
<a href="https://www.youtube.com/playlist?list=PLmvNihjFsoM5hpQdqoI7onL4oXDSQ0ym8" target=_blank rel=noopener>Writing Reproducible Scientific Papers in R</a></p><p>PsuTeachR&rsquo;s
<a href=https://psyteachr.github.io/msc-data-skills/ target=_blank rel=noopener>Data Skills for Reproducible Science</a></p><br></div><div class="tab-pane fade" id=C3S4 role=tabpanel aria-labelledby=C3S4-tab><br><h2 id=programming-reproducible-data-analyses>Programming reproducible data analyses</h2><p><em><strong>Making sure anyone can reproduce analyses through things like well-commented scripts, writing codebooks, etc.</strong></em></p><ul><li><p>Gandrud, C. (2016). Reproducible research with R and R Sstudio. New York; CRC Press</p></li><li><p>Wilson, G., Bryan, J., Cranston, K., Kitzes, J., Nederbragt, L., & Teal, T. K. (2017). Good enough practices in scientific computing. PLoS computational biology, 13(6). e1005510.
<a href=https://doi.org/10.1371/journal.pcbi.1005510 target=_blank rel=noopener>https://doi.org/10.1371/journal.pcbi.1005510</a></p></li><li><p><a href=https://sites.trinity.edu/osl/ target=_blank rel=noopener>Open Stats Lab</a></p></li><li><p><a href=https://software-carpentry.org/ target=_blank rel=noopener>Software Carpentry</a></p></li><li><p><a href=https://learningstatisticswithr.com/book/ target=_blank rel=noopener>Learning statistics with R: A tutorial for psychology students and other beginners</a></p></li></ul><br></div><div class="tab-pane fade" id=C3S5 role=tabpanel aria-labelledby=C3S5-tab><br><h2 id=open-source-and-free-software>Open source and free software.</h2><ul><li>Chao, L. (2009). Utilizing open source tools for online teaching and learning Information Science. Hershey, PA: Information Science Reference.</li></ul><br></div><div class="tab-pane fade" id=C3S6 role=tabpanel aria-labelledby=C3S6-tab><br><h2 id=tools-to-check-yourself-and-others>Tools to check yourself and others</h2><p><em><strong>Includes tools such as statcheck.io, GRIM, and SPRITE</strong></em></p><ul><li><p>Brown, N. J., & Heathers, J. A. (2016). The GRIM test: A simple technique detects numerous anomalies in the reporting of results in psychology. Social Psychological and Personality Science, 1948550616673876.
<a href=http://journals.sagepub.com/doi/pdf/10.1177/1948550616673876 target=_blank rel=noopener>http://journals.sagepub.com/doi/pdf/10.1177/1948550616673876</a></p></li><li><p>Nuijten, M. B., Van Assen, M. A. L. M., Hartgerink, C. H. J., Epskamp, S., & Wicherts, J. M. (2017). The validity of the tool ‚Äústatcheck‚Äù in discovering statistical reporting inconsistencies. Preprint retrieved from
<a href=https://psyarxiv.com/tcxaj/ target=_blank rel=noopener>https://psyarxiv.com/tcxaj/</a>.</p></li><li><p>van der Zee, T., Anaya, J., & Brown, N. J. (2017). Statistical heartburn: An attempt to digest four pizza publications from the Cornell Food and Brand Lab. BMC Nutrition, 3(1), 54. DOI 10.1186/s40795-017-0167-x</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster4 class="home-section wg-blank" style="background-color:#bdc5ca;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 4: Open (FAIR) data and materials analyses</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in open (FAIR) data and materials. It requires students to learn about FAIR data (and education materials) principles: findability, accessibility, interoperability, and reusability; engage with reasons to share data, the initiatives designed to increase scientific openness; as well as ethical considerations and consequences of open (FAIR) data practices. There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Publication models.</li><li>Reasons to share; for science, and for one‚Äôs own practices.</li><li>Repositories such as OSF, FigShare, GitHub, Zenodo.</li><li>Accessing or sharing others data, code, and materials.</li><li>Ethical considerations.</li><li>Examples and consequences of accessing un/open data.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C4S1-tab data-toggle=tab href=#C4S1 role=tab aria-controls=C4S1 aria-selected=true>Publication models</a></li><li class=nav-item><a class=nav-link id=C4S2-tab data-toggle=tab href=#C4S2 role=tab aria-controls=C4S2 aria-selected=false>Why?</a></li><li class=nav-item><a class=nav-link id=C4S3-tab data-toggle=tab href=#C4S3 role=tab aria-controls=C4S3 aria-selected=false>Repositories</a></li><li class=nav-item><a class=nav-link id=C4S4-tab data-toggle=tab href=#C4S4 role=tab aria-controls=C4S4 aria-selected=false>Access</a></li><li class=nav-item><a class=nav-link id=C4S5-tab data-toggle=tab href=#C4S5 role=tab aria-controls=C4S5 aria-selected=false>Ethics</a></li><li class=nav-item><a class=nav-link id=C4S6-tab data-toggle=tab href=#C4S6 role=tab aria-controls=C4S6 aria-selected=false>Examples</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C4S1 role=tabpanel aria-labelledby=C4S1-tab><br><h2 id=publication-models>Publication models</h2><p><em><strong>Traditional publication models, open access models, preprints, etc.</strong></em></p><ul><li><p>Hardwicke, T. E., Mathur, M. B., MacDonald, K., Nilsonne, G., Banks, G. C., Kidwell, M. C., &mldr; & Lenne, R. L. (2018). Data availability, reusability, and analytic reproducibility: Evaluating the impact of a mandatory open data policy at the journal Cognition. Royal Society Open Science, 5(8), 180448.
<a href=http://dx.doi.org/10.1098/rsos.180448 target=_blank rel=noopener>http://dx.doi.org/10.1098/rsos.180448</a></p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., ‚Ä¶ Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443‚Äì490.
<a href=https://doi.org/10.1177/2515245918810225 target=_blank rel=noopener>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahn√≠k, ≈†., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A ‚Äúmany labs‚Äù replication project. Social Psychology, 45, 142‚Äì152.
<a href=https://doi.org/10.1027/1864-9335/a000178 target=_blank rel=noopener>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062‚Äì1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Siler, K., Haustein, S., Smith, E., Larivi√®re, V., & Alperin, J. P. (2018). Authorial and institutional stratification in open access publishing: the case of global health research. PeerJ, 6, e4269. doi:10.7717/peerj.4269</p></li><li><p>Tennant, J. P., Waldner, F., Jacques, D. C., Masuzzo, P., Collister, L. B., & Hartgerink, C. H. (2016). The academic, economic and societal impacts of Open Access: an evidence-based review. F1000Research, 5, 632. doi:10.12688/f1000research.8460.3</p></li></ul><br></div><div class="tab-pane fade" id=C4S2 role=tabpanel aria-labelledby=C4S2-tab><br><h2 id=reasons-to-share-for-science-and-for-ones-own-practices>Reasons to share; for science, and for one‚Äôs own practices</h2><ul><li><p>Colavizza, G., Hrynaszkiewicz, I., Staden, I., Whitaker, K., & McGillivray, B. (2020). The citation advantage of linking publications to research data. PloS One, 15(4), e0230416.</p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., ‚Ä¶ Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443‚Äì490.
<a href=https://doi.org/10.1177/2515245918810225 target=_blank rel=noopener>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahn√≠k, ≈†., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A ‚Äúmany labs‚Äù replication project. Social Psychology, 45, 142‚Äì152.
<a href=https://doi.org/10.1027/1864-9335/a000178 target=_blank rel=noopener>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Levenstein, M. C., & Lyle, J. A. (2018). Data: Sharing Is Caring. Advances in Methods and Practices in Psychological Science, 1(1), 95‚Äì103.
<a href=https://doi.org/10.1177/2515245918758319 target=_blank rel=noopener>https://doi.org/10.1177/2515245918758319</a></p></li><li><p>Piwowar, H.A., & Vision, T.J. (2013). Data reuse and the open data citation advantage. PeerJ, 1, e175
<a href=https://doi.org/10.7717/peerj.175 target=_blank rel=noopener>https://doi.org/10.7717/peerj.175</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062‚Äì1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Stodden, V. C. (2011). Trust your science? Open your data and code. Amstat News, 409, 21-22.</p></li><li><p>Tennant, J. P., Waldner, F., Jacques, D. C., Masuzzo, P., Collister, L. B., & Hartgerink, C. H. (2016). The academic, economic and societal impacts of Open Access: an evidence-based review. F1000Research, 5, 632. doi:10.12688/f1000research.8460.3</p></li></ul><br></div><div class="tab-pane fade" id=C4S3 role=tabpanel aria-labelledby=C4S3-tab><br><h2 id=repositories-such-as-osf-figshare-github-zenodo>Repositories such as OSF, FigShare, GitHub, Zenodo</h2><ul><li><p>Gilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2018). Practical solutions for sharing data and materials from psychological research. Advances in Methods and Practices in Psychological Science, 1(1), 121‚Äì130.
<a href=https://doi.org/10.1177/2515245917746500 target=_blank rel=noopener>https://doi.org/10.1177/2515245917746500</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062‚Äì1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Soderberg, C. K. (2018). Using OSF to Share Data: A Step-by-Step Guide. Advances in Methods and Practices in Psychological Science, 1(1), 115‚Äì120.
<a href=https://doi.org/10.1177/2515245918757689 target=_blank rel=noopener>https://doi.org/10.1177/2515245918757689</a></p></li><li><p><a href=osf.io>osf.io</a></p></li><li><p><a href=figshare.com>figshare.com</a></p></li><li><p><a href=github.com>github.com</a></p></li><li><p><a href=http://zenodo.org/ target=_blank rel=noopener>zenodo.org</a></p></li></ul><br></div><div class="tab-pane fade" id=C4S4 role=tabpanel aria-labelledby=C4S4-tab><br><h2 id=accessing-or-sharing-others-data-code-and-materials>Accessing or sharing others data, code, and materials</h2><ul><li><p>Joel, S., Eastwick, P. W., & Finkel, E. J. (2018). Open sharing of data on close relationships and other sensitive social psychological topics: Challenges, tools, and future directions. Advances in Methods and Practices in Psychological Science, 1(1), 86‚Äì94.
<a href=https://doi.org/10.1177/2515245917744281 target=_blank rel=noopener>https://doi.org/10.1177/2515245917744281</a></p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., ‚Ä¶ Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443‚Äì490.
<a href=https://doi.org/10.1177/2515245918810225 target=_blank rel=noopener>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahn√≠k, ≈†., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A ‚Äúmany labs‚Äù replication project. Social Psychology, 45, 142‚Äì152.
<a href=https://doi.org/10.1027/1864-9335/a000178 target=_blank rel=noopener>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Piwowar, H.A., & Vision, T.J. (2013). Data reuse and the open data citation advantage. PeerJ, 1, e175
<a href=https://doi.org/10.7717/peerj.175 target=_blank rel=noopener>https://doi.org/10.7717/peerj.175</a></p></li><li><p>Wicherts, J. M., Borsboom, D., Kats, J., & Molenaar, D. (2006). The poor availability of psychological research data for reanalysis. American Psychologist, 61(7), 726‚Äì728.
<a href=https://doi.org/10.1037/0003-066X.61.7.726 target=_blank rel=noopener>https://doi.org/10.1037/0003-066X.61.7.726</a></p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.</p></li></ul><br></div><div class="tab-pane fade" id=C4S5 role=tabpanel aria-labelledby=C4S5-tab><br><h2 id=ethical-considerations>Ethical considerations</h2><ul><li><p>Hand, D. J. (2018). Aspects of data ethics in a changing world: Where are we now? Big Data, 6(3), :176‚Äì190. doi:
<a href=https://doi.org/10.1089/big.2018.0083 target=_blank rel=noopener>https://doi.org/10.1089/big.2018.0083</a></p></li><li><p>O‚ÄôCallaghan, E., & Douglas, H. M. (2021). #MeToo Online Disclosures: A Survivor-Informed Approach to Open Science Practices and Ethical Use of Social Media Data. Psychology of Women Quarterly, 45(4), 505‚Äì525.
<a href=https://doi.org/10.1177/03616843211039175 target=_blank rel=noopener>https://doi.org/10.1177/03616843211039175</a></p></li><li><p>Ross, M. W., Iguchi, M. Y., & Panicker, S. (2018). Ethical aspects of data sharing and research participant protections. American Psychologist, 73(2), 138-145.
<a href=http://dx.doi.org/10.1037/amp0000240 target=_blank rel=noopener>http://dx.doi.org/10.1037/amp0000240</a></p></li><li><p>Siler, K., Haustein, S., Smith, E., Larivi√®re, V., & Alperin, J. P. (2018). Authorial and institutional stratification in open access publishing: the case of global health research. PeerJ, 6, e4269. doi:10.7717/peerj.4269</p></li><li><p>Walsh, C. G., Xia, W., Li, M., Denny, J. C., Harris, P. A., & Malin, B. A. (2018). Enabling open-science initiatives in clinical psychology and psychiatry without sacrificing patients‚Äô privacy: Current practices and future challenges. Advances in Methods and Practices in Psychological Science, 1(1), 104‚Äì114.
<a href=https://doi.org/10.1177/2515245917749652 target=_blank rel=noopener>https://doi.org/10.1177/2515245917749652</a></p></li></ul><br></div><div class="tab-pane fade" id=C4S6 role=tabpanel aria-labelledby=C4S6-tab><br><h2 id=examples-and-consequences-of-accessing-unopen-data>Examples and consequences of accessing un/open data</h2><ul><li><p>Houtkoop, B. L., Chambers, C., Macleod, M., Bishop, D. V. M., Nichols, T. E., & Wagenmakers, E.-J. (2018). Data sharing in psychology: A survey on barriers and preconditions. Advances in Methods and Practices in Psychological Science, 1(1), 70‚Äì85.
<a href=https://doi.org/10.1177/2515245917751886 target=_blank rel=noopener>https://doi.org/10.1177/2515245917751886</a></p></li><li><p>Peng, R. (2015). The reproducibility crisis in science: A statistical counterattack. Significance, 12(3).
<a href=https://doi.org/10.1111/j.1740-9713.2015.00827.x target=_blank rel=noopener>https://doi.org/10.1111/j.1740-9713.2015.00827.x</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062‚Äì1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Walsh, C. G., Xia, W., Li, M., Denny, J. C., Harris, P. A., & Malin, B. A. (2018). Enabling open-science initiatives in clinical psychology and psychiatry without sacrificing patients‚Äô privacy: Current practices and future challenges. Advances in Methods and Practices in Psychological Science, 1(1), 104‚Äì114.
<a href=https://doi.org/10.1177/2515245917749652 target=_blank rel=noopener>https://doi.org/10.1177/2515245917749652</a></p></li><li><p>Wicherts, J. M., Borsboom, D., Kats, J., & Molenaar, D. (2006). The poor availability of psychological research data for reanalysis. American Psychologist, 61(7), 726‚Äì728.
<a href=https://doi.org/10.1037/0003-066X.61.7.726 target=_blank rel=noopener>https://doi.org/10.1037/0003-066X.61.7.726</a></p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster5 class="home-section wg-blank" style="background-color:#b6cac8;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 5: Preregistration</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Preregistration entails laying out a complete methodology and analysis before a study has been undertaken. This facilitates transparency and removes several potential QRPs. When teaching, students should attain knowledge regarding what a pre-registration entails, why it is important to remove potential QRPs and how to address deviations from preregistered plans.
There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Purpose of preregistration.</li><li>Preregistration and registered reports - strengths and differences.</li><li>When can you preregister? Can you pre-register secondary data?</li><li>Understanding the types of preregistration and writing one.</li><li>Comparing a preregistration to a final study manuscript.</li><li>Conducting a preregistered study.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C5S1-tab data-toggle=tab href=#C5S1 role=tab aria-controls=C5S1 aria-selected=true>Purpose</a></li><li class=nav-item><a class=nav-link id=C5S2-tab data-toggle=tab href=#C5S2 role=tab aria-controls=C5S2 aria-selected=false>Registered Reports</a></li><li class=nav-item><a class=nav-link id=C5S3-tab data-toggle=tab href=#C5S3 role=tab aria-controls=C5S3 aria-selected=false>Secondary data</a></li><li class=nav-item><a class=nav-link id=C5S4-tab data-toggle=tab href=#C5S4 role=tab aria-controls=C5S4 aria-selected=false>Types & How-to</a></li><li class=nav-item><a class=nav-link id=C5S5-tab data-toggle=tab href=#C5S5 role=tab aria-controls=C5S5 aria-selected=false>Comparing</a></li><li class=nav-item><a class=nav-link id=C5S6-tab data-toggle=tab href=#C5S6 role=tab aria-controls=C5S6 aria-selected=false>Conducting</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C5S1 role=tabpanel aria-labelledby=C5S1-tab><br><h2 id=purpose-of-preregistration>Purpose of preregistration</h2><p><em><strong>Distinguishing exploratory and confirmatory analyses, transparency measures.</strong></em></p><ul><li><p>Dal-R√©, R., Ioannidis, J. P., Bracken, M. B., Buffler, P. A., Chan, A.-W., Franco, E. L., La Vecchia, C., Weiderpass, E. (2014). Making prospective registration of observational research a reality. Science translational medicine, 6(224), 224cm1. DOI:
<a href=https://doi.org/10.1126/scitranslmed.3007513 target=_blank rel=noopener>https://doi.org/10.1126/scitranslmed.3007513</a></p></li><li><p>Nosek, B. A., & Lakens, D. (2014). Registered reports: A method to increase the credibility of published results. Social Psychology, 45, 137‚Äì141.</p></li><li><p>Lin, W., & Green, D. P. (2016). Standard operating procedures: A safety net for pre-analysis plans. PS: Political Science & Politics, 49(3), 495-500.</p></li><li><p>Nosek, B. A., Ebersole, C. R., DeHaven, A., & Mellor, D. (2018). The Preregistration Revolution. Proceedings of National Academy Sciences, 115(11), 2600-2606.
<a href=https://doi.org/10.1073/pnas.1708274114 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1708274114</a></p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.doi: 10.3389/fpsyg.2016.01832</p></li><li><p>Nuzzo, R. (2015). How scientists fool themselves ‚Äî and how they can stop. Nature, 526, 182‚Äì185.</p></li><li><p>Wagenmakers, E. J., & Dutilh, G. (2016). Seven selfish reasons for preregistration. APS Observer, 29(9).</p></li></ul><br></div><div class="tab-pane fade" id=C5S2 role=tabpanel aria-labelledby=C5S2-tab><br><h2 id=preregistration-and-registered-reports---strengths-and-differences>Preregistration and registered reports - strengths and differences</h2><p>*<strong>OSC, CREP, ManyLabs, etc.</strong></p><ul><li><p>Chambers, C. D. (2013). Registered reports: A new publishing initiative at Cortex. Cortex, 49(3), 609-610.
<a href=https://doi.org/10.1016/j.cortex.2012.12.016 target=_blank rel=noopener>https://doi.org/10.1016/j.cortex.2012.12.016</a></p></li><li><p>Chambers, C. D., Feredoes, E., Muthukumaraswamy, S. D., & Etchells, P. (2014). Instead of ‚Äúplaying the game‚Äù it is time to change the rules: Registered Reports at AIMS Neuroscience and beyond. AIMS Neuroscience, 1(1), 4‚Äì17. DOI: 10.3934/Neuroscience2014.1.4</p></li><li><p>Chambers, C.D., Dienes, Z., McIntosh, R.D., Rotshtein, P., & Willmes, K. (2015). Registered Reports: Realigning incentives in scientific publishing. Cortex, 66, A1-2. DOI: 10.1016/j.cortex.2015.03.022</p></li></ul><br></div><div class="tab-pane fade" id=C5S3 role=tabpanel aria-labelledby=C5S3-tab><br><h2 id=when-can-you-preregister-can-you-pre-register-secondary-data>When can you preregister? Can you pre-register secondary data?</h2><ul><li><p>Chambers, C.D., Dienes, Z., McIntosh, R.D., Rotshtein, P., & Willmes, K. (2015). Registered Reports: Realigning incentives in scientific publishing. Cortex, 66, A1-2. DOI:
<a href=https://doi.org/10.1016/j.cortex.2015.03.022 target=_blank rel=noopener>https://doi.org/10.1016/j.cortex.2015.03.022</a></p></li><li><p>Haven, Tamarinde., L. & Van Grootel, Leonie. (2019). Preregistering qualitative research. Accountability in Research, 26(3), 229-244., DOI:
<a href=https://doi.org/10.1080/08989621.2019.1580147 target=_blank rel=noopener>https://doi.org/10.1080/08989621.2019.1580147</a></p></li><li><p>Kirtley, O. J., Lafit, G., Achterhof, R., Hiekkaranta, A. P., & Myin-Germeys, I. (2019, April 10). Making the black box transparent: A pre-registration template for studies using Experience Sampling Methods (ESM).
<a href=https://doi.org/10.31234/osf.io/seyq7 target=_blank rel=noopener>https://doi.org/10.31234/osf.io/seyq7</a></p></li><li><p>Mertens, G., & Krypotos, A. (2019, February 20). Preregistration of secondary analyses.
<a href=https://doi.org/10.31234/osf.io/ph4q7 target=_blank rel=noopener>https://doi.org/10.31234/osf.io/ph4q7</a></p></li></ul><br></div><div class="tab-pane fade" id=C5S4 role=tabpanel aria-labelledby=C5S4-tab><br><h2 id=understanding-the-types-of-preregistration-and-writing-one>Understanding the types of preregistration and writing one.</h2><ul><li><p>Nosek, B. A., Ebersole, C. R., DeHaven, A. C., & Mellor, D. T. (2018). The preregistration revolution. Proceedings of the National Academy of Sciences, 115(11), 2600-2606.
<a href=https://doi.org/10.1073/pnas.1708274114 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1708274114</a></p></li><li><p>Mertens, G., & Krypotos, A. (2019, February 20). Preregistration of secondary analyses.
<a href=https://doi.org/10.31234/osf.io/ph4q7 target=_blank rel=noopener>https://doi.org/10.31234/osf.io/ph4q7</a></p></li><li><p>COS:
<a href=https://cos.io/prereg/ target=_blank rel=noopener>What is Preregistration?</a></p></li><li><p>COS:
<a href=https://cos.io/blog/10-preregistration-tips/ target=_blank rel=noopener>10 Tips for Making a Great Preregistration</a></p></li><li><p>COS:
<a href=https://www.wiley.com/network/researchers/being-a-peer-reviewer/8-answers-about-registered-reports-research-preregistration-and-why-both-are-important target=_blank rel=noopener>8 Answers About Registered Reports and Research Preregistration</a></p></li></ul><br></div><div class="tab-pane fade" id=C5S5 role=tabpanel aria-labelledby=C5S5-tab><br><h2 id=comparing-a-preregistration-to-a-final-study-manuscript>Comparing a preregistration to a final study manuscript.</h2><ul><li><a href=https://authorservices.wiley.com/Reviewers/journal-reviewers/how-to-perform-a-peer-review/reviewing-registered-reports.html target=_blank rel=noopener>Wiley&rsquo;s Reviewing Registered Reports</a></li></ul><br></div><div class="tab-pane fade" id=C5S6 role=tabpanel aria-labelledby=C5S6-tab><br><h2 id=conducting-a-preregistered-study>Conducting a preregistered study.</h2><ul><li><p>L. Haven, T., & Van Grootel, D. L. (2019). Preregistering qualitative research. Accountability in Research, 26(3), 229-244.
<a href=https://doi.org/10.1080/08989621.2019.1580147 target=_blank rel=noopener>https://doi.org/10.1080/08989621.2019.1580147</a></p></li><li><p>Nosek, B. A., Ebersole, C. R., DeHaven, A., & Mellor, D. (2018). The Preregistration Revolution. PNAS, 115(11), 2600-2606.
<a href=https://doi.org/10.1073/pnas.1708274114 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1708274114</a></p></li><li><p>COS:
<a href=https://www.cos.io/blog/one-preregistration-rule-them-all target=_blank rel=noopener>One Preregistration to Rule Them All?</a></p></li></ul><br></div></div></div></div></div></div></section><section id=cluster6 class="home-section wg-blank" style="background-color:#bacabd;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 6: Replication research</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in &lsquo;replication research&rsquo;, which takes a variety of forms, each with a different purpose and contribution. Reproducible science requires replication research. When teaching, students should understand the purpose and need of replications in its variety of forms and being able to conduct (and join) replication projects. There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Purposes of replication attempts - what is a ‚Äòfailed‚Äô replication?</li><li>Large scale replication attempts.</li><li>Distinguishing direct and conceptual replications.</li><li>Conducting replication studies; challenges, limitations, and comparisons with the original study.</li><li>Registered Replication Reports (RRR).</li><li>The politics of replicating famous studies.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C6S1-tab data-toggle=tab href=#C6S1 role=tab aria-controls=C6S1 aria-selected=true>Purpose</a></li><li class=nav-item><a class=nav-link id=C6S2-tab data-toggle=tab href=#C6S2 role=tab aria-controls=C6S2 aria-selected=false>Large Scale</a></li><li class=nav-item><a class=nav-link id=C6S3-tab data-toggle=tab href=#C6S3 role=tab aria-controls=C6S3 aria-selected=false>Direct vs conceptual</a></li><li class=nav-item><a class=nav-link id=C6S4-tab data-toggle=tab href=#C6S4 role=tab aria-controls=C6S4 aria-selected=false>Conducting replications</a></li><li class=nav-item><a class=nav-link id=C6S5-tab data-toggle=tab href=#C6S5 role=tab aria-controls=C6S5 aria-selected=false>RRR</a></li><li class=nav-item><a class=nav-link id=C6S6-tab data-toggle=tab href=#C6S6 role=tab aria-controls=C6S6 aria-selected=false>Politics</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C6S1 role=tabpanel aria-labelledby=C6S1-tab><br><h2 id=purposes-of-replication-attempts---what-is-a-failed-replication>Purposes of replication attempts - what is a ‚Äòfailed‚Äô replication?</h2><ul><li><p>Fidler, F., & Wilcox, J. (2018). Reproducibility of scientific results. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Winter 2018). Metaphysics Research Lab, Stanford University.
<a href=https://plato.stanford.edu/archives/win2018/entries/scientific-reproducibility/ target=_blank rel=noopener>https://plato.stanford.edu/archives/win2018/entries/scientific-reproducibility/</a></p></li><li><p>Frank, M. C., & Saxe, R. (2012). Teaching replication. Perspectives on Psychological Science, 7(6), 600‚Äì604.
<a href=https://doi.org/10.1177/1745691612460686 target=_blank rel=noopener>https://doi.org/10.1177/1745691612460686</a></p></li><li><p>Garc√≠a, FM. (2016). Replication and the manufacture of scientific inferences: A formal approach. International Studies Perspectives, 17(4), 408‚Äì425.
<a href=https://doi.org/10.1093/isp/ekv011 target=_blank rel=noopener>https://doi.org/10.1093/isp/ekv011</a></p></li><li><p>Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J., & Reinero, D. A. (2016). Contextual sensitivity in scientific reproducibility. Proceedings of the National Academy of Sciences, 113(23), 6454-6459.
<a href=https://doi.org/10.1073/pnas.1521897113 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1521897113</a></p></li><li><p>Zwaan, R.A., Etz, A., Lucas, R.E, Donnellan, M.B. (2018). Making replication mainstream. Behavior and Brain Sciences, 41, e120.
<a href=https://doi.org/10.1017/S0140525X17001972 target=_blank rel=noopener>https://doi.org/10.1017/S0140525X17001972</a></p></li></ul><br></div><div class="tab-pane fade" id=C6S2 role=tabpanel aria-labelledby=C6S2-tab><br><h2 id=large-scale-replication-attempts>Large scale replication attempts</h2><p>*<strong>OSC, CREP, ManyLabs, etc.</strong></p><ul><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahn√≠k, ≈†., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A ‚Äúmany labs‚Äù replication project. Social Psychology, 45, 142‚Äì152.
<a href=https://doi.org/10.1027/1864-9335/a000178 target=_blank rel=noopener>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., ‚Ä¶ Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443‚Äì490.
<a href=https://doi.org/10.1177/2515245918810225 target=_blank rel=noopener>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Open Science Collaboration (2012). An open, large-scale, collaborative effort to estimate the reproducibility of psychological science. Perspectives on Psychological Science, 7, 657‚Äì660.</p></li><li><p>Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aaC6716. DOI: 10.1126/science.aaC6716</p></li><li><p>Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J., & Reinero, D. A. (2016). Contextual sensitivity in scientific reproducibility. Proceedings of the National Academy of Sciences, 113(23), 6454-6459.
<a href=https://doi.org/10.1073/pnas.1521897113 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1521897113</a></p></li><li><p><a href=https://manyprimates.github.io/ target=_blank rel=noopener>ManyPrimates</a></p></li><li><p><a href=https://osf.io/wfc6u/ target=_blank rel=noopener>CREP</a></p></li></ul><br></div><div class="tab-pane fade" id=C6S3 role=tabpanel aria-labelledby=C6S3-tab><br><h2 id=distinguishing-direct-and-conceptual-replications>Distinguishing direct and conceptual replications</h2><p><em><strong>Direct replications use the exact same methods and materials, while conceptual replications test the same concept but with different methods, materials, or both.</strong></em></p><ul><li><p>Kunert, R. (2016). Internal conceptual replications do not increase independent replication success. Psychonomic bulletin & review, 23(5), 1631-1638.
<a href=https://doi.org/10.3758/s13423-016-1030-9 target=_blank rel=noopener>https://doi.org/10.3758/s13423-016-1030-9</a></p></li><li><p>Simons, D. J. (2014). The Value of Direct Replication. Perspectives on Psychological Science, 9(1), 76‚Äì80.
<a href=https://doi.org/10.1177/1745691613514755 target=_blank rel=noopener>https://doi.org/10.1177/1745691613514755</a></p></li><li><p>Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J., & Reinero, D. A. (2016). Contextual sensitivity in scientific reproducibility. Proceedings of the National Academy of Sciences, 113(23), 6454-6459.
<a href=https://doi.org/10.1073/pnas.1521897113 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1521897113</a></p></li><li><p>Zwaan, R.A., Etz, A., Lucas, R.E, Donnellan, M.B. (2018). Making replication mainstream. Behavior and Brain Sciences, 41, e120.
<a href=https://doi.org/10.1017/S0140525X17001972 target=_blank rel=noopener>https://doi.org/10.1017/S0140525X17001972</a></p></li></ul><br></div><div class="tab-pane fade" id=C6S4 role=tabpanel aria-labelledby=C6S4-tab><br><h2 id=conducting-replication-studies-challenges-limitations-and-comparisons-with-the-original-study>Conducting replication studies; challenges, limitations, and comparisons with the original study</h2><ul><li><p>Grahe, J. E., Brandt, M. J., Wagge, J. R., Legate, N., Wiggins, B. J., Christopherson, C. D., . . . LePine, S. (2018). Collaborative Replications and Education Project (CREP). Retrieved from
<a href=https://osf.io/wfc6u/ target=_blank rel=noopener>https://osf.io/wfc6u/</a></p></li><li><p>Grahe, J. E., Reifman, A., Hermann, A. D., Walker, M., Oleson, K. C., Nario-Redmond, M., & Wiebe, R. P. (2012). Harnessing the undiscovered resource of student research projects. Perspectives on Psychological Science, 7(6), 605‚Äì607.
<a href=https://doi.org/10.1177/1745691612459057 target=_blank rel=noopener>https://doi.org/10.1177/1745691612459057</a></p></li><li><p>Frank, M. C., & Saxe, R. (2012). Teaching replication. Perspectives on Psychological Science, 7(6), 600‚Äì604.
<a href=https://doi.org/10.1177/1745691612460686 target=_blank rel=noopener>https://doi.org/10.1177/1745691612460686</a></p></li><li><p>Lenne & Mann (2016). CREP project report.
<a href=https://osf.io/sdj7e/ target=_blank rel=noopener>https://osf.io/sdj7e/</a></p></li><li><p>Stanley, D. J., & Spence, J. R. (2014). Expectations for replications: Are yours realistic? Perspectives on Psychological Science, 9(3), 305-318.
<a href=https://doi.org/10.1177/1745691614528518 target=_blank rel=noopener>https://doi.org/10.1177/1745691614528518</a></p></li><li><p>Wagge, J. R., Brandt, M. J., Lazarevic, L. B., Legate, N., Christopherson, C., Wiggins, B., & Grahe, J. E. (2019). Publishing research with undergraduate students via replication work: The collaborative replications and education project. Frontiers in psychology, 10, 247.</p></li></ul><br></div><div class="tab-pane fade" id=C6S5 role=tabpanel aria-labelledby=C6S5-tab><br><h2 id=registered-replication-reports>Registered Replication Reports</h2><p><em><strong>Registered Reports are studies that are peer-reviewed prior to data collection, with an agreement between the journal and the author(s) that it will be published regardless of outcome as long as the preregistered methods are reasonably followed. Registered REPLICATION Reports are a special category of these that only include replications.</strong></em></p><ul><li><p>Simons, D. J., Holcombe, A. O., & Spellman, B. A. (2014). An Introduction to Registered Replication Reports at Perspectives on Psychological Science. Perspectives on Psychological Science, 9(5), 552‚Äì555.
<a href=https://doi.org/10.1177/1745691614543974 target=_blank rel=noopener>https://doi.org/10.1177/1745691614543974</a></p></li><li><p>Ongoing Replication projects
<a href=https://www.psychologicalscience.org/publications/replication/ongoing-projects target=_blank rel=noopener>https://www.psychologicalscience.org/publications/replication/ongoing-projects</a></p></li><li><p>Alogna, V. K., Attaya, M. K., Aucoin, P., Bahn√≠k, ≈†., Birch, S., Birt, A. R., &mldr; & Buswell, K. (2014). Registered replication report: Schooler and engstler-schooler (1990). Perspectives on Psychological Science, 9(5), 556-578.</p></li><li><p>Eerland, A., Sherrill, A. M., Magliano, J. P., Zwaan, R. A., Arnal, J. D., Aucoin, P., &mldr; & Crocker, C. (2016). Registered replication report: Hart & albarrac√≠n (2011). Perspectives on Psychological Science, 11(1), 158-171.</p></li></ul><p><a href=https://www.psychologicalscience.org/publications/replication/ongoing-projects target=_blank rel=noopener>Psychological Science Accelerator (PSA) Ongoing Replications</a></p><br></div><div class="tab-pane fade" id=C6S6 role=tabpanel aria-labelledby=C6S6-tab><br><h2 id=the-politics-of-replicating-famous-studies>The politics of replicating famous studies</h2><p><em><strong>Sometimes responses to replication research can be negative. Failed replications of famous work, most notably power posing, ego depletion, stereotype threat, and facial feedback, have received a lot of attention.</strong></em></p><ul><li><p>Neuliep, J. W., & Crandall, R. (1990). Editorial bias against replication research. Journal of Social Behavior & Personality, 5(4), 85-90.</p></li><li><p>Neuliep, J. W., & Crandall, R. (1993). Reviewer bias against replication research. Journal of Social Behavior & Personality, 8(6), 21-29.</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster7 class="home-section wg-blank" style="background-color:#c9dbcb;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 7: Academic Life, Ethics and Culture</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in topics related to academia and academics. Students should understand how individuals, teams, institutions, and academic culture work together to promote (or hinder) openness, inclusion, diversity, equity and transparency. Gathering perspectives on navigating scientific and academic life. Learning the challenges and rewards in the academic setting, the ‚Äúhidden curriculum‚Äù in academic life.</p><p>There are 8 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Diversity</li><li>Equity</li><li>Inclusion</li><li>Citizen science</li><li>Team science</li><li>Adversarial collaboration</li><li>The structure of and incentives in academia</li><li>Types of academic, non-academic & alt-academic positions</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C7S1-tab data-toggle=tab href=#C7S1 role=tab aria-controls=C7S1 aria-selected=true>Diversity</a></li><li class=nav-item><a class=nav-link id=C7S2-tab data-toggle=tab href=#C7S2 role=tab aria-controls=C7S2 aria-selected=false>Equity</a></li><li class=nav-item><a class=nav-link id=C7S3-tab data-toggle=tab href=#C7S3 role=tab aria-controls=C7S3 aria-selected=false>Inclusion</a></li><li class=nav-item><a class=nav-link id=C7S4-tab data-toggle=tab href=#C7S4 role=tab aria-controls=C7S4 aria-selected=false>Citizen science</a></li><li class=nav-item><a class=nav-link id=C7S5-tab data-toggle=tab href=#C7S5 role=tab aria-controls=C7S5 aria-selected=false>Team science</a></li><li class=nav-item><a class=nav-link id=C7S6-tab data-toggle=tab href=#C7S6 role=tab aria-controls=C7S6 aria-selected=false>Adversarial collaboration</a></li><li class=nav-item><a class=nav-link id=C7S7-tab data-toggle=tab href=#C7S7 role=tab aria-controls=C7S7 aria-selected=false>Incentives</a></li><li class=nav-item><a class=nav-link id=C7S8-tab data-toggle=tab href=#C7S8 role=tab aria-controls=C7S8 aria-selected=false>Positions</a></li><li class=nav-item><a class=nav-link id=C7S9-tab data-toggle=tab href=#C7S9 role=tab aria-controls=C7S9 aria-selected=false>Feminist Thought</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C7S1 role=tabpanel aria-labelledby=C7S1-tab><br><h2 id=diversity>Diversity</h2><p><em><strong>Diversity is the presence of difference within a specific environment, e.g. racial diversity, gender diversity, social-economic diversity, etc.</strong></em></p><ul><li><p>Bahlai, C., Bartlett, L. J., Burgio, K. R., Fournier, A., Keiser, C. N., Poisot, T., & Whitney, K. S. (2019). Open science isn‚Äôt always open to all scientists. American Scientist, 107(2), 78-82.
<a href=https://doi.org/10.1511/2019.107.2.78 target=_blank rel=noopener>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Cislak, A., Formanowicz, M., & Saguy, T. (2018). Bias against research on gender bias. Scientometrics, 115(1), 189-200.
<a href=https://doi.org/10.1007/s11192-018-2667-0 target=_blank rel=noopener>https://doi.org/10.1007/s11192-018-2667-0</a></p></li><li><p>Flaherty, C. (2020, August, 20). Something&rsquo;s Got to Give. Inside Higher Ed. Retrieved from
<a href=https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall target=_blank rel=noopener>https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall</a></p></li><li><p>Kim, E., & Patterson, S. (2020). The Pandemic and Gender Inequality in Academia. Available at SSRN 3666587.
<a href=http://dx.doi.org/10.2139/ssrn.3666587 target=_blank rel=noopener>http://dx.doi.org/10.2139/ssrn.3666587</a></p></li><li><p>Larivi√®re, V., Ni, C., Gingras, Y., Cronin, B., & Sugimoto, C. R. (2013). Bibliometrics: Global gender disparities in science. Nature News, 504(7479), 211.
<a href=https://doi.org/10.1038/504211a target=_blank rel=noopener>https://doi.org/10.1038/504211a</a></p></li><li><p>Myers, K. R., Tham, W. Y., Yin, Y., Cohodes, N., Thursby, J. G., Thursby, M. C., &mldr; & Wang, D. (2020). Unequal effects of the COVID-19 pandemic on scientists. Nature human behaviour, 4(9), 880-883.</p></li><li><p>Quagliata, T. (2008). Is there a positive correlation between socioeconomic status and academic achievement?. Paper: Education masters (p. 78).
<a href="https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&amp;context=education_ETD_masters" target=_blank rel=noopener>https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&context=education_ETD_masters</a></p></li><li><p>Roberson, M. L. (2020). On supporting early-career Black scholars. Nature Human Behaviour, 1-1.
<a href=https://doi.org/10.1038/s41562-020-0926-6 target=_blank rel=noopener>https://doi.org/10.1038/s41562-020-0926-6</a></p></li><li><p>APA (2010). Sexual Orientation, Gender identity & Socioeconomic Status [Blog post]. Retrieved fromhttps://www.apa.org/pi/ses/resources/publications/lgbt</p></li><li><p>APA (2010). Disability & Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/disability target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/disability</a></p></li><li><p>APA. (2017, July). Women & Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/women target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/women</a></p></li><li><p>APA (2017, July). Ethnic and Racial Minorities & Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/minorities target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/minorities</a></p></li><li><p>APA (2017, July). Education and Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/education target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/education</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S2 role=tabpanel aria-labelledby=C7S2-tab><br><p><em><strong>Equity is that everyone has access to the same opportunities and that we all have privileges and barriers, thus we do not all start from the same starting position.</strong></em></p><ul><li><p>APA (2010). Sexual Orientation, Gender identity & Socioeconomic Status [Blog post]. Retrieved fromhttps://www.apa.org/pi/ses/resources/publications/lgbt</p></li><li><p>APA (2010). Disability & Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/disability target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/disability</a></p></li><li><p>APA. (2017, July). Women & Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/women target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/women</a>
APA (2017, July). Ethnic and Racial Minorities & Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/minorities target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/minorities</a></p></li><li><p>APA (2017, July). Education and Socioeconomic Status [Blog post]. Retrieved from
<a href=https://www.apa.org/pi/ses/resources/publications/education target=_blank rel=noopener>https://www.apa.org/pi/ses/resources/publications/education</a></p></li><li><p>Bahlai, C., Bartlett, L. J., Burgio, K. R., Fournier, A., Keiser, C. N., Poisot, T., & Whitney, K. S. (2019). Open science isn‚Äôt always open to all scientists. American Scientist, 107(2), 78-82.
<a href=https://doi.org/10.1511/2019.107.2.78 target=_blank rel=noopener>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Cislak, A., Formanowicz, M., & Saguy, T. (2018). Bias against research on gender bias. Scientometrics, 115(1), 189-200.
<a href=https://doi.org/10.1007/s11192-018-2667-0 target=_blank rel=noopener>https://doi.org/10.1007/s11192-018-2667-0</a></p></li><li><p>Flaherty, C. (2020, August, 20). Something&rsquo;s Got to Give. Inside Higher Ed. Retrieved from
<a href=https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall target=_blank rel=noopener>https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall</a></p></li><li><p>Kim, E., & Patterson, S. (2020). The Pandemic and Gender Inequality in Academia. Available at SSRN 3666587.
<a href=http://dx.doi.org/10.2139/ssrn.3666587 target=_blank rel=noopener>http://dx.doi.org/10.2139/ssrn.3666587</a></p></li><li><p>Larivi√®re, V., Ni, C., Gingras, Y., Cronin, B., & Sugimoto, C. R. (2013). Bibliometrics: Global gender disparities in science. Nature News, 504(7479), 211.
<a href=https://doi.org/10.1038/504211a target=_blank rel=noopener>https://doi.org/10.1038/504211a</a></p></li><li><p>Myers, K. R., Tham, W. Y., Yin, Y., Cohodes, N., Thursby, J. G., Thursby, M. C., &mldr; & Wang, D. (2020). Unequal effects of the COVID-19 pandemic on scientists. Nature human behaviour, 4(9), 880-883.</p></li><li><p>Quagliata, T. (2008). Is there a positive correlation between socioeconomic status and academic achievement?. Paper: Education masters (p. 78).
<a href="https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&amp;context=education_ETD_masters" target=_blank rel=noopener>https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&context=education_ETD_masters</a></p></li><li><p>Roberson, M. L. (2020). On supporting early-career Black scholars. Nature Human Behaviour, 1-1.
<a href=https://doi.org/10.1038/s41562-020-0926-6 target=_blank rel=noopener>https://doi.org/10.1038/s41562-020-0926-6</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S3 role=tabpanel aria-labelledby=C7S3-tab><br><h2 id=inclusion>Inclusion</h2><p><em><strong>Inclusion is that individuals with different representations, identities and feelings being respected, influenced, and welcomed in a specific environment.</strong></em></p><ul><li><p>Bahlai, C., Bartlett, L. J., Burgio, K. R., Fournier, A., Keiser, C. N., Poisot, T., & Whitney, K. S. (2019). Open science isn‚Äôt always open to all scientists. American Scientist, 107(2), 78-82.
<a href=https://doi.org/10.1511/2019.107.2.78 target=_blank rel=noopener>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Carli, L. L., Alawa, L., Lee, Y., Zhao, B., & Kim, E. (2016). Stereotypes about gender and science: Women‚â† scientists. Psychology of Women Quarterly, 40(2), 244-260
<a href=https://doi.org/10.1177/0361684315622645 target=_blank rel=noopener>https://doi.org/10.1177/0361684315622645</a></p></li><li><p>Cislak, A., Formanowicz, M., & Saguy, T. (2018). Bias against research on gender bias. Scientometrics, 115(1), 189-200.
<a href=https://doi.org/10.1007/s11192-018-2667-0 target=_blank rel=noopener>https://doi.org/10.1007/s11192-018-2667-0</a></p></li><li><p>Eagly, A. H., & Miller, D. I. (2016). Scientific eminence: Where are the women?. Perspectives on Psychological Science, 11(6), 899-904.</p></li><li><p>Flaherty, C. (2020, August, 20). Something&rsquo;s Got to Give. Inside Higher Ed. Retrieved from
<a href=https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall target=_blank rel=noopener>https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall</a></p></li><li><p>Henrich, J., Heine, S. & Norenzayan, A. (2010) Most people are not WEIRD. Nature 466, 29.
<a href=https://doi.org/10.1038/466029a target=_blank rel=noopener>https://doi.org/10.1038/466029a</a></p></li><li><p>Larivi√®re, V., Ni, C., Gingras, Y., Cronin, B., & Sugimoto, C. R. (2013). Bibliometrics: Global gender disparities in science. Nature News, 504(7479), 211.
<a href=https://doi.org/10.1038/504211a target=_blank rel=noopener>https://doi.org/10.1038/504211a</a></p></li><li><p>Macoun, A., & Miller, D. (2014). Surviving (thriving) in academia: Feminist support networks and women ECRs. Journal of Gender Studies, 23(3), 287-301.
<a href=https://doi.org/10.1080/09589236.2014.909718 target=_blank rel=noopener>https://doi.org/10.1080/09589236.2014.909718</a></p></li><li><p>Myers, K. R., Tham, W. Y., Yin, Y., Cohodes, N., Thursby, J. G., Thursby, M. C., &mldr; & Wang, D. (2020). Unequal effects of the COVID-19 pandemic on scientists. Nature human behaviour, 4(9), 880-883.</p></li><li><p>Risner, L. E., Morin, X. K., Erenrich, E. S., Clifford, P. S., Franke, J., Hurley, I., & Schwartz, N. B. (2020). Leveraging a collaborative consortium model of mentee/mentor training to foster career progression of underrepresented postdoctoral researchers and promote institutional diversity and inclusion. PloS one, 15(9), e0238518.
<a href=https://doi.org/10.1371/journal.pone.0238518 target=_blank rel=noopener>https://doi.org/10.1371/journal.pone.0238518</a></p></li><li><p>Roberson, M. L. (2020). On supporting early-career Black scholars. Nature Human Behaviour, 1-1.
<a href=https://doi.org/10.1038/s41562-020-0926-6 target=_blank rel=noopener>https://doi.org/10.1038/s41562-020-0926-6</a></p></li><li><p>Skitka, L. J., Melton, Z. J., Mueller, A. B., & Wei, K. Y. (2020). The Gender Gap: Who Is (and Is Not) Included on Graduate-Level Syllabi in Social/Personality Psychology. Personality and Social Psychology Bulletin, 0146167220947326.
<a href=https://doi.org/10.1177/0146167220947326 target=_blank rel=noopener>https://doi.org/10.1177/0146167220947326</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S4 role=tabpanel aria-labelledby=C7S4-tab><br><h2 id=citizen-science>Citizen science</h2><p><em><strong>Citizen science is scientific research conducted, in whole or in part, by amateur (or nonprofessional) scientists. Citizen science is sometimes described as &ldquo;public participation in scientific research,&rdquo; participatory monitoring, and participatory action research whose outcomes are often advancements in scientific research by improving the scientific communities capacity, as well as an increasing the public&rsquo;s understanding of science.</strong></em></p><ul><li><p>Hart, D. D., & Silka, L. (2020). Rebuilding the ivory tower: bottom-up experiment in aligning research with societal needs. Issues Sci Technol, 36(3), 64-70.
<a href=https://issues.org/aligning-research-with-societal-needs/ target=_blank rel=noopener>https://issues.org/aligning-research-with-societal-needs/</a></p></li><li><p>Bonney, R., Cooper, C. B., Dickinson, J., Kelling, S., Phillips, T., Rosenberg, K. V., & Shirk, J. (2009). Citizen science: a developing tool for expanding science knowledge and scientific literacy. BioScience, 59(11), 977-984.</p></li><li><p>Bonney, R., Shirk, J. L., Phillips, T. B., Wiggins, A., Ballard, H. L., Miller-Rushing, A. J., & Parrish, J. K. (2014). Next steps for citizen science. Science, 343(6178), 1436-1437.</p></li><li><p>Cohn, J. P. (2008). Citizen science: Can volunteers do real research?. BioScience, 58(3), 192-197.</p></li></ul><br></div><div class="tab-pane fade" id=C7S5 role=tabpanel aria-labelledby=C7S5-tab><br><h2 id=team-science>Team science</h2><p><em><strong>Team science institutions coordinate a large group of scientists to solve a problem. Individual scientists are rewarded a publication by the institution for their efforts and resources. Once a group signs onto a team science project, the institution serves as a coordinating role, merging the resources from all scientists and focusing on a common project.</strong></em></p><ul><li><p>Forscher, P. S., Wagenmakers, E. J., DeBruine, L., Coles, N., Silan, M. A., & IJzerman, H. (2020). A Manifesto for Team Science. Retrieved from
<a href=https://psyarxiv.com/2mdxh target=_blank rel=noopener>https://psyarxiv.com/2mdxh</a>
Silberzahn, R., & Uhlmann, E. L. (2015). Crowdsourced research: Many hands make tight work. Nature News, 526(7572), 189.
<a href=https://doi.org/10.1038/526189a target=_blank rel=noopener>https://doi.org/10.1038/526189a</a></p></li><li><p>Wagge, J. R., Brandt, M. J., Lazarevic, L. B., Legate, N., Christopherson, C., Wiggins, B., & Grahe, J. E. (2019). Publishing research with undergraduate students via replication work: The collaborative replications and education project. Frontiers in psychology, 10, 247.
<a href=https://doi.org/10.3389/fpsyg.2019.00247 target=_blank rel=noopener>https://doi.org/10.3389/fpsyg.2019.00247</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S6 role=tabpanel aria-labelledby=C7S6-tab><br><h2 id=adversarial-collaborations>Adversarial collaborations</h2><ul><li><p>Tijdink, J. K., Verbeke, R., & Smulders, Y. M. (2014). Publication pressure and scientific misconduct in medical scientists. Journal of Empirical Research on Human Research Ethics, 9(5), 64-71.
<a href=https://doi.org/10.1177/1556264614552421 target=_blank rel=noopener>https://doi.org/10.1177/1556264614552421</a></p></li><li><p>Bateman, I., Kahneman, D., Munro, A., Starmer, C., & Sugden, R. (2005). Testing competing models of loss aversion: An adversarial collaboration. Journal of Public Economics, 89(8), 1561-1580.</p></li></ul><br></div><div class="tab-pane fade" id=C7S7 role=tabpanel aria-labelledby=C7S7-tab><br><h2 id=structures-and-incentives-in-academia>Structures and Incentives in academia</h2><p><em><strong>Sometimes responses to replication research can be negative. Failed replications of famous work, most notably power posing, ego depletion, stereotype threat, and facial feedback, have received a lot of attention.</strong></em></p><ul><li><p>Bol, T., de Vaan, M., & van de Rijt, A. (2018). The Matthew effect in science funding. Proceedings of the National Academy of Sciences, 115(19), 4887-4890.</p></li><li><p>Corker, K. S. (2017). Why a Focus on Eminence is Misguided: A Call to Return to Basic Scientific Values.
<a href=https://doi.org/10.31234/osf.io/yqfrd target=_blank rel=noopener>https://doi.org/10.31234/osf.io/yqfrd</a></p></li><li><p>Diener, E. (2016). Improving departments of psychology. Perspectives on Psychological Science, 11(6), 909-912.</p></li><li><p>Ebersole, C. R., Axt, J. R., & Nosek, B. A. (2016). Scientists‚Äô reputations are based on getting it right, not being right. PLoS biology, 14(5), e1002460.</p></li><li><p>Fanelli, D. (2012). Negative results are disappearing from most disciplines and countries. Scientometrics, 90(3), 891-904.
<a href=https://doi.org/10.1007/s11192-011-0494-7 target=_blank rel=noopener>https://doi.org/10.1007/s11192-011-0494-7</a></p></li><li><p>Feist, G. J. (2016). Intrinsic and extrinsic science: A dialectic of scientific fame. Perspectives on Psychological Science, 11(6), 893-898.</p></li><li><p>Ferreira, F. (2017). Fame: I‚Äôm Skeptical.
<a href=https://doi.org/10.31234/osf.io/6zb4f target=_blank rel=noopener>https://doi.org/10.31234/osf.io/6zb4f</a></p></li><li><p>Flier J. (2017) Faculty promotion must assess reproducibility. Nature, 549(7671),133.
<a href=https://doi.org/10.1038/549133a target=_blank rel=noopener>https://doi.org/10.1038/549133a</a></p></li><li><p>Foss, D. J. (2016). Eminence and omniscience: Statistical and clinical prediction of merit. Perspectives on Psychological Science, 11(6), 913-916.</p></li><li><p>Gernsbacher, M. A. (2018). Rewarding research transparency. Trends in cognitive sciences, 22(11), 953-956.
<a href=https://doi.org/10.1016/j.tics.2018.07.002 target=_blank rel=noopener>https://doi.org/10.1016/j.tics.2018.07.002</a></p></li><li><p>Hirsch, J. E. (2010). An index to quantify an individual‚Äôs scientific research output that takes into account the effect of multiple coauthorship. Scientometrics, 85(3), 741-754.</p></li><li><p>Innes-Ker, √Ö. (2017). The Focus on Fame Distorts Science.
<a href=https://doi.org/10.31234/osf.io/vyr3e target=_blank rel=noopener>https://doi.org/10.31234/osf.io/vyr3e</a></p></li><li><p>Ioannidis, J. P., & Thombs, B. D. (2019). A user‚Äôs guide to inflated and manipulated impact factors. European journal of clinical investigation, 49(9), e13151.
<a href=https://doi.org/10.1111/eci.13151 target=_blank rel=noopener>https://doi.org/10.1111/eci.13151</a></p></li><li><p>Jamieson, K. H., McNutt, M., Kiermer, V., & Sever, R. (2019). Signaling the trustworthiness of science. Proceedings of the National Academy of Sciences, 116(39), 19231-19236.https://doi.org/10.1073/pnas.1913039116</p></li><li><p>Jamieson, K. H., McNutt, M., Kiermer, V., & Sever, R. (2020). Reply to Kornfeld and Titus: No distraction from misconduct. Proceedings of the National Academy of Sciences of the United States of America, 117(1), 42.
<a href=https://doi.org/10.1073/pnas.1918001116 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1918001116</a></p></li><li><p>Kornfeld, D. S., & Titus, S. L. (2016). Stop ignoring misconduct. Nature, 537(7618), 29-30.https://doi.org/10.1038/537029a</p></li><li><p>Kornfeld, D. S., & Titus, S. L. (2020). Signaling the trustworthiness of science should not be a substitute for direct action against research misconduct. Proceedings of the National Academy of Sciences of the United States of America, 117(1), 41.
<a href=https://doi.org/10.1073/pnas.1917490116 target=_blank rel=noopener>https://doi.org/10.1073/pnas.1917490116</a></p></li><li><p>Li, W., Aste, T., Caccioli, F., & Livan, G. (2019). Early coauthorship with top scientists predicts success in academic careers. Nature communications, 10(1), 1-9.</p></li><li><p>Matosin, N., Frank, E., Engel, M., Lum, J. S., & Newell, K. A. (2014). Negativity towards negative results: a discussion of the disconnect between scientific worth and scientific culture. Disease Models & Mechanisms, 7(2), 171.
<a href=https://doi.org/10.1242/dmm.015123 target=_blank rel=noopener>https://doi.org/10.1242/dmm.015123</a></p></li><li><p>Morgan, A. C., Economou, D. J., Way, S. F., & Clauset, A. (2018). Prestige drives epistemic inequality in the diffusion of scientific ideas. EPJ Data Science, 7(1), 40.
<a href=https://doi.org/10.1140/epjds/s13688-018-0166-4 target=_blank rel=noopener>https://doi.org/10.1140/epjds/s13688-018-0166-4</a></p></li><li><p>Naudet, F., Ioannidis, J., Miedema, F., Cristea, I. A., Goodman, S. N., & Moher, D. (2018). Six principles for assessing scientists for hiring, promotion, and tenure. Impact of Social Sciences Blog.
<a href=http://eprints.lse.ac.uk/90753/ target=_blank rel=noopener>http://eprints.lse.ac.uk/90753/</a></p></li><li><p>Pickett, C. (2017). Let&rsquo;s Look at the Big Picture: A System-Level Approach to Assessing Scholarly Merit.
<a href=https://doi.org/10.31234/osf.io/tv6nb target=_blank rel=noopener>https://doi.org/10.31234/osf.io/tv6nb</a></p></li><li><p>Roediger III, H. L. (2016). Varieties of fame in psychology. Perspectives on Psychological Science, 11(6), 882-887.</p></li><li><p>Ruscio, J. (2016). Taking advantage of citation measures of scholarly impact: Hip Hip h Index!. Perspectives on Psychological Science, 11(6), 905-908.</p></li><li><p>Shiota, M. N. (2017). ‚ÄúFame‚Äù is the Problem:Conflation of Visibility With Potential for Long-Term Impact in Psychological Science.
<a href=https://doi.org/10.31234/osf.io/4kwuq target=_blank rel=noopener>https://doi.org/10.31234/osf.io/4kwuq</a></p></li><li><p>Simonton, D. K. (2016). Giving credit where credit‚Äôs due: Why it‚Äôs so hard to do in psychological science. Perspectives on Psychological Science, 11(6), 888-892.</p></li><li><p>Tressoldi, P. E., Giofr√©, D., Sella, F., & Cumming, G. (2013). High impact= high statistical standards? Not necessarily so. PloS one, 8(2), e56180.</p></li><li><p>Sternberg, R. J. (2016). ‚ÄúAm I famous yet?‚Äù Judging scholarly merit in psychological science: An introduction. Perspectives on Psychological Science, 11(6), 877-881.</p></li><li><p>Vazire, S. (2017). Against eminence.https://doi.org/10.31234/osf.io/djbcw</p></li><li><p>Van Dijk, D., Manor, O., & Carey, L. B. (2014). Publication metrics and success on the academic job market. Current Biology, 24(11), R516-R517.</p></li></ul><br></div><div class="tab-pane fade" id=C7S8 role=tabpanel aria-labelledby=C7S8-tab><br><h2 id=types-of-academic-non-academic--alt-academic-positions>Types of academic, non-academic & alt-academic positions</h2><ul><li><p>Gomez, P., Anderson, A. R., & Baciero, A. (2017). Lessons for psychology laboratories from industrial laboratories. Research Ethics, 13(3-4), 155-160.
<a href=https://doi.org/10.1177/1747016117693827 target=_blank rel=noopener>https://doi.org/10.1177/1747016117693827</a></p></li><li><p>Nature. (2019). Postdocs in crisis: science cannot risk losing the next generation. Nature, 580, 160.
<a href=https://doi.org/10.1038/d41586-020-02541-9 target=_blank rel=noopener>https://doi.org/10.1038/d41586-020-02541-9</a></p></li><li><p>Nature. (2019). The mental health of PhD researchers demands urgent attention. Nature, 575, 257-258.
<a href=https://doi.org/10.1038/d41586-019-03489-1 target=_blank rel=noopener>https://doi.org/10.1038/d41586-019-03489-1</a></p></li><li><p>Nature. (2020). Seeking an ‚Äòexit plan‚Äô for leaving academia amid coronavirus worries. Nature 583, 645-646.
<a href=https://doi.org/10.1038/d41586-020-02029-6 target=_blank rel=noopener>https://doi.org/10.1038/d41586-020-02029-6</a>.</p></li></ul><br></div><div class="tab-pane fade" id=C7S9 role=tabpanel aria-labelledby=C7S9-tab><br><h2 id=feminist-thought>Feminist Thought</h2><p><em><strong>It aims to understand the nature of gender inequality. Themes explored include discrimination, objectification, oppression, patriarchy, stereotyping, and aesthetics. It examines women&rsquo;s and men&rsquo;s social roles, experiences, interests, chores, and feminist politics in a variety of fields.</strong></em></p><ul><li><p>Eagly, A. H., Eaton, A., Rose, S. M., Riger, S., & McHugh, M. C. (2012). Feminism and psychology: Analysis of a half-century of research on women and gender. American Psychologist, 67(3), 211-230,
<a href=https://doi.org/10.1037/a0027260 target=_blank rel=noopener>https://doi.org/10.1037/a0027260</a></p></li><li><p>Matsick, J. L., Kruk, M., Oswald, F., & Palmer, L. (2021). Bridging Feminist Psychology and Open Science: Feminist Tools and Shared Values Inform Best Practices for Science Reform. Psychology of Women Quarterly,
<a href=https://doi.org/10.1177/03616843211026564 target=_blank rel=noopener>https://doi.org/10.1177/03616843211026564</a></p></li><li><p>Lazard, L., & McAvoy, J. (2020). Doing reflexivity in psychological research: What‚Äôs the point? What‚Äôs the practice?. Qualitative research in psychology, 17(2), 159-177
<a href=https://doi.org/10.1080/14780887.2017.1400144 target=_blank rel=noopener>https://doi.org/10.1080/14780887.2017.1400144</a></p></li><li><p>Macleod, C. I., Capdevila, R., Marecek, J., Braun, V., Gavey, N., & Wilkinson, S. (2021). Celebrating 30 years of Feminism & Psychology. Feminism & Psychology, 31(3), 313-325.
<a href=https://doi.org/10.1177/09593535211027457 target=_blank rel=noopener>https://doi.org/10.1177/09593535211027457</a></p></li><li><p>Crawford, M., & Marecek, J. (1989). Feminist theory, feminist psychology: A bibliography of epistemology, critical analysis, and applications. Psychology of Women Quarterly, 13(4), 477-491.
<a href=https://doi.org/10.1111/j.1471-6402.1989.tb01015.x target=_blank rel=noopener>https://doi.org/10.1111/j.1471-6402.1989.tb01015.x</a></p></li><li><p>Marecek, J. (2016). Invited reflection: Intersectionality theory and feminist psychology. Psychology of Women Quarterly, 40(2), 177-181.
<a href=https://doi.org/10.1177/0361684316641090 target=_blank rel=noopener>https://doi.org/10.1177/0361684316641090</a></p></li><li><p>OpenSexism Archives on Open Science
<a href=https://opensexism.wordpress.com/tag/open-science/ target=_blank rel=noopener>https://opensexism.wordpress.com/tag/open-science/</a></p></li></ul><br></div></div></div></div></div></div></section><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin=anonymous title=mermaid></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js integrity="sha512-7t8APmYpzEsZP7CYoA7RfMPV9Bb+PJHa9x2WiUnDXZx3XHveuyWUtvNOexhkierl5flZ3tr92dP1mMS+SGlD+A==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin=anonymous></script><script>const code_highlighting=!0</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",talk:"Talks",slides:"Slides"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/academic.min.5367584a2dab5698b5d631d722b877ef.js></script><div class=container><footer class=site-footer><p class=powered-by>¬© 2024 - FORRT > Framework for Open and Reproducible Research Training</p><p class="powered-by copyright-license-text">Except where otherwise noted, content on this site is licensed under a <a href=https://creativecommons.org/licenses/by-nc-sa/4.0 rel="noopener noreferrer" target=_blank>CC BY NC SA 4.0</a> license</p><div class="d-flex justify-content-center powered-by footer-license-icons pb-2"><a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png></a></div><p class=powered-by>This website is published using two great open source tools:
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a> & the
    <a href=https://hugoblox.com/ target=_blank rel=noopener>Academic theme.</a>
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div></body></html>