<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.8.0"><meta name=description content><link rel=alternate hreflang=en-us href=https://forrt.org/clusters/><meta name=theme-color content="#004055"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Century Schoolbook:400,700%7CCentury Schoolbook:400,400italic,700%7CCentury Schoolbook&display=swap" type=text/css><link rel=stylesheet href=/css/academic.css><script>(function(b,d,e,a,g){b[a]=b[a]||[],b[a].push({'gtm.start':(new Date).getTime(),event:'gtm.js'});var f=d.getElementsByTagName(e)[0],c=d.createElement(e),h=a!='dataLayer'?'&l='+a:'';c.async=!0,c.src='https://www.googletagmanager.com/gtm.js?id='+g+h,f.parentNode.insertBefore(c,f)})(window,document,'script','dataLayer','G-GY39NFKC89')</script><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_hu157d5c18119aadbeae18d128d49811b3_36734_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/images/icon_hu157d5c18119aadbeae18d128d49811b3_36734_192x192_fill_lanczos_center_2.png><link rel=canonical href=https://forrt.org/clusters/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@FORRTproject"><meta property="twitter:creator" content="@FORRTproject"><meta property="og:site_name" content="FORRT - Framework for Open and Reproducible Research Training"><meta property="og:url" content="https://forrt.org/clusters/"><meta property="og:title" content><meta property="og:description" content><meta property="og:image" content="https://forrt.org/img/FORRT_banner.svg"><meta property="twitter:image" content="https://forrt.org/img/FORRT_banner.svg"><meta property="og:locale" content="en-us"><meta property="article:modified_time" content="2020-09-20T23:49:04-04:00"><script src=https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin=anonymous><script>window.addEventListener("load",function(){window.cookieconsent.initialise({palette:{popup:{background:"#004055",text:"#fefdf6"},button:{background:"#fefdf6",text:"#004055"}},theme:"classic",content:{message:"This website uses cookies to ensure you get the best experience on our website.",dismiss:"Got it!",link:"Learn more",href:"/tag/privacy/"}})})</script><title>| FORRT - Framework for Open and Reproducible Research Training</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main><script>const isSiteThemeDark=!1</script><script src=/js/load-theme.js></script><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><label for=search-query class=sr-only>Search:</label>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/images/logo.svg alt="FORRT - Framework for Open and Reproducible Research Training Logo. Link to homepage"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/images/logo.svg alt="FORRT - Framework for Open and Reproducible Research Training"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-center" id=navbar-content><ul class="navbar-nav d-md-inline-flex font-weight-bold text-uppercase"><li class="nav-item dropdown px-2"><a href=# class="nav-link dropdown-toggle" data-hover=dropdown aria-haspopup=true><span>About FORRT</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/about/us><span>About FORRT</span></a>
<a class=dropdown-item href=/awards><span>Awards</span></a>
<a class=dropdown-item href=/about/get-involved/#calendar><span>Calendar</span></a>
<a class=dropdown-item href=/coc><span>Code of Conduct</span></a>
<a class=dropdown-item href=/about/community><span>Community</span></a>
<a class=dropdown-item href=/contributors><span>Contributors</span></a>
<a class=dropdown-item href=/cv><span>Curriculum Vitae</span></a>
<a class=dropdown-item href=/feedback><span>Feedback</span></a>
<a class=dropdown-item href=/about/get-involved><span>Get Involved</span></a>
<a class=dropdown-item href=/about/mission/><span>Mission & Advocacy</span></a>
<a class=dropdown-item href=/about/partnerships/><span>Partners</span></a>
<a class=dropdown-item href=/about/principles/><span>Principles</span></a>
<a class=dropdown-item href=/talk/><span>Talks</span></a>
<a class=dropdown-item href=/about/teams/><span>Teams</span></a></div></li><li class="nav-item dropdown px-2"><a href=# class="nav-link dropdown-toggle" data-hover=dropdown aria-haspopup=true><span>Educational NEXUS</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/nexus><span>About Educational Nexus</span></a>
<a class=dropdown-item href=/adopting><span>Adopting Principled Education</span></a>
<a class=dropdown-item href=/clusters><span>Clusters</span></a>
<a class=dropdown-item href=/resources><span>Curated Resources</span></a>
<a class=dropdown-item href=/educators-corner><span>Educators' Corner</span></a>
<a class=dropdown-item href=/equityinos><span>Equity in Open Science</span></a>
<a class=dropdown-item href=/glossary><span>Glossary</span></a>
<a class=dropdown-item href=/impact><span>Impact of O&R on students</span></a>
<a class=dropdown-item href=/dei><span>Initiatives Towards Social Justice</span></a>
<a class=dropdown-item href=/lesson-plans><span>Lesson Plans</span></a>
<a class=dropdown-item href=/neurodiversity><span>Neurodiversity</span></a>
<a class=dropdown-item href=/replication-hub><span>Replication Hub</span></a>
<a class=dropdown-item href=/reversals><span>Replications & Reversals</span></a>
<a class=dropdown-item href=/self-assessment><span>Self-Assessment</span></a>
<a class=dropdown-item href=/summaries><span>Summaries</span></a>
<a class=dropdown-item href=/syllabus><span>Syllabus</span></a></div></li><li class="nav-item px-2"><a class=nav-link href=/pedagogies/><span>Pedagogies</span></a></li><li class="nav-item px-2"><a class=nav-link href=/publications/><span>Publications</span></a></li><li class=nav-item><a href=/about/get-involved/ class="nav-link btn btn-primary nav-btn">🚀&nbsp;Get&nbsp;involved!</a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# alt="Opens search bar"><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/forrtproject/forrt alt="Link to FORRT's GitHub repository"><i class="fab fa-github" aria-hidden=true></i></a></li></ul></div></nav><span class="js-widget-page d-none"></span><section id=1-hero class="home-section wg-hero-welcome"><div class=container><div class=row><div class="col-lg-5 col-md-6 order-md-1 text-left text-lg-right mr-auto"><h1 class="hero-title d-inline-block float-lg-left" style="font-family:New Century Schoolbook;line-height:1.25">Framework for<br>Open and<br>Reproducible<br>Research<br>Training</h1></div><div class="my-auto mx-auto col-lg-7 col-md-6 order-md-2 hero-media border-left border-dark"><img width=100% src=/img/FORRT.svg alt="Logo of FORRT is a fort."></div></div></div></section><section id=intro-clusters class="home-section wg-blank" style="padding:60px 0;font-size:1.25rem"><div class=container><div class=row><div class="col-lg-12 text-center"></div></div><div class=row><div class=col-lg-12><h1 id=forrts-clusters>FORRT&rsquo;s Clusters</h1><br><p>In order to teach open and reproducible science effectively, educators need to make sense of almost a decade of literature, across several fields, and be informed about ongoing (and often dynamic) debates. This is a tall ask for most educators. So FORRT sought to develop strategies and propose solutions to mitigate the effects of competing academic interests and help scholars implement open and reproducible science tenets in their teaching and mentoring workflow. In an effort to reduce some of the burden on educators wishing to learn or teach these concepts, FORRT has draw on the expertise of more than 50 experts from its community to provide educators with a comprehensive but straightforward accessible didactic framework. FORRT clusters is a result of a comprehensive literature review guided by <em><strong>educational, pedagogical and didactic considerations</strong></em> aiming at providing a pathway towards the incremental adoption of Open and Reproducible Science tenets into educators/scholars teaching and mentoring. The focus lies not on simply aggregating the literature into bins, but on making sense of existing works, weaving connections where none exist, and providing a sensible learning-oriented Open and Reproducible Science taxonomy. FORRT taxonomy is composed of 7 clusters:</p><ol><li>Reproducibility and replicability knowledge</li><li>Conceptual and statistical knowledge</li><li>Reproducible analyses</li><li>Preregistration</li><li>FAIR data and materials</li><li>Replication research</li><li>Academic life and culture</li></ol><p>We further breakdown each cluster into sub-categories to provide educators/scholars with useful information on the extant of open science scholarship, and how they are connected to one another. The idea behind specifying clusters and sub-clusters it to highlight we have drawn fuzzy boundaries between clusters while allowing for diversification and heterogeneity in how each educator integrates these cluster/sub-clusters with their respective field content. The breakdown of each cluster into sub-categories provides scholars with useful information on the extant of open science scholarship, and how they are connected to one another. To have a look at the sub-clusters within each cluster, please click on the clusters above.</p><p>See below for each cluster, its description, sub-clusters, and associated works geared for teaching. And here&rsquo;s an attempt to visualize FORRT&rsquo;s clusters:</p><br><p><img src=FORRT_Clusters.png alt="FORRT&rsquo;s Clusters" title="FORRT's Clusters"></p><br><h2 id=Syllabus>FORRT&rsquo;s Syllabus</h2><p>Building on the clusters we created a <em><strong>&ldquo;Open and Reproducible Science&rdquo; Syllabus</strong></em>. We hope it can serve as starting point for your class.
<a href=FORRT_O&R_101_Syllabus.pdf>.pdf download</a> or
<a href=https://docs.google.com/document/d/1pfFro5MbwBHzzXTeM_lE1gjFuq7AnnKWSDWkVwOBAtE/edit# target=_blank rel=noopener>editable G-doc version</a>. Check out the
<a href=/syllabus/>FORRT&rsquo;s syllabus page</a>.</p><br></div></div></div></div></section><section id=cluster1 class="home-section wg-blank" style="background-color:#cacfdc;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 1: Reproducibility Crisis and Credibility Revolution</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of foundational knowledge on the emergence of, and importance of, reproducible and open research (i.e., grounding the motivations and theoretical underpinnings of Open and Reproducible Science). Integration with field specific content (i.e., grounded in the history of replicability). There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>History of the reproducibility crisis & credibility revolution.</li><li>Exploratory and confirmatory analyses.</li><li>Questionable research practices and their prevalence.</li><li>Proposed improvement science initiatives on statistics, measurement, teaching, data sharing, code sharing, pre-registration, replication.</li><li>Ongoing debates (e.g., incentives for and against open science).</li><li>Ethical considerations for improved practices.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C1S1-tab data-toggle=tab href=#C1S1 role=tab aria-controls=C1S1 aria-selected=true>History</a></li><li class=nav-item><a class=nav-link id=C1S2-tab data-toggle=tab href=#C1S2 role=tab aria-controls=C1S2 aria-selected=false>Analyses</a></li><li class=nav-item><a class=nav-link id=C1S3-tab data-toggle=tab href=#C1S3 role=tab aria-controls=C1S3 aria-selected=false>QRPs</a></li><li class=nav-item><a class=nav-link id=C1S4-tab data-toggle=tab href=#C1S4 role=tab aria-controls=C1S4 aria-selected=false>Improvements</a></li><li class=nav-item><a class=nav-link id=C1S5-tab data-toggle=tab href=#C1S5 role=tab aria-controls=C1S5 aria-selected=false>Ongoing debates</a></li><li class=nav-item><a class=nav-link id=C1S6-tab data-toggle=tab href=#C1S6 role=tab aria-controls=C1S6 aria-selected=false>Ethics</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C1S1 role=tabpanel aria-labelledby=C1S1-tab><br><h2 id=history-of-the-reproducibility-crisis--credibility-revolution>History of the reproducibility crisis & credibility revolution</h2><ul><li><p>Baker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature News, 533(7604), 452. doi: <a href=https://doi.org/10.1038/533452a>https://doi.org/10.1038/533452a</a></p></li><li><p>Baker, M. (2016). Is there a reproducibility crisis? Nature, 533(7604), 3–5. doi: <a href=https://doi.org/10.1038/d41586-019-00067-3>https://doi.org/10.1038/d41586-019-00067-3</a></p></li><li><p>Chambers, C. (2017). The seven deadly sins of psychology: A manifesto for reforming the culture of scientific practice. Princeton University Press.
<a href=http://dx.doi.org/10.1515/9781400884940>http://dx.doi.org/10.1515/9781400884940</a></p></li><li><p>Crüwell, S., van Doorn, J., Etz, A., Makel, M. C., Moshontz, H., Niebaum, J., … SchulteMecklenbeck, M. (2018, November 16). 7 easy steps to open science: An annotated reading list. <a href=https://doi.org/10.31234/osf.io/cfzyx>https://doi.org/10.31234/osf.io/cfzyx</a></p></li><li><p>Edwards, M. A., & Roy, S. (2016). Academic research in the 21st century: Maintaining scientific integrity in a climate of perverse incentives and hypercompetition. Environmental Engineering Science, 34(1), 51-61. DOI: <a href=https://doi.org/10.1089/ees.2016.0223>https://doi.org/10.1089/ees.2016.0223</a></p></li><li><p>Merton, R., K. (1968). The Matthew effect in science. Science, 159(3810), 56-63.
10.1126/science.159.3810.56</p></li><li><p>Merton, R., K. (1988). The Matthew Effect in Science, II: Cumulative Advantage and the Symbolism of Intellectual Property. ISIS, 79(4), 606-623. 10.1086/354848</p></li><li><p>Munafo, M. R., et al. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 0021. DOI: 10.0138/s41562-016-0021</p></li><li><p>Vazire, S. (2018). Implications of the Credibility Revolution for Productivity, Creativity, and Progress. Perspectives on Psychological Science, 13(4), 411-417.
<a href=https://doi.org/10.1177/1745691617751884>https://doi.org/10.1177/1745691617751884</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S2 role=tabpanel aria-labelledby=C1S2-tab><br><h2 id=exploratory-and-confirmatory-analyses>Exploratory and confirmatory analyses</h2><p><em><strong>Confirmatory analyses refer to tests of hypotheses that are formulated prior to data collection. Exploratory analyses refer to everything else.</strong></em></p><ul><li><p>Chambers, C. (2017). The seven deadly sins of psychology: A manifesto for reforming the culture of scientific practice. Princeton University Press.
<a href=http://dx.doi.org/10.1515/9781400884940>http://dx.doi.org/10.1515/9781400884940</a></p></li><li><p>Lin, W., & Green, D. P. (2016). Standard operating procedures: A safety net for pre-analysis plans. PS: Political Science & Politics, 49(3), 495-500.</p></li><li><p>Wagenmakers, E.-J., Wetzels, R., Borsboom, D., van der Mass, H. L. J., & Kievit, R. A. (2012). An agenda for purely confirmatory research. Perspectives on Psychological Science, 7(6), 632–638. doi:10.1177/1745691612463078</p></li><li><p>Wagenmakers , E.-J., Dutilh, G., & Sarafoglou, A. (2018). The Creativity-Verification Cycle in Psychological Science: New Methods to Combat Old Idols. Perspectives on Psychological Science, 13(4), 418–427. <a href=https://doi.org/10.1177/1745691618771357>https://doi.org/10.1177/1745691618771357</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S3 role=tabpanel aria-labelledby=C1S3-tab><br><h2 id=questionable-research-practices-and-their-prevalence>Questionable research practices and their prevalence</h2><p><em><strong>The ways in which researchers engage in behaviors and decision-making that increase the probability of their (consciously or unconsciously) desired result.</strong></em></p><ul><li><p>Gelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time. Unpublished manuscript. <a href=http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf>http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf</a></p></li><li><p>John, L. K., Loewenstein, G., & Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth telling. Psychological Science, 23(5), 524-532. <a href=https://doi.org/10.1177/0956797611430953>https://doi.org/10.1177/0956797611430953</a></p></li><li><p>Simmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359–1366.https://doi.org/10.1177/0956797611417632</p></li><li><p>Smaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.https://doi.org/10.1098/rsos.160384</p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R. C., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in psychology, 7.</p></li></ul><br></div><div class="tab-pane fade" id=C1S4 role=tabpanel aria-labelledby=C1S4-tab><br><h2 id=proposed-improvement-science-initiatives-on-statistics-measurement-teaching-data-sharing-code-sharing-pre-registration-replication>Proposed improvement science initiatives on statistics, measurement, teaching, data sharing, code sharing, pre-registration, replication</h2><p><em><strong>Published checklists and other resources that can be used to shift behavior more toward improved practices.</strong></em></p><ul><li><p>Crüwell, S., van Doorn, J., Etz, A., Makel, M. C., Moshontz, H., Niebaum, J., … SchulteMecklenbeck, M. (2018, November 16). 7 easy steps to open science: An annotated reading list. <a href=https://doi.org/10.31234/osf.io/cfzyx>https://doi.org/10.31234/osf.io/cfzyx</a></p></li><li><p>Lindsay (2020) Seven steps toward transparency and replicability in psychological science. Canadian Psychology/Psychologie canadienne.</p></li><li><p>Ioannidis, J. P., Munafo, M. R., Fusar-Poli, P., Nosek, B. A., & David, S. P. (2014). Publication and other reporting biases in cognitive sciences: detection, prevalence, and prevention. Trends in cognitive sciences, 18(5), 235-241.</p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., … Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443–490. <a href=https://doi.org/10.1177/2515245918810225>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Munafo, M. R., et al. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 0021. DOI: 10.0138/s41562-016-0021</p></li><li><p>Peng, R. (2015). The reproducibility crisis in science: A statistical counterattack. Significance, 12(3). <a href=https://doi.org/10.1111/j.1740-9713.2015.00827.x>https://doi.org/10.1111/j.1740-9713.2015.00827.x</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S5 role=tabpanel aria-labelledby=C1S5-tab><br><h2 id=ongoing-debates-eg-incentives-for-and-against-open-science>Ongoing debates (e.g., incentives for and against open science)</h2><ul><li><p>Bahlai et al. (2019). Open science isn&rsquo;t always open to all scientists. American Scientist, 107(2), 78. DOI: <a href=https://doi.org/10.1511/2019.107.2.78>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Chen, X., Dallmeier-Tiessen, S., Dasler, R., Feger, S., Fokianos, P., Gonzalez, J. B., &mldr; & Rodriguez, D. R. et al. (2019). Open is not enough. Nature : Physics, 15 (2), 113-119. <a href=https://doi.org/10.1038/s41567-018-0342-2>https://doi.org/10.1038/s41567-018-0342-2</a></p></li><li><p>Drummond, C. (2018).; Reproducible research: a minority opinion. Journal of Experimental & Theoretical Artificial Intelligence, 30(1), 1-11. <a href=https://doi.org/10.1080/0952813X.2017.1413140>https://doi.org/10.1080/0952813X.2017.1413140</a></p></li><li><p>Fanelli, D. (2018). Opinion: Is science really facing a reproducibility crisis, and do we need it to? Proceedings of the National Academy of Sciences, 115(11), 2628-2631. <a href=https://doi.org/10.1073/pnas.1708272114>https://doi.org/10.1073/pnas.1708272114</a></p></li><li><p>Fanelli, D., & Ioannidis, J. P. (2013). US studies may overestimate effect sizes in softer research. Proceedings of the National Academy of Sciences, 110(37), 15031-15036. <a href=https://doi.org/10.1073/pnas.1302997110>https://doi.org/10.1073/pnas.1302997110</a></p></li><li><p>Fell, M. J. (2019). The economic impacts of open science: A rapid evidence assessment. Publications, 7(3), 46. <a href=https://doi.org/10.3390/publications7030046>https://doi.org/10.3390/publications7030046</a></p></li><li><p>Pashler, H., & Harris, C. R. (2012). Is the replicability crisis overblown? Three arguments examined. Perspectives on Psychological Science, 7, 531‑536. <a href=https://doi.org/10.1177/1745691612463401>https://doi.org/10.1177/1745691612463401</a></p></li></ul><br></div><div class="tab-pane fade" id=C1S6 role=tabpanel aria-labelledby=C1S6-tab><br><h2 id=ethical-considerations-for-improved-practices>Ethical considerations for improved practices</h2><ul><li><p>Brabeck, M. M. (2021). Open science and feminist ethics: Promises and challenges of open access. Psychology of Women Quarterly, 45(4), 457-474. <a href=https://doi.org/10.1177/03616843211030926>https://doi.org/10.1177/03616843211030926</a></p></li><li><p>Bol, T., de Vaan, M., & van de Rijt, A. (2018). The Matthew effect in science funding. Proceedings of the National Academy of Sciences, 115(19), 4887-4890. <a href=https://doi.org/10.1073/pnas.1719557115>https://doi.org/10.1073/pnas.1719557115</a></p></li><li><p>Chopik, W. J., Bremner, R. H., Defever, A. M., & Keller, V. N. (2018). How (and whether) to teach undergraduates about the replication crisis in psychological science. Teaching of Psychology, 45(2), 158–163. <a href=https://doi.org/10.1177/0098628318762900>https://doi.org/10.1177/0098628318762900</a></p></li><li><p>Edwards, M. A., & Roy, S. (2016). Academic research in the 21st century: Maintaining scientific integrity in a climate of perverse incentives and hypercompetition. Environmental Engineering Science, 34(1), 51-61. DOI: <a href=https://doi.org/10.1089/ees.2016.0223>https://doi.org/10.1089/ees.2016.0223</a></p></li><li><p>Fell, M. J. (2019). The economic impacts of open science: A rapid evidence assessment. Publications, 7(3), 46. <a href=https://doi.org/10.3390/publications7030046>https://doi.org/10.3390/publications7030046</a></p></li><li><p>Jones, NL. (2007). A code of ethics for the life sciences. Science and Engineering Ethics, 13, 25-43. DOI:https://doi.org/ 0.1007/s11948-006-0007-x</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster2 class="home-section wg-blank" style="background-color:#eadce6;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 2: Conceptual and Statistical Knowledge</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in fundamental statistics, measurement, and its implications encompassing conceptual knowledge, application, interpretation and communication of statistical analyses. There are 5 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>The logic of null hypothesis testing, p-values, Type I and II errors (and when and why they might happen).</li><li>Limitations and benefits of NHST, Bayesian and Likelihood approaches.</li><li>Effect sizes, Statistical power, Confidence Intervals.</li><li>Research Design, Sample Methods, and its implications for inferences.</li><li>Questionable measurement practices (QMPs), validity and reliability issues.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C2S1-tab data-toggle=tab href=#C2S1 role=tab aria-controls=C2S1 aria-selected=true>NHST</a></li><li class=nav-item><a class=nav-link id=C2S2-tab data-toggle=tab href=#C2S2 role=tab aria-controls=C2S2 aria-selected=false>Approaches</a></li><li class=nav-item><a class=nav-link id=C2S3-tab data-toggle=tab href=#C2S3 role=tab aria-controls=C2S3 aria-selected=false>Effect-sizes & cia</a></li><li class=nav-item><a class=nav-link id=C2S4-tab data-toggle=tab href=#C2S4 role=tab aria-controls=C2S4 aria-selected=false>Research Design</a></li><li class=nav-item><a class=nav-link id=C2S5-tab data-toggle=tab href=#C2S5 role=tab aria-controls=C2S5 aria-selected=false>QMPs</a></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C2S1 role=tabpanel aria-labelledby=C2S1-tab><br><h2 id=the-logic-of-null-hypothesis-testing-p-values-type-i-and-ii-errors-and-when-and-why-they-might-happen>The logic of null hypothesis testing, p-values, Type I and II errors (and when and why they might happen).</h2><ul><li><p>Banerjee, A., Chitnis, UB., Jadhav, SL., Bhawalkar, JS., Chaudhury, S. (2009). Hypothesis testing, type I and type II errors. Industrial Psychiatry Journal, 18(2), 127-131. <a href=https://doi.org/10.1111/j.1740-9713.2015.00827.x>https://doi.org/10.1111/j.1740-9713.2015.00827.x</a></p></li><li><p>Gelman, A., & Carlin, J. (2014). Beyond power calculations: Assessing Type S (sign) and Type M (magnitude) errors. Perspectives on Psychological Science, 9(6), 641-651. doi: 10.1177/1745691614551642</p></li><li><p>Lakens, D. Improving your statistical inferences. Online course. <a href=https://www.coursera.org/learn/statistical-inferences>https://www.coursera.org/learn/statistical-inferences</a></p></li></ul><br></div><div class="tab-pane fade" id=C2S2 role=tabpanel aria-labelledby=C2S2-tab><br><h2 id=limitations-and-benefits-of-nhst-bayesian-and-likelihood-approaches>Limitations and benefits of NHST, Bayesian and Likelihood approaches.</h2><ul><li><p>Cumming, G. (2014). The new statistics: Why and how. Psychological Science, 25(1), 7-29. <a href=https://doi.org/10.1177/0956797613504966>https://doi.org/10.1177/0956797613504966</a></p></li><li><p>Etz, A., Gronau, Q.F., Dablander, F. et al. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin Review, 25, 219–234. <a href=https://doi.org/10.3758/s13423-017-1317-5>https://doi.org/10.3758/s13423-017-1317-5</a></p></li><li><p>Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, p values, confidence intervals, and power: Aa guide to misinterpretations. European Journal of Epidemiology, 31(4), 337–50. <a href=http://doi.org/10.1007/s10654-016-0149-3>http://doi.org/10.1007/s10654-016-0149-3</a></p></li><li><p>Nuzzo, R. (2014). Statistical errors: P values, the ‘gold standard’ of statistical validity, are not as reliable as many scientists assume. Nature, 506(7487), 150-152. doi:10.1038/506150a</p></li><li><p>Wagenmakers , E.-J., Dutilh, G., & Sarafoglou, A. (2018). The Creativity-Verification Cycle in Psychological Science: New Methods to Combat Old Idols. Perspectives on Psychological Science, 13(4), 418–427. <a href=https://doi.org/10.1177/1745691618771357>https://doi.org/10.1177/1745691618771357</a></p></li></ul><br></div><div class="tab-pane fade" id=C2S3 role=tabpanel aria-labelledby=C2S3-tab><br><h2 id=effect-sizes-statistical-power-confidence-intervals>Effect sizes, Statistical power, Confidence Intervals.</h2><ul><li><p>Brysbaert, M. and Stevens, M. (2018). Power analysis and effect size in mixed effects models: A Tutorial. Journal of Cognition, 1(1): 9, pp. 1–20, DOI: <a href=https://doi.org/10.5334/joc.10>https://doi.org/10.5334/joc.10</a></p></li><li><p>Button, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365-376. <a href=https://doi.org/10.1038/nrn3475>https://doi.org/10.1038/nrn3475</a></p></li><li><p>Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, p values, confidence intervals, and power: A guide to misinterpretations. European Journal of Epidemiology, 31(4), 337–50. <a href=http://doi.org/10.1007/s10654-016-0149-3>http://doi.org/10.1007/s10654-016-0149-3</a></p></li><li><p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs. Frontiers in Psychology, 4, 863. 10.3389/fpsyg.2013.00863</p></li><li><p>Pek, J., & Flora, D. B. (2018). Reporting effect sizes in original psychological research: A discussion and tutorial. Psychological Methods, 23(2), 208-225. <a href=http://doi.org/10.1037/met0000126>http://doi.org/10.1037/met0000126</a></p></li><li><p>Perugini, M., Gallucci, M., & Costantini, G. (2014). Safeguard power as a protection against imprecise power estimates. Perspectives on Psychological Science, 9, 319-332.</p></li></ul><br></div><div class="tab-pane fade" id=C2S4 role=tabpanel aria-labelledby=C2S4-tab><br><h2 id=research-design-sample-methods-and-its-implications-for-inferences>Research Design, Sample Methods, and its implications for inferences.</h2><ul><li><p>Gervais et al. (2015). A powerful nudge? Presenting calculable consequences of underpowered research shifts incentives towards adequately powered designs. Social Psychological and Personality Science, 6, 847-854. <a href=https://doi.org/10.1177/1948550615584199>https://doi.org/10.1177/1948550615584199</a></p></li><li><p>Perugini, M., Gallucci, M., & Costantini, G. (2014). Safeguard power as a protection against imprecise power estimates. Perspectives on Psychological Science, 9, 319-332.</p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.doi: 10.3389/fpsyg.2016.01832</p></li></ul><br></div><div class="tab-pane fade" id=C2S5 role=tabpanel aria-labelledby=C2S5-tab><br><h2 id=questionable-measurement-practices-qmps-validity-and-reliability-issues>Questionable measurement practices (QMPs), validity and reliability issues.</h2><ul><li><p>Flake, J. K., & Fried, E. I. (2019, January 17). Measurement schmeasurement: Questionable measurement practices and how to avoid them. <a href=https://doi.org/10.31234/osf.io/hs7wm>https://doi.org/10.31234/osf.io/hs7wm</a></p></li><li><p>Flake, J. K., Pek, J., & Hehman, E. (2017). Construct validation in social and personality research: Current practice and recommendations. Social Psychological and Personality Science, 8(4), 370–378. <a href=https://doi.org/10.1177/1948550617693063>https://doi.org/10.1177/1948550617693063</a></p></li><li><p>Hussey, I., & Hughes, S. (2018, November 19). Hidden invalidity among fifteen commonly used measures in social and personality psychology. <a href=https://doi.org/10.31234/osf.io/7rbfp>https://doi.org/10.31234/osf.io/7rbfp</a></p></li><li><p>Rodebaugh, T. L., Scullin, R. B., Langer, J. K., Dixon, D. J., Huppert, J. D., Bernstein, A., . . . Lenze, E. J. (2016). Unreliability as a threat to understanding psychopathology: The cautionary tale of attentional bias. Journal of Abnormal Psychology, 125(6), 840-851. <a href=http://dx.doi.org/10.1037/abn0000184>http://dx.doi.org/10.1037/abn0000184</a></p></li></ul><br></div></div></div></div></div></div></section><section id=cluster3 class="home-section wg-blank" style="background-color:#dad5dd;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 3: Reproducible analyses</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of the <em>how-to</em> basics of reproducible reports and analyses. It requires students to move towards transparent and scripted analysis practices. There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Strengths of reproducible pipelines.</li><li>Scripted analyses compared with GUI.</li><li>Data wrangling.</li><li>Programming reproducible data analyses.</li><li>Open source and free software.</li><li>Tools to check yourself and others.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C3S1-tab data-toggle=tab href=#C3S1 role=tab aria-controls=C3S1 aria-selected=true>Reproducible pipelines</a></li><li class=nav-item><a class=nav-link id=C3S2-tab data-toggle=tab href=#C3S2 role=tab aria-controls=C3S2 aria-selected=false>Scripted Analyses</a></li><li class=nav-item><a class=nav-link id=C3S3-tab data-toggle=tab href=#C3S3 role=tab aria-controls=C3S3 aria-selected=false>Data wrangling</a></li><li class=nav-item><a class=nav-link id=C3S4-tab data-toggle=tab href=#C3S4 role=tab aria-controls=C3S4 aria-selected=false>Reproducible Analyses</a></li><li class=nav-item><a class=nav-link id=C3S5-tab data-toggle=tab href=#C3S5 role=tab aria-controls=C3S5 aria-selected=false>Open source</a></li><li class=nav-item><a class=nav-link id=C3S6-tab data-toggle=tab href=#C3S6 role=tab aria-controls=C3S6 aria-selected=false>Tools</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C3S1 role=tabpanel aria-labelledby=C3S1-tab><br><h2 id=strengths-of-reproducible-pipelines>Strengths of reproducible pipelines.</h2><p><em><strong>Automating data analysis to make the process easier</strong></em></p><ul><li><p>Gandrud, C. (2016). Reproducible research with R and R Sstudio. New York; CRC Press</p></li><li><p>Wilson G, Bryan J, Cranston K, Kitzes J, Nederbragt L, et al. (2017) Good enough practices in scientific computing. PLOS Computational Biology 13(6): e1005510. <a href=https://doi.org/10.1371/journal.pcbi.1005510>https://doi.org/10.1371/journal.pcbi.1005510</a></p></li><li><p><a href=https://datacarpentry.org/rr-workshop/ target=_blank rel=noopener>Reproducible Research in R Workshop Overview</a></p></li><li><p><a href=https://github.com/MonashDataFluency target=_blank rel=noopener>Monash&rsquo;s</a> Data Fluency
<a href=https://monashdatafluency.github.io/r-rep-res/index.html target=_blank rel=noopener>Reproducible Research in R (RRR)</a></p></li><li><p><a href=https://www.projecttier.org target=_blank rel=noopener>ProjectTier</a></p></li></ul><br></div><div class="tab-pane fade" id=C3S2 role=tabpanel aria-labelledby=C3S2-tab><br><h2 id=scripted-analyses-compared-with-gui>Scripted analyses compared with GUI.</h2><p><em><strong>Writing analyses in programming language compared to performing them with a point-and-click menu.</strong></em></p><ul><li>Gandrud, C. (2016). Reproducible research with R and R Sstudio. New York; CRC Press</li></ul><br></div><div class="tab-pane fade" id=C3S3 role=tabpanel aria-labelledby=C3S3-tab><br><h2 id=data-wrangling>Data wrangling</h2><p><em><strong>Processing and restructuring data so that it is more useful for analyse.</strong></em></p><p>Nick Fox&rsquo;s
<a href="https://www.youtube.com/playlist?list=PLmvNihjFsoM5hpQdqoI7onL4oXDSQ0ym8" target=_blank rel=noopener>Writing Reproducible Scientific Papers in R</a></p><p>PsuTeachR&rsquo;s
<a href=https://psyteachr.github.io/msc-data-skills/ target=_blank rel=noopener>Data Skills for Reproducible Science</a></p><br></div><div class="tab-pane fade" id=C3S4 role=tabpanel aria-labelledby=C3S4-tab><br><h2 id=programming-reproducible-data-analyses>Programming reproducible data analyses</h2><p><em><strong>Making sure anyone can reproduce analyses through things like well-commented scripts, writing codebooks, etc.</strong></em></p><ul><li><p>Gandrud, C. (2016). Reproducible research with R and R Sstudio. New York; CRC Press</p></li><li><p>Wilson, G., Bryan, J., Cranston, K., Kitzes, J., Nederbragt, L., & Teal, T. K. (2017). Good enough practices in scientific computing. PLoS computational biology, 13(6). e1005510. <a href=https://doi.org/10.1371/journal.pcbi.1005510>https://doi.org/10.1371/journal.pcbi.1005510</a></p></li><li><p><a href=https://sites.trinity.edu/osl/ target=_blank rel=noopener>Open Stats Lab</a></p></li><li><p><a href=https://software-carpentry.org/ target=_blank rel=noopener>Software Carpentry</a></p></li><li><p><a href=https://learningstatisticswithr.com/book/ target=_blank rel=noopener>Learning statistics with R: A tutorial for psychology students and other beginners</a></p></li></ul><br></div><div class="tab-pane fade" id=C3S5 role=tabpanel aria-labelledby=C3S5-tab><br><h2 id=open-source-and-free-software>Open source and free software.</h2><ul><li>Chao, L. (2009). Utilizing open source tools for online teaching and learning Information Science. Hershey, PA: Information Science Reference.</li></ul><br></div><div class="tab-pane fade" id=C3S6 role=tabpanel aria-labelledby=C3S6-tab><br><h2 id=tools-to-check-yourself-and-others>Tools to check yourself and others</h2><p><em><strong>Includes tools such as statcheck.io, GRIM, and SPRITE</strong></em></p><ul><li><p>Brown, N. J., & Heathers, J. A. (2016). The GRIM test: A simple technique detects numerous anomalies in the reporting of results in psychology. Social Psychological and Personality Science, 1948550616673876. <a href=http://journals.sagepub.com/doi/pdf/10.1177/1948550616673876>http://journals.sagepub.com/doi/pdf/10.1177/1948550616673876</a></p></li><li><p>Nuijten, M. B., Van Assen, M. A. L. M., Hartgerink, C. H. J., Epskamp, S., & Wicherts, J. M. (2017). The validity of the tool “statcheck” in discovering statistical reporting inconsistencies. Preprint retrieved from <a href=https://psyarxiv.com/tcxaj/>https://psyarxiv.com/tcxaj/</a>.</p></li><li><p>van der Zee, T., Anaya, J., & Brown, N. J. (2017). Statistical heartburn: An attempt to digest four pizza publications from the Cornell Food and Brand Lab. BMC Nutrition, 3(1), 54. DOI 10.1186/s40795-017-0167-x</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster4 class="home-section wg-blank" style="background-color:#bdc5ca;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 4: Open (FAIR) data and materials analyses</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in open (FAIR) data and materials. It requires students to learn about FAIR data (and education materials) principles: findability, accessibility, interoperability, and reusability; engage with reasons to share data, the initiatives designed to increase scientific openness; as well as ethical considerations and consequences of open (FAIR) data practices. There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Publication models.</li><li>Reasons to share; for science, and for one’s own practices.</li><li>Repositories such as OSF, FigShare, GitHub, Zenodo.</li><li>Accessing or sharing others data, code, and materials.</li><li>Ethical considerations.</li><li>Examples and consequences of accessing un/open data.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C4S1-tab data-toggle=tab href=#C4S1 role=tab aria-controls=C4S1 aria-selected=true>Publication models</a></li><li class=nav-item><a class=nav-link id=C4S2-tab data-toggle=tab href=#C4S2 role=tab aria-controls=C4S2 aria-selected=false>Why?</a></li><li class=nav-item><a class=nav-link id=C4S3-tab data-toggle=tab href=#C4S3 role=tab aria-controls=C4S3 aria-selected=false>Repositories</a></li><li class=nav-item><a class=nav-link id=C4S4-tab data-toggle=tab href=#C4S4 role=tab aria-controls=C4S4 aria-selected=false>Access</a></li><li class=nav-item><a class=nav-link id=C4S5-tab data-toggle=tab href=#C4S5 role=tab aria-controls=C4S5 aria-selected=false>Ethics</a></li><li class=nav-item><a class=nav-link id=C4S6-tab data-toggle=tab href=#C4S6 role=tab aria-controls=C4S6 aria-selected=false>Examples</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C4S1 role=tabpanel aria-labelledby=C4S1-tab><br><h2 id=publication-models>Publication models</h2><p><em><strong>Traditional publication models, open access models, preprints, etc.</strong></em></p><ul><li><p>Hardwicke, T. E., Mathur, M. B., MacDonald, K., Nilsonne, G., Banks, G. C., Kidwell, M. C., &mldr; & Lenne, R. L. (2018). Data availability, reusability, and analytic reproducibility: Evaluating the impact of a mandatory open data policy at the journal Cognition. Royal Society Open Science, 5(8), 180448. <a href=http://dx.doi.org/10.1098/rsos.180448>http://dx.doi.org/10.1098/rsos.180448</a></p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., … Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443–490. <a href=https://doi.org/10.1177/2515245918810225>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahník, Š., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A “many labs” replication project. Social Psychology, 45, 142–152. <a href=https://doi.org/10.1027/1864-9335/a000178>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062–1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Siler, K., Haustein, S., Smith, E., Larivière, V., & Alperin, J. P. (2018). Authorial and institutional stratification in open access publishing: the case of global health research. PeerJ, 6, e4269. doi:10.7717/peerj.4269</p></li><li><p>Tennant, J. P., Waldner, F., Jacques, D. C., Masuzzo, P., Collister, L. B., & Hartgerink, C. H. (2016). The academic, economic and societal impacts of Open Access: an evidence-based review. F1000Research, 5, 632. doi:10.12688/f1000research.8460.3</p></li></ul><br></div><div class="tab-pane fade" id=C4S2 role=tabpanel aria-labelledby=C4S2-tab><br><h2 id=reasons-to-share-for-science-and-for-ones-own-practices>Reasons to share; for science, and for one’s own practices</h2><ul><li><p>Colavizza, G., Hrynaszkiewicz, I., Staden, I., Whitaker, K., & McGillivray, B. (2020). The citation advantage of linking publications to research data. PloS One, 15(4), e0230416.</p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., … Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443–490. <a href=https://doi.org/10.1177/2515245918810225>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahník, Š., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A “many labs” replication project. Social Psychology, 45, 142–152. <a href=https://doi.org/10.1027/1864-9335/a000178>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Levenstein, M. C., & Lyle, J. A. (2018). Data: Sharing Is Caring. Advances in Methods and Practices in Psychological Science, 1(1), 95–103. <a href=https://doi.org/10.1177/2515245918758319>https://doi.org/10.1177/2515245918758319</a></p></li><li><p>Piwowar, H.A., & Vision, T.J. (2013). Data reuse and the open data citation advantage. PeerJ, 1, e175 <a href=https://doi.org/10.7717/peerj.175>https://doi.org/10.7717/peerj.175</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062–1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Stodden, V. C. (2011). Trust your science? Open your data and code. Amstat News, 409, 21-22.</p></li><li><p>Tennant, J. P., Waldner, F., Jacques, D. C., Masuzzo, P., Collister, L. B., & Hartgerink, C. H. (2016). The academic, economic and societal impacts of Open Access: an evidence-based review. F1000Research, 5, 632. doi:10.12688/f1000research.8460.3</p></li></ul><br></div><div class="tab-pane fade" id=C4S3 role=tabpanel aria-labelledby=C4S3-tab><br><h2 id=repositories-such-as-osf-figshare-github-zenodo>Repositories such as OSF, FigShare, GitHub, Zenodo</h2><ul><li><p>Gilmore, R. O., Kennedy, J. L., & Adolph, K. E. (2018). Practical solutions for sharing data and materials from psychological research. Advances in Methods and Practices in Psychological Science, 1(1), 121–130. <a href=https://doi.org/10.1177/2515245917746500>https://doi.org/10.1177/2515245917746500</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062–1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Soderberg, C. K. (2018). Using OSF to Share Data: A Step-by-Step Guide. Advances in Methods and Practices in Psychological Science, 1(1), 115–120. <a href=https://doi.org/10.1177/2515245918757689>https://doi.org/10.1177/2515245918757689</a></p></li><li><p><a href=osf.io>osf.io</a></p></li><li><p><a href=figshare.com>figshare.com</a></p></li><li><p><a href=github.com>github.com</a></p></li><li><p><a href=http://zenodo.org/ target=_blank rel=noopener>zenodo.org</a></p></li></ul><br></div><div class="tab-pane fade" id=C4S4 role=tabpanel aria-labelledby=C4S4-tab><br><h2 id=accessing-or-sharing-others-data-code-and-materials>Accessing or sharing others data, code, and materials</h2><ul><li><p>Joel, S., Eastwick, P. W., & Finkel, E. J. (2018). Open sharing of data on close relationships and other sensitive social psychological topics: Challenges, tools, and future directions. Advances in Methods and Practices in Psychological Science, 1(1), 86–94. <a href=https://doi.org/10.1177/2515245917744281>https://doi.org/10.1177/2515245917744281</a></p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., … Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443–490. <a href=https://doi.org/10.1177/2515245918810225>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahník, Š., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A “many labs” replication project. Social Psychology, 45, 142–152. <a href=https://doi.org/10.1027/1864-9335/a000178>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Piwowar, H.A., & Vision, T.J. (2013). Data reuse and the open data citation advantage. PeerJ, 1, e175 <a href=https://doi.org/10.7717/peerj.175>https://doi.org/10.7717/peerj.175</a></p></li><li><p>Wicherts, J. M., Borsboom, D., Kats, J., & Molenaar, D. (2006). The poor availability of psychological research data for reanalysis. American Psychologist, 61(7), 726–728. <a href=https://doi.org/10.1037/0003-066X.61.7.726>https://doi.org/10.1037/0003-066X.61.7.726</a></p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.</p></li></ul><br></div><div class="tab-pane fade" id=C4S5 role=tabpanel aria-labelledby=C4S5-tab><br><h2 id=ethical-considerations>Ethical considerations</h2><ul><li><p>Hand, D. J. (2018). Aspects of data ethics in a changing world: Where are we now? Big Data, 6(3), :176–190. doi: <a href=https://doi.org/10.1089/big.2018.0083>https://doi.org/10.1089/big.2018.0083</a></p></li><li><p>O’Callaghan, E., & Douglas, H. M. (2021). #MeToo Online Disclosures: A Survivor-Informed Approach to Open Science Practices and Ethical Use of Social Media Data. Psychology of Women Quarterly, 45(4), 505–525. <a href=https://doi.org/10.1177/03616843211039175>https://doi.org/10.1177/03616843211039175</a></p></li><li><p>Ross, M. W., Iguchi, M. Y., & Panicker, S. (2018). Ethical aspects of data sharing and research participant protections. American Psychologist, 73(2), 138-145. <a href=http://dx.doi.org/10.1037/amp0000240>http://dx.doi.org/10.1037/amp0000240</a></p></li><li><p>Siler, K., Haustein, S., Smith, E., Larivière, V., & Alperin, J. P. (2018). Authorial and institutional stratification in open access publishing: the case of global health research. PeerJ, 6, e4269. doi:10.7717/peerj.4269</p></li><li><p>Walsh, C. G., Xia, W., Li, M., Denny, J. C., Harris, P. A., & Malin, B. A. (2018). Enabling open-science initiatives in clinical psychology and psychiatry without sacrificing patients’ privacy: Current practices and future challenges. Advances in Methods and Practices in Psychological Science, 1(1), 104–114. <a href=https://doi.org/10.1177/2515245917749652>https://doi.org/10.1177/2515245917749652</a></p></li></ul><br></div><div class="tab-pane fade" id=C4S6 role=tabpanel aria-labelledby=C4S6-tab><br><h2 id=examples-and-consequences-of-accessing-unopen-data>Examples and consequences of accessing un/open data</h2><ul><li><p>Houtkoop, B. L., Chambers, C., Macleod, M., Bishop, D. V. M., Nichols, T. E., & Wagenmakers, E.-J. (2018). Data sharing in psychology: A survey on barriers and preconditions. Advances in Methods and Practices in Psychological Science, 1(1), 70–85. <a href=https://doi.org/10.1177/2515245917751886>https://doi.org/10.1177/2515245917751886</a></p></li><li><p>Peng, R. (2015). The reproducibility crisis in science: A statistical counterattack. Significance, 12(3). <a href=https://doi.org/10.1111/j.1740-9713.2015.00827.x>https://doi.org/10.1111/j.1740-9713.2015.00827.x</a></p></li><li><p>Rouder, J. N. (2016). The what, why, and how of born open data. Behavior Research Methods, 48, 1062–1069. doi:10.3758/s13428-015-0630-z</p></li><li><p>Walsh, C. G., Xia, W., Li, M., Denny, J. C., Harris, P. A., & Malin, B. A. (2018). Enabling open-science initiatives in clinical psychology and psychiatry without sacrificing patients’ privacy: Current practices and future challenges. Advances in Methods and Practices in Psychological Science, 1(1), 104–114. <a href=https://doi.org/10.1177/2515245917749652>https://doi.org/10.1177/2515245917749652</a></p></li><li><p>Wicherts, J. M., Borsboom, D., Kats, J., & Molenaar, D. (2006). The poor availability of psychological research data for reanalysis. American Psychologist, 61(7), 726–728. <a href=https://doi.org/10.1037/0003-066X.61.7.726>https://doi.org/10.1037/0003-066X.61.7.726</a></p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster5 class="home-section wg-blank" style="background-color:#b6cac8;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 5: Preregistration</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Preregistration entails laying out a complete methodology and analysis before a study has been undertaken. This facilitates transparency and removes several potential QRPs. When teaching, students should attain knowledge regarding what a pre-registration entails, why it is important to remove potential QRPs and how to address deviations from preregistered plans.
There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Purpose of preregistration.</li><li>Preregistration and registered reports - strengths and differences.</li><li>When can you preregister? Can you pre-register secondary data?</li><li>Understanding the types of preregistration and writing one.</li><li>Comparing a preregistration to a final study manuscript.</li><li>Conducting a preregistered study.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C5S1-tab data-toggle=tab href=#C5S1 role=tab aria-controls=C5S1 aria-selected=true>Purpose</a></li><li class=nav-item><a class=nav-link id=C5S2-tab data-toggle=tab href=#C5S2 role=tab aria-controls=C5S2 aria-selected=false>Registered Reports</a></li><li class=nav-item><a class=nav-link id=C5S3-tab data-toggle=tab href=#C5S3 role=tab aria-controls=C5S3 aria-selected=false>Secondary data</a></li><li class=nav-item><a class=nav-link id=C5S4-tab data-toggle=tab href=#C5S4 role=tab aria-controls=C5S4 aria-selected=false>Types & How-to</a></li><li class=nav-item><a class=nav-link id=C5S5-tab data-toggle=tab href=#C5S5 role=tab aria-controls=C5S5 aria-selected=false>Comparing</a></li><li class=nav-item><a class=nav-link id=C5S6-tab data-toggle=tab href=#C5S6 role=tab aria-controls=C5S6 aria-selected=false>Conducting</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C5S1 role=tabpanel aria-labelledby=C5S1-tab><br><h2 id=purpose-of-preregistration>Purpose of preregistration</h2><p><em><strong>Distinguishing exploratory and confirmatory analyses, transparency measures.</strong></em></p><ul><li><p>Dal-Ré, R., Ioannidis, J. P., Bracken, M. B., Buffler, P. A., Chan, A.-W., Franco, E. L., La Vecchia, C., Weiderpass, E. (2014). Making prospective registration of observational research a reality. Science translational medicine, 6(224), 224cm1. DOI: <a href=https://doi.org/10.1126/scitranslmed.3007513>https://doi.org/10.1126/scitranslmed.3007513</a></p></li><li><p>Nosek, B. A., & Lakens, D. (2014). Registered reports: A method to increase the credibility of published results. Social Psychology, 45, 137–141.</p></li><li><p>Lin, W., & Green, D. P. (2016). Standard operating procedures: A safety net for pre-analysis plans. PS: Political Science & Politics, 49(3), 495-500.</p></li><li><p>Nosek, B. A., Ebersole, C. R., DeHaven, A., & Mellor, D. (2018). The Preregistration Revolution. Proceedings of National Academy Sciences, 115(11), 2600-2606. <a href=https://doi.org/10.1073/pnas.1708274114>https://doi.org/10.1073/pnas.1708274114</a></p></li><li><p>Wicherts, J. M., Veldkamp, C. L., Augusteijn, H. E., Bakker, M., Van Aert, R., & Van Assen, M. A. (2016). Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology, 7, 1832.doi: 10.3389/fpsyg.2016.01832</p></li><li><p>Nuzzo, R. (2015). How scientists fool themselves — and how they can stop. Nature, 526, 182–185.</p></li><li><p>Wagenmakers, E. J., & Dutilh, G. (2016). Seven selfish reasons for preregistration. APS Observer, 29(9).</p></li></ul><br></div><div class="tab-pane fade" id=C5S2 role=tabpanel aria-labelledby=C5S2-tab><br><h2 id=preregistration-and-registered-reports---strengths-and-differences>Preregistration and registered reports - strengths and differences</h2><p>*<strong>OSC, CREP, ManyLabs, etc.</strong></p><ul><li><p>Chambers, C. D. (2013). Registered reports: A new publishing initiative at Cortex. Cortex, 49(3), 609-610. <a href=https://doi.org/10.1016/j.cortex.2012.12.016>https://doi.org/10.1016/j.cortex.2012.12.016</a></p></li><li><p>Chambers, C. D., Feredoes, E., Muthukumaraswamy, S. D., & Etchells, P. (2014). Instead of “playing the game” it is time to change the rules: Registered Reports at AIMS Neuroscience and beyond. AIMS Neuroscience, 1(1), 4–17. DOI: 10.3934/Neuroscience2014.1.4</p></li><li><p>Chambers, C.D., Dienes, Z., McIntosh, R.D., Rotshtein, P., & Willmes, K. (2015). Registered Reports: Realigning incentives in scientific publishing. Cortex, 66, A1-2. DOI: 10.1016/j.cortex.2015.03.022</p></li></ul><br></div><div class="tab-pane fade" id=C5S3 role=tabpanel aria-labelledby=C5S3-tab><br><h2 id=when-can-you-preregister-can-you-pre-register-secondary-data>When can you preregister? Can you pre-register secondary data?</h2><ul><li><p>Chambers, C.D., Dienes, Z., McIntosh, R.D., Rotshtein, P., & Willmes, K. (2015). Registered Reports: Realigning incentives in scientific publishing. Cortex, 66, A1-2. DOI: <a href=https://doi.org/10.1016/j.cortex.2015.03.022>https://doi.org/10.1016/j.cortex.2015.03.022</a></p></li><li><p>Haven, Tamarinde., L. & Van Grootel, Leonie. (2019). Preregistering qualitative research. Accountability in Research, 26(3), 229-244., DOI: <a href=https://doi.org/10.1080/08989621.2019.1580147>https://doi.org/10.1080/08989621.2019.1580147</a></p></li><li><p>Kirtley, O. J., Lafit, G., Achterhof, R., Hiekkaranta, A. P., & Myin-Germeys, I. (2019, April 10). Making the black box transparent: A pre-registration template for studies using Experience Sampling Methods (ESM). <a href=https://doi.org/10.31234/osf.io/seyq7>https://doi.org/10.31234/osf.io/seyq7</a></p></li><li><p>Mertens, G., & Krypotos, A. (2019, February 20). Preregistration of secondary analyses. <a href=https://doi.org/10.31234/osf.io/ph4q7>https://doi.org/10.31234/osf.io/ph4q7</a></p></li></ul><br></div><div class="tab-pane fade" id=C5S4 role=tabpanel aria-labelledby=C5S4-tab><br><h2 id=understanding-the-types-of-preregistration-and-writing-one>Understanding the types of preregistration and writing one.</h2><ul><li><p>Nosek, B. A., Ebersole, C. R., DeHaven, A. C., & Mellor, D. T. (2018). The preregistration revolution. Proceedings of the National Academy of Sciences, 115(11), 2600-2606. <a href=https://doi.org/10.1073/pnas.1708274114>https://doi.org/10.1073/pnas.1708274114</a></p></li><li><p>Mertens, G., & Krypotos, A. (2019, February 20). Preregistration of secondary analyses. <a href=https://doi.org/10.31234/osf.io/ph4q7>https://doi.org/10.31234/osf.io/ph4q7</a></p></li><li><p>COS:
<a href=https://cos.io/prereg/ target=_blank rel=noopener>What is Preregistration?</a></p></li><li><p>COS:
<a href=https://cos.io/blog/10-preregistration-tips/ target=_blank rel=noopener>10 Tips for Making a Great Preregistration</a></p></li><li><p>COS:
<a href=https://www.wiley.com/network/researchers/being-a-peer-reviewer/8-answers-about-registered-reports-research-preregistration-and-why-both-are-important target=_blank rel=noopener>8 Answers About Registered Reports and Research Preregistration</a></p></li></ul><br></div><div class="tab-pane fade" id=C5S5 role=tabpanel aria-labelledby=C5S5-tab><br><h2 id=comparing-a-preregistration-to-a-final-study-manuscript>Comparing a preregistration to a final study manuscript.</h2><ul><li><a href=https://authorservices.wiley.com/Reviewers/journal-reviewers/how-to-perform-a-peer-review/reviewing-registered-reports.html target=_blank rel=noopener>Wiley&rsquo;s Reviewing Registered Reports</a></li></ul><br></div><div class="tab-pane fade" id=C5S6 role=tabpanel aria-labelledby=C5S6-tab><br><h2 id=conducting-a-preregistered-study>Conducting a preregistered study.</h2><ul><li><p>L. Haven, T., & Van Grootel, D. L. (2019). Preregistering qualitative research. Accountability in Research, 26(3), 229-244. <a href=https://doi.org/10.1080/08989621.2019.1580147>https://doi.org/10.1080/08989621.2019.1580147</a></p></li><li><p>Nosek, B. A., Ebersole, C. R., DeHaven, A., & Mellor, D. (2018). The Preregistration Revolution. PNAS, 115(11), 2600-2606. <a href=https://doi.org/10.1073/pnas.1708274114>https://doi.org/10.1073/pnas.1708274114</a></p></li><li><p>COS:
<a href=https://www.cos.io/blog/one-preregistration-rule-them-all target=_blank rel=noopener>One Preregistration to Rule Them All?</a></p></li></ul><br></div></div></div></div></div></div></section><section id=cluster6 class="home-section wg-blank" style="background-color:#bacabd;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 6: Replication research</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in &lsquo;replication research&rsquo;, which takes a variety of forms, each with a different purpose and contribution. Reproducible science requires replication research. When teaching, students should understand the purpose and need of replications in its variety of forms and being able to conduct (and join) replication projects. There are 6 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Purposes of replication attempts - what is a ‘failed’ replication?</li><li>Large scale replication attempts.</li><li>Distinguishing direct and conceptual replications.</li><li>Conducting replication studies; challenges, limitations, and comparisons with the original study.</li><li>Registered Replication Reports (RRR).</li><li>The politics of replicating famous studies.</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C6S1-tab data-toggle=tab href=#C6S1 role=tab aria-controls=C6S1 aria-selected=true>Purpose</a></li><li class=nav-item><a class=nav-link id=C6S2-tab data-toggle=tab href=#C6S2 role=tab aria-controls=C6S2 aria-selected=false>Large Scale</a></li><li class=nav-item><a class=nav-link id=C6S3-tab data-toggle=tab href=#C6S3 role=tab aria-controls=C6S3 aria-selected=false>Direct vs conceptual</a></li><li class=nav-item><a class=nav-link id=C6S4-tab data-toggle=tab href=#C6S4 role=tab aria-controls=C6S4 aria-selected=false>Conducting replications</a></li><li class=nav-item><a class=nav-link id=C6S5-tab data-toggle=tab href=#C6S5 role=tab aria-controls=C6S5 aria-selected=false>RRR</a></li><li class=nav-item><a class=nav-link id=C6S6-tab data-toggle=tab href=#C6S6 role=tab aria-controls=C6S6 aria-selected=false>Politics</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C6S1 role=tabpanel aria-labelledby=C6S1-tab><br><h2 id=purposes-of-replication-attempts---what-is-a-failed-replication>Purposes of replication attempts - what is a ‘failed’ replication?</h2><ul><li><p>Fidler, F., & Wilcox, J. (2018). Reproducibility of scientific results. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Winter 2018). Metaphysics Research Lab, Stanford University. <a href=https://plato.stanford.edu/archives/win2018/entries/scientific-reproducibility/>https://plato.stanford.edu/archives/win2018/entries/scientific-reproducibility/</a></p></li><li><p>Frank, M. C., & Saxe, R. (2012). Teaching replication. Perspectives on Psychological Science, 7(6), 600–604. <a href=https://doi.org/10.1177/1745691612460686>https://doi.org/10.1177/1745691612460686</a></p></li><li><p>García, FM. (2016). Replication and the manufacture of scientific inferences: A formal approach. International Studies Perspectives, 17(4), 408–425. <a href=https://doi.org/10.1093/isp/ekv011>https://doi.org/10.1093/isp/ekv011</a></p></li><li><p>Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J., & Reinero, D. A. (2016). Contextual sensitivity in scientific reproducibility. Proceedings of the National Academy of Sciences, 113(23), 6454-6459. <a href=https://doi.org/10.1073/pnas.1521897113>https://doi.org/10.1073/pnas.1521897113</a></p></li><li><p>Zwaan, R.A., Etz, A., Lucas, R.E, Donnellan, M.B. (2018). Making replication mainstream. Behavior and Brain Sciences, 41, e120. <a href=https://doi.org/10.1017/S0140525X17001972>https://doi.org/10.1017/S0140525X17001972</a></p></li></ul><br></div><div class="tab-pane fade" id=C6S2 role=tabpanel aria-labelledby=C6S2-tab><br><h2 id=large-scale-replication-attempts>Large scale replication attempts</h2><p>*<strong>OSC, CREP, ManyLabs, etc.</strong></p><ul><li><p>Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahník, Š., Bernstein, M. J., et al. (2014). Investigating variation in replicability: A “many labs” replication project. Social Psychology, 45, 142–152. <a href=https://doi.org/10.1027/1864-9335/a000178>https://doi.org/10.1027/1864-9335/a000178</a></p></li><li><p>Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., … Nosek, B. A. (2018). Many Labs 2: Investigating Variation in Replicability Across Samples and Settings. Advances in Methods and Practices in Psychological Science, 1(4), 443–490. <a href=https://doi.org/10.1177/2515245918810225>https://doi.org/10.1177/2515245918810225</a></p></li><li><p>Open Science Collaboration (2012). An open, large-scale, collaborative effort to estimate the reproducibility of psychological science. Perspectives on Psychological Science, 7, 657–660.</p></li><li><p>Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aaC6716. DOI: 10.1126/science.aaC6716</p></li><li><p>Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J., & Reinero, D. A. (2016). Contextual sensitivity in scientific reproducibility. Proceedings of the National Academy of Sciences, 113(23), 6454-6459. <a href=https://doi.org/10.1073/pnas.1521897113>https://doi.org/10.1073/pnas.1521897113</a></p></li><li><p><a href=https://manyprimates.github.io/ target=_blank rel=noopener>ManyPrimates</a></p></li><li><p><a href=https://osf.io/wfc6u/ target=_blank rel=noopener>CREP</a></p></li></ul><br></div><div class="tab-pane fade" id=C6S3 role=tabpanel aria-labelledby=C6S3-tab><br><h2 id=distinguishing-direct-and-conceptual-replications>Distinguishing direct and conceptual replications</h2><p><em><strong>Direct replications use the exact same methods and materials, while conceptual replications test the same concept but with different methods, materials, or both.</strong></em></p><ul><li><p>Kunert, R. (2016). Internal conceptual replications do not increase independent replication success. Psychonomic bulletin & review, 23(5), 1631-1638. <a href=https://doi.org/10.3758/s13423-016-1030-9>https://doi.org/10.3758/s13423-016-1030-9</a></p></li><li><p>Simons, D. J. (2014). The Value of Direct Replication. Perspectives on Psychological Science, 9(1), 76–80. <a href=https://doi.org/10.1177/1745691613514755>https://doi.org/10.1177/1745691613514755</a></p></li><li><p>Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J., & Reinero, D. A. (2016). Contextual sensitivity in scientific reproducibility. Proceedings of the National Academy of Sciences, 113(23), 6454-6459. <a href=https://doi.org/10.1073/pnas.1521897113>https://doi.org/10.1073/pnas.1521897113</a></p></li><li><p>Zwaan, R.A., Etz, A., Lucas, R.E, Donnellan, M.B. (2018). Making replication mainstream. Behavior and Brain Sciences, 41, e120. <a href=https://doi.org/10.1017/S0140525X17001972>https://doi.org/10.1017/S0140525X17001972</a></p></li></ul><br></div><div class="tab-pane fade" id=C6S4 role=tabpanel aria-labelledby=C6S4-tab><br><h2 id=conducting-replication-studies-challenges-limitations-and-comparisons-with-the-original-study>Conducting replication studies; challenges, limitations, and comparisons with the original study</h2><ul><li><p>Grahe, J. E., Brandt, M. J., Wagge, J. R., Legate, N., Wiggins, B. J., Christopherson, C. D., . . . LePine, S. (2018). Collaborative Replications and Education Project (CREP). Retrieved from <a href=https://osf.io/wfc6u/>https://osf.io/wfc6u/</a></p></li><li><p>Grahe, J. E., Reifman, A., Hermann, A. D., Walker, M., Oleson, K. C., Nario-Redmond, M., & Wiebe, R. P. (2012). Harnessing the undiscovered resource of student research projects. Perspectives on Psychological Science, 7(6), 605–607. <a href=https://doi.org/10.1177/1745691612459057>https://doi.org/10.1177/1745691612459057</a></p></li><li><p>Frank, M. C., & Saxe, R. (2012). Teaching replication. Perspectives on Psychological Science, 7(6), 600–604. <a href=https://doi.org/10.1177/1745691612460686>https://doi.org/10.1177/1745691612460686</a></p></li><li><p>Lenne & Mann (2016). CREP project report. <a href=https://osf.io/sdj7e/>https://osf.io/sdj7e/</a></p></li><li><p>Stanley, D. J., & Spence, J. R. (2014). Expectations for replications: Are yours realistic? Perspectives on Psychological Science, 9(3), 305-318. <a href=https://doi.org/10.1177/1745691614528518>https://doi.org/10.1177/1745691614528518</a></p></li><li><p>Wagge, J. R., Brandt, M. J., Lazarevic, L. B., Legate, N., Christopherson, C., Wiggins, B., & Grahe, J. E. (2019). Publishing research with undergraduate students via replication work: The collaborative replications and education project. Frontiers in psychology, 10, 247.</p></li></ul><br></div><div class="tab-pane fade" id=C6S5 role=tabpanel aria-labelledby=C6S5-tab><br><h2 id=registered-replication-reports>Registered Replication Reports</h2><p><em><strong>Registered Reports are studies that are peer-reviewed prior to data collection, with an agreement between the journal and the author(s) that it will be published regardless of outcome as long as the preregistered methods are reasonably followed. Registered REPLICATION Reports are a special category of these that only include replications.</strong></em></p><ul><li><p>Simons, D. J., Holcombe, A. O., & Spellman, B. A. (2014). An Introduction to Registered Replication Reports at Perspectives on Psychological Science. Perspectives on Psychological Science, 9(5), 552–555. <a href=https://doi.org/10.1177/1745691614543974>https://doi.org/10.1177/1745691614543974</a></p></li><li><p>Ongoing Replication projects <a href=https://www.psychologicalscience.org/publications/replication/ongoing-projects>https://www.psychologicalscience.org/publications/replication/ongoing-projects</a></p></li><li><p>Alogna, V. K., Attaya, M. K., Aucoin, P., Bahník, Š., Birch, S., Birt, A. R., &mldr; & Buswell, K. (2014). Registered replication report: Schooler and engstler-schooler (1990). Perspectives on Psychological Science, 9(5), 556-578.</p></li><li><p>Eerland, A., Sherrill, A. M., Magliano, J. P., Zwaan, R. A., Arnal, J. D., Aucoin, P., &mldr; & Crocker, C. (2016). Registered replication report: Hart & albarracín (2011). Perspectives on Psychological Science, 11(1), 158-171.</p></li></ul><p><a href=https://www.psychologicalscience.org/publications/replication/ongoing-projects target=_blank rel=noopener>Psychological Science Accelerator (PSA) Ongoing Replications</a></p><br></div><div class="tab-pane fade" id=C6S6 role=tabpanel aria-labelledby=C6S6-tab><br><h2 id=the-politics-of-replicating-famous-studies>The politics of replicating famous studies</h2><p><em><strong>Sometimes responses to replication research can be negative. Failed replications of famous work, most notably power posing, ego depletion, stereotype threat, and facial feedback, have received a lot of attention.</strong></em></p><ul><li><p>Neuliep, J. W., & Crandall, R. (1990). Editorial bias against replication research. Journal of Social Behavior & Personality, 5(4), 85-90.</p></li><li><p>Neuliep, J. W., & Crandall, R. (1993). Reviewer bias against replication research. Journal of Social Behavior & Personality, 8(6), 21-29.</p></li></ul><br></div></div></div></div></div></div></section><section id=cluster7 class="home-section wg-blank" style="background-color:#c9dbcb;padding:60px 0;font-size:1rem"><div class=container><div class=row><div class="col-lg-12 text-center"><h1>Cluster 7: Academic Life, Ethics and Culture</h1></div></div><div class=row><div class=col-lg-12><h3 id=description>Description</h3><p>Attainment of a grounding in topics related to academia and academics. Students should understand how individuals, teams, institutions, and academic culture work together to promote (or hinder) openness, inclusion, diversity, equity and transparency. Gathering perspectives on navigating scientific and academic life. Learning the challenges and rewards in the academic setting, the “hidden curriculum” in academic life.</p><p>There are 8 sub-clusters which aim to further parse the learning and teaching process:</p><ul><li>Diversity</li><li>Equity</li><li>Inclusion</li><li>Citizen science</li><li>Team science</li><li>Adversarial collaboration</li><li>The structure of and incentives in academia</li><li>Types of academic, non-academic & alt-academic positions</li></ul><br><ul class="nav nav-tabs" id=myTab role=tablist><li class=nav-item><a class="nav-link active" id=C7S1-tab data-toggle=tab href=#C7S1 role=tab aria-controls=C7S1 aria-selected=true>Diversity</a></li><li class=nav-item><a class=nav-link id=C7S2-tab data-toggle=tab href=#C7S2 role=tab aria-controls=C7S2 aria-selected=false>Equity</a></li><li class=nav-item><a class=nav-link id=C7S3-tab data-toggle=tab href=#C7S3 role=tab aria-controls=C7S3 aria-selected=false>Inclusion</a></li><li class=nav-item><a class=nav-link id=C7S4-tab data-toggle=tab href=#C7S4 role=tab aria-controls=C7S4 aria-selected=false>Citizen science</a></li><li class=nav-item><a class=nav-link id=C7S5-tab data-toggle=tab href=#C7S5 role=tab aria-controls=C7S5 aria-selected=false>Team science</a></li><li class=nav-item><a class=nav-link id=C7S6-tab data-toggle=tab href=#C7S6 role=tab aria-controls=C7S6 aria-selected=false>Adversarial collaboration</a></li><li class=nav-item><a class=nav-link id=C7S7-tab data-toggle=tab href=#C7S7 role=tab aria-controls=C7S7 aria-selected=false>Incentives</a></li><li class=nav-item><a class=nav-link id=C7S8-tab data-toggle=tab href=#C7S8 role=tab aria-controls=C7S8 aria-selected=false>Positions</a></li><li class=nav-item><a class=nav-link id=C7S9-tab data-toggle=tab href=#C7S9 role=tab aria-controls=C7S9 aria-selected=false>Feminist Thought</a></li></ul><div class=tab-content id=myTabContent><div class="tab-pane fade show active" id=C7S1 role=tabpanel aria-labelledby=C7S1-tab><br><h2 id=diversity>Diversity</h2><p><em><strong>Diversity is the presence of difference within a specific environment, e.g. racial diversity, gender diversity, social-economic diversity, etc.</strong></em></p><ul><li><p>Bahlai, C., Bartlett, L. J., Burgio, K. R., Fournier, A., Keiser, C. N., Poisot, T., & Whitney, K. S. (2019). Open science isn’t always open to all scientists. American Scientist, 107(2), 78-82. <a href=https://doi.org/10.1511/2019.107.2.78>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Cislak, A., Formanowicz, M., & Saguy, T. (2018). Bias against research on gender bias. Scientometrics, 115(1), 189-200. <a href=https://doi.org/10.1007/s11192-018-2667-0>https://doi.org/10.1007/s11192-018-2667-0</a></p></li><li><p>Flaherty, C. (2020, August, 20). Something&rsquo;s Got to Give. Inside Higher Ed. Retrieved from <a href=https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall>https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall</a></p></li><li><p>Kim, E., & Patterson, S. (2020). The Pandemic and Gender Inequality in Academia. Available at SSRN 3666587. <a href=http://dx.doi.org/10.2139/ssrn.3666587>http://dx.doi.org/10.2139/ssrn.3666587</a></p></li><li><p>Larivière, V., Ni, C., Gingras, Y., Cronin, B., & Sugimoto, C. R. (2013). Bibliometrics: Global gender disparities in science. Nature News, 504(7479), 211. <a href=https://doi.org/10.1038/504211a>https://doi.org/10.1038/504211a</a></p></li><li><p>Myers, K. R., Tham, W. Y., Yin, Y., Cohodes, N., Thursby, J. G., Thursby, M. C., &mldr; & Wang, D. (2020). Unequal effects of the COVID-19 pandemic on scientists. Nature human behaviour, 4(9), 880-883.</p></li><li><p>Quagliata, T. (2008). Is there a positive correlation between socioeconomic status and academic achievement?. Paper: Education masters (p. 78). <a href="https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&context=education_ETD_masters">https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&context=education_ETD_masters</a></p></li><li><p>Roberson, M. L. (2020). On supporting early-career Black scholars. Nature Human Behaviour, 1-1. <a href=https://doi.org/10.1038/s41562-020-0926-6>https://doi.org/10.1038/s41562-020-0926-6</a></p></li><li><p>APA (2010). Sexual Orientation, Gender identity & Socioeconomic Status [Blog post]. Retrieved fromhttps://www.apa.org/pi/ses/resources/publications/lgbt</p></li><li><p>APA (2010). Disability & Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/disability>https://www.apa.org/pi/ses/resources/publications/disability</a></p></li><li><p>APA. (2017, July). Women & Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/women>https://www.apa.org/pi/ses/resources/publications/women</a></p></li><li><p>APA (2017, July). Ethnic and Racial Minorities & Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/minorities>https://www.apa.org/pi/ses/resources/publications/minorities</a></p></li><li><p>APA (2017, July). Education and Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/education>https://www.apa.org/pi/ses/resources/publications/education</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S2 role=tabpanel aria-labelledby=C7S2-tab><br><p><em><strong>Equity is that everyone has access to the same opportunities and that we all have privileges and barriers, thus we do not all start from the same starting position.</strong></em></p><ul><li><p>APA (2010). Sexual Orientation, Gender identity & Socioeconomic Status [Blog post]. Retrieved fromhttps://www.apa.org/pi/ses/resources/publications/lgbt</p></li><li><p>APA (2010). Disability & Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/disability>https://www.apa.org/pi/ses/resources/publications/disability</a></p></li><li><p>APA. (2017, July). Women & Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/women>https://www.apa.org/pi/ses/resources/publications/women</a>
APA (2017, July). Ethnic and Racial Minorities & Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/minorities>https://www.apa.org/pi/ses/resources/publications/minorities</a></p></li><li><p>APA (2017, July). Education and Socioeconomic Status [Blog post]. Retrieved from <a href=https://www.apa.org/pi/ses/resources/publications/education>https://www.apa.org/pi/ses/resources/publications/education</a></p></li><li><p>Bahlai, C., Bartlett, L. J., Burgio, K. R., Fournier, A., Keiser, C. N., Poisot, T., & Whitney, K. S. (2019). Open science isn’t always open to all scientists. American Scientist, 107(2), 78-82. <a href=https://doi.org/10.1511/2019.107.2.78>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Cislak, A., Formanowicz, M., & Saguy, T. (2018). Bias against research on gender bias. Scientometrics, 115(1), 189-200. <a href=https://doi.org/10.1007/s11192-018-2667-0>https://doi.org/10.1007/s11192-018-2667-0</a></p></li><li><p>Flaherty, C. (2020, August, 20). Something&rsquo;s Got to Give. Inside Higher Ed. Retrieved from <a href=https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall>https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall</a></p></li><li><p>Kim, E., & Patterson, S. (2020). The Pandemic and Gender Inequality in Academia. Available at SSRN 3666587. <a href=http://dx.doi.org/10.2139/ssrn.3666587>http://dx.doi.org/10.2139/ssrn.3666587</a></p></li><li><p>Larivière, V., Ni, C., Gingras, Y., Cronin, B., & Sugimoto, C. R. (2013). Bibliometrics: Global gender disparities in science. Nature News, 504(7479), 211. <a href=https://doi.org/10.1038/504211a>https://doi.org/10.1038/504211a</a></p></li><li><p>Myers, K. R., Tham, W. Y., Yin, Y., Cohodes, N., Thursby, J. G., Thursby, M. C., &mldr; & Wang, D. (2020). Unequal effects of the COVID-19 pandemic on scientists. Nature human behaviour, 4(9), 880-883.</p></li><li><p>Quagliata, T. (2008). Is there a positive correlation between socioeconomic status and academic achievement?. Paper: Education masters (p. 78). <a href="https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&context=education_ETD_masters">https://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1077&context=education_ETD_masters</a></p></li><li><p>Roberson, M. L. (2020). On supporting early-career Black scholars. Nature Human Behaviour, 1-1. <a href=https://doi.org/10.1038/s41562-020-0926-6>https://doi.org/10.1038/s41562-020-0926-6</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S3 role=tabpanel aria-labelledby=C7S3-tab><br><h2 id=inclusion>Inclusion</h2><p><em><strong>Inclusion is that individuals with different representations, identities and feelings being respected, influenced, and welcomed in a specific environment.</strong></em></p><ul><li><p>Bahlai, C., Bartlett, L. J., Burgio, K. R., Fournier, A., Keiser, C. N., Poisot, T., & Whitney, K. S. (2019). Open science isn’t always open to all scientists. American Scientist, 107(2), 78-82. <a href=https://doi.org/10.1511/2019.107.2.78>https://doi.org/10.1511/2019.107.2.78</a></p></li><li><p>Carli, L. L., Alawa, L., Lee, Y., Zhao, B., & Kim, E. (2016). Stereotypes about gender and science: Women≠ scientists. Psychology of Women Quarterly, 40(2), 244-260 <a href=https://doi.org/10.1177/0361684315622645>https://doi.org/10.1177/0361684315622645</a></p></li><li><p>Cislak, A., Formanowicz, M., & Saguy, T. (2018). Bias against research on gender bias. Scientometrics, 115(1), 189-200. <a href=https://doi.org/10.1007/s11192-018-2667-0>https://doi.org/10.1007/s11192-018-2667-0</a></p></li><li><p>Eagly, A. H., & Miller, D. I. (2016). Scientific eminence: Where are the women?. Perspectives on Psychological Science, 11(6), 899-904.</p></li><li><p>Flaherty, C. (2020, August, 20). Something&rsquo;s Got to Give. Inside Higher Ed. Retrieved from <a href=https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall>https://www.insidehighered.com/news/2020/08/20/womens-journal-submission-rates-continue-fall</a></p></li><li><p>Henrich, J., Heine, S. & Norenzayan, A. (2010) Most people are not WEIRD. Nature 466, 29. <a href=https://doi.org/10.1038/466029a>https://doi.org/10.1038/466029a</a></p></li><li><p>Larivière, V., Ni, C., Gingras, Y., Cronin, B., & Sugimoto, C. R. (2013). Bibliometrics: Global gender disparities in science. Nature News, 504(7479), 211. <a href=https://doi.org/10.1038/504211a>https://doi.org/10.1038/504211a</a></p></li><li><p>Macoun, A., & Miller, D. (2014). Surviving (thriving) in academia: Feminist support networks and women ECRs. Journal of Gender Studies, 23(3), 287-301. <a href=https://doi.org/10.1080/09589236.2014.909718>https://doi.org/10.1080/09589236.2014.909718</a></p></li><li><p>Myers, K. R., Tham, W. Y., Yin, Y., Cohodes, N., Thursby, J. G., Thursby, M. C., &mldr; & Wang, D. (2020). Unequal effects of the COVID-19 pandemic on scientists. Nature human behaviour, 4(9), 880-883.</p></li><li><p>Risner, L. E., Morin, X. K., Erenrich, E. S., Clifford, P. S., Franke, J., Hurley, I., & Schwartz, N. B. (2020). Leveraging a collaborative consortium model of mentee/mentor training to foster career progression of underrepresented postdoctoral researchers and promote institutional diversity and inclusion. PloS one, 15(9), e0238518. <a href=https://doi.org/10.1371/journal.pone.0238518>https://doi.org/10.1371/journal.pone.0238518</a></p></li><li><p>Roberson, M. L. (2020). On supporting early-career Black scholars. Nature Human Behaviour, 1-1. <a href=https://doi.org/10.1038/s41562-020-0926-6>https://doi.org/10.1038/s41562-020-0926-6</a></p></li><li><p>Skitka, L. J., Melton, Z. J., Mueller, A. B., & Wei, K. Y. (2020). The Gender Gap: Who Is (and Is Not) Included on Graduate-Level Syllabi in Social/Personality Psychology. Personality and Social Psychology Bulletin, 0146167220947326. <a href=https://doi.org/10.1177/0146167220947326>https://doi.org/10.1177/0146167220947326</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S4 role=tabpanel aria-labelledby=C7S4-tab><br><h2 id=citizen-science>Citizen science</h2><p><em><strong>Citizen science is scientific research conducted, in whole or in part, by amateur (or nonprofessional) scientists. Citizen science is sometimes described as &ldquo;public participation in scientific research,&rdquo; participatory monitoring, and participatory action research whose outcomes are often advancements in scientific research by improving the scientific communities capacity, as well as an increasing the public&rsquo;s understanding of science.</strong></em></p><ul><li><p>Hart, D. D., & Silka, L. (2020). Rebuilding the ivory tower: bottom-up experiment in aligning research with societal needs. Issues Sci Technol, 36(3), 64-70. <a href=https://issues.org/aligning-research-with-societal-needs/>https://issues.org/aligning-research-with-societal-needs/</a></p></li><li><p>Bonney, R., Cooper, C. B., Dickinson, J., Kelling, S., Phillips, T., Rosenberg, K. V., & Shirk, J. (2009). Citizen science: a developing tool for expanding science knowledge and scientific literacy. BioScience, 59(11), 977-984.</p></li><li><p>Bonney, R., Shirk, J. L., Phillips, T. B., Wiggins, A., Ballard, H. L., Miller-Rushing, A. J., & Parrish, J. K. (2014). Next steps for citizen science. Science, 343(6178), 1436-1437.</p></li><li><p>Cohn, J. P. (2008). Citizen science: Can volunteers do real research?. BioScience, 58(3), 192-197.</p></li></ul><br></div><div class="tab-pane fade" id=C7S5 role=tabpanel aria-labelledby=C7S5-tab><br><h2 id=team-science>Team science</h2><p><em><strong>Team science institutions coordinate a large group of scientists to solve a problem. Individual scientists are rewarded a publication by the institution for their efforts and resources. Once a group signs onto a team science project, the institution serves as a coordinating role, merging the resources from all scientists and focusing on a common project.</strong></em></p><ul><li><p>Forscher, P. S., Wagenmakers, E. J., DeBruine, L., Coles, N., Silan, M. A., & IJzerman, H. (2020). A Manifesto for Team Science. Retrieved from <a href=https://psyarxiv.com/2mdxh>https://psyarxiv.com/2mdxh</a>
Silberzahn, R., & Uhlmann, E. L. (2015). Crowdsourced research: Many hands make tight work. Nature News, 526(7572), 189. <a href=https://doi.org/10.1038/526189a>https://doi.org/10.1038/526189a</a></p></li><li><p>Wagge, J. R., Brandt, M. J., Lazarevic, L. B., Legate, N., Christopherson, C., Wiggins, B., & Grahe, J. E. (2019). Publishing research with undergraduate students via replication work: The collaborative replications and education project. Frontiers in psychology, 10, 247. <a href=https://doi.org/10.3389/fpsyg.2019.00247>https://doi.org/10.3389/fpsyg.2019.00247</a></p></li></ul><br></div><div class="tab-pane fade" id=C7S6 role=tabpanel aria-labelledby=C7S6-tab><br><h2 id=adversarial-collaborations>Adversarial collaborations</h2><ul><li><p>Tijdink, J. K., Verbeke, R., & Smulders, Y. M. (2014). Publication pressure and scientific misconduct in medical scientists. Journal of Empirical Research on Human Research Ethics, 9(5), 64-71. <a href=https://doi.org/10.1177/1556264614552421>https://doi.org/10.1177/1556264614552421</a></p></li><li><p>Bateman, I., Kahneman, D., Munro, A., Starmer, C., & Sugden, R. (2005). Testing competing models of loss aversion: An adversarial collaboration. Journal of Public Economics, 89(8), 1561-1580.</p></li></ul><br></div><div class="tab-pane fade" id=C7S7 role=tabpanel aria-labelledby=C7S7-tab><br><h2 id=structures-and-incentives-in-academia>Structures and Incentives in academia</h2><p><em><strong>Sometimes responses to replication research can be negative. Failed replications of famous work, most notably power posing, ego depletion, stereotype threat, and facial feedback, have received a lot of attention.</strong></em></p><ul><li><p>Bol, T., de Vaan, M., & van de Rijt, A. (2018). The Matthew effect in science funding. Proceedings of the National Academy of Sciences, 115(19), 4887-4890.</p></li><li><p>Corker, K. S. (2017). Why a Focus on Eminence is Misguided: A Call to Return to Basic Scientific Values. <a href=https://doi.org/10.31234/osf.io/yqfrd>https://doi.org/10.31234/osf.io/yqfrd</a></p></li><li><p>Diener, E. (2016). Improving departments of psychology. Perspectives on Psychological Science, 11(6), 909-912.</p></li><li><p>Ebersole, C. R., Axt, J. R., & Nosek, B. A. (2016). Scientists’ reputations are based on getting it right, not being right. PLoS biology, 14(5), e1002460.</p></li><li><p>Fanelli, D. (2012). Negative results are disappearing from most disciplines and countries. Scientometrics, 90(3), 891-904. <a href=https://doi.org/10.1007/s11192-011-0494-7>https://doi.org/10.1007/s11192-011-0494-7</a></p></li><li><p>Feist, G. J. (2016). Intrinsic and extrinsic science: A dialectic of scientific fame. Perspectives on Psychological Science, 11(6), 893-898.</p></li><li><p>Ferreira, F. (2017). Fame: I’m Skeptical. <a href=https://doi.org/10.31234/osf.io/6zb4f>https://doi.org/10.31234/osf.io/6zb4f</a></p></li><li><p>Flier J. (2017) Faculty promotion must assess reproducibility. Nature, 549(7671),133. <a href=https://doi.org/10.1038/549133a>https://doi.org/10.1038/549133a</a></p></li><li><p>Foss, D. J. (2016). Eminence and omniscience: Statistical and clinical prediction of merit. Perspectives on Psychological Science, 11(6), 913-916.</p></li><li><p>Gernsbacher, M. A. (2018). Rewarding research transparency. Trends in cognitive sciences, 22(11), 953-956. <a href=https://doi.org/10.1016/j.tics.2018.07.002>https://doi.org/10.1016/j.tics.2018.07.002</a></p></li><li><p>Hirsch, J. E. (2010). An index to quantify an individual’s scientific research output that takes into account the effect of multiple coauthorship. Scientometrics, 85(3), 741-754.</p></li><li><p>Innes-Ker, Å. (2017). The Focus on Fame Distorts Science. <a href=https://doi.org/10.31234/osf.io/vyr3e>https://doi.org/10.31234/osf.io/vyr3e</a></p></li><li><p>Ioannidis, J. P., & Thombs, B. D. (2019). A user’s guide to inflated and manipulated impact factors. European journal of clinical investigation, 49(9), e13151. <a href=https://doi.org/10.1111/eci.13151>https://doi.org/10.1111/eci.13151</a></p></li><li><p>Jamieson, K. H., McNutt, M., Kiermer, V., & Sever, R. (2019). Signaling the trustworthiness of science. Proceedings of the National Academy of Sciences, 116(39), 19231-19236.https://doi.org/10.1073/pnas.1913039116</p></li><li><p>Jamieson, K. H., McNutt, M., Kiermer, V., & Sever, R. (2020). Reply to Kornfeld and Titus: No distraction from misconduct. Proceedings of the National Academy of Sciences of the United States of America, 117(1), 42. <a href=https://doi.org/10.1073/pnas.1918001116>https://doi.org/10.1073/pnas.1918001116</a></p></li><li><p>Kornfeld, D. S., & Titus, S. L. (2016). Stop ignoring misconduct. Nature, 537(7618), 29-30.https://doi.org/10.1038/537029a</p></li><li><p>Kornfeld, D. S., & Titus, S. L. (2020). Signaling the trustworthiness of science should not be a substitute for direct action against research misconduct. Proceedings of the National Academy of Sciences of the United States of America, 117(1), 41. <a href=https://doi.org/10.1073/pnas.1917490116>https://doi.org/10.1073/pnas.1917490116</a></p></li><li><p>Li, W., Aste, T., Caccioli, F., & Livan, G. (2019). Early coauthorship with top scientists predicts success in academic careers. Nature communications, 10(1), 1-9.</p></li><li><p>Matosin, N., Frank, E., Engel, M., Lum, J. S., & Newell, K. A. (2014). Negativity towards negative results: a discussion of the disconnect between scientific worth and scientific culture. Disease Models & Mechanisms, 7(2), 171. <a href=https://doi.org/10.1242/dmm.015123>https://doi.org/10.1242/dmm.015123</a></p></li><li><p>Morgan, A. C., Economou, D. J., Way, S. F., & Clauset, A. (2018). Prestige drives epistemic inequality in the diffusion of scientific ideas. EPJ Data Science, 7(1), 40. <a href=https://doi.org/10.1140/epjds/s13688-018-0166-4>https://doi.org/10.1140/epjds/s13688-018-0166-4</a></p></li><li><p>Naudet, F., Ioannidis, J., Miedema, F., Cristea, I. A., Goodman, S. N., & Moher, D. (2018). Six principles for assessing scientists for hiring, promotion, and tenure. Impact of Social Sciences Blog. <a href=http://eprints.lse.ac.uk/90753/>http://eprints.lse.ac.uk/90753/</a></p></li><li><p>Pickett, C. (2017). Let&rsquo;s Look at the Big Picture: A System-Level Approach to Assessing Scholarly Merit. <a href=https://doi.org/10.31234/osf.io/tv6nb>https://doi.org/10.31234/osf.io/tv6nb</a></p></li><li><p>Roediger III, H. L. (2016). Varieties of fame in psychology. Perspectives on Psychological Science, 11(6), 882-887.</p></li><li><p>Ruscio, J. (2016). Taking advantage of citation measures of scholarly impact: Hip Hip h Index!. Perspectives on Psychological Science, 11(6), 905-908.</p></li><li><p>Shiota, M. N. (2017). “Fame” is the Problem:Conflation of Visibility With Potential for Long-Term Impact in Psychological Science. <a href=https://doi.org/10.31234/osf.io/4kwuq>https://doi.org/10.31234/osf.io/4kwuq</a></p></li><li><p>Simonton, D. K. (2016). Giving credit where credit’s due: Why it’s so hard to do in psychological science. Perspectives on Psychological Science, 11(6), 888-892.</p></li><li><p>Tressoldi, P. E., Giofré, D., Sella, F., & Cumming, G. (2013). High impact= high statistical standards? Not necessarily so. PloS one, 8(2), e56180.</p></li><li><p>Sternberg, R. J. (2016). “Am I famous yet?” Judging scholarly merit in psychological science: An introduction. Perspectives on Psychological Science, 11(6), 877-881.</p></li><li><p>Vazire, S. (2017). Against eminence.https://doi.org/10.31234/osf.io/djbcw</p></li><li><p>Van Dijk, D., Manor, O., & Carey, L. B. (2014). Publication metrics and success on the academic job market. Current Biology, 24(11), R516-R517.</p></li></ul><br></div><div class="tab-pane fade" id=C7S8 role=tabpanel aria-labelledby=C7S8-tab><br><h2 id=types-of-academic-non-academic--alt-academic-positions>Types of academic, non-academic & alt-academic positions</h2><ul><li><p>Gomez, P., Anderson, A. R., & Baciero, A. (2017). Lessons for psychology laboratories from industrial laboratories. Research Ethics, 13(3-4), 155-160. <a href=https://doi.org/10.1177/1747016117693827>https://doi.org/10.1177/1747016117693827</a></p></li><li><p>Nature. (2019). Postdocs in crisis: science cannot risk losing the next generation. Nature, 580, 160. <a href=https://doi.org/10.1038/d41586-020-02541-9>https://doi.org/10.1038/d41586-020-02541-9</a></p></li><li><p>Nature. (2019). The mental health of PhD researchers demands urgent attention. Nature, 575, 257-258. <a href=https://doi.org/10.1038/d41586-019-03489-1>https://doi.org/10.1038/d41586-019-03489-1</a></p></li><li><p>Nature. (2020). Seeking an ‘exit plan’ for leaving academia amid coronavirus worries. Nature 583, 645-646. <a href=https://doi.org/10.1038/d41586-020-02029-6>https://doi.org/10.1038/d41586-020-02029-6</a>.</p></li></ul><br></div><div class="tab-pane fade" id=C7S9 role=tabpanel aria-labelledby=C7S9-tab><br><h2 id=feminist-thought>Feminist Thought</h2><p><em><strong>It aims to understand the nature of gender inequality. Themes explored include discrimination, objectification, oppression, patriarchy, stereotyping, and aesthetics. It examines women&rsquo;s and men&rsquo;s social roles, experiences, interests, chores, and feminist politics in a variety of fields.</strong></em></p><ul><li><p>Eagly, A. H., Eaton, A., Rose, S. M., Riger, S., & McHugh, M. C. (2012). Feminism and psychology: Analysis of a half-century of research on women and gender. American Psychologist, 67(3), 211-230, <a href=https://doi.org/10.1037/a0027260>https://doi.org/10.1037/a0027260</a></p></li><li><p>Matsick, J. L., Kruk, M., Oswald, F., & Palmer, L. (2021). Bridging Feminist Psychology and Open Science: Feminist Tools and Shared Values Inform Best Practices for Science Reform. Psychology of Women Quarterly, <a href=https://doi.org/10.1177/03616843211026564>https://doi.org/10.1177/03616843211026564</a></p></li><li><p>Lazard, L., & McAvoy, J. (2020). Doing reflexivity in psychological research: What’s the point? What’s the practice?. Qualitative research in psychology, 17(2), 159-177 <a href=https://doi.org/10.1080/14780887.2017.1400144>https://doi.org/10.1080/14780887.2017.1400144</a></p></li><li><p>Macleod, C. I., Capdevila, R., Marecek, J., Braun, V., Gavey, N., & Wilkinson, S. (2021). Celebrating 30 years of Feminism & Psychology. Feminism & Psychology, 31(3), 313-325. <a href=https://doi.org/10.1177/09593535211027457>https://doi.org/10.1177/09593535211027457</a></p></li><li><p>Crawford, M., & Marecek, J. (1989). Feminist theory, feminist psychology: A bibliography of epistemology, critical analysis, and applications. Psychology of Women Quarterly, 13(4), 477-491. <a href=https://doi.org/10.1111/j.1471-6402.1989.tb01015.x>https://doi.org/10.1111/j.1471-6402.1989.tb01015.x</a></p></li><li><p>Marecek, J. (2016). Invited reflection: Intersectionality theory and feminist psychology. Psychology of Women Quarterly, 40(2), 177-181. <a href=https://doi.org/10.1177/0361684316641090>https://doi.org/10.1177/0361684316641090</a></p></li><li><p>OpenSexism Archives on Open Science <a href=https://opensexism.wordpress.com/tag/open-science/>https://opensexism.wordpress.com/tag/open-science/</a></p></li></ul><br></div></div></div></div></div></div></section><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin=anonymous title=mermaid></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js integrity="sha512-7t8APmYpzEsZP7CYoA7RfMPV9Bb+PJHa9x2WiUnDXZx3XHveuyWUtvNOexhkierl5flZ3tr92dP1mMS+SGlD+A==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin=anonymous></script><script>const code_highlighting=!0</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",talk:"Talks",slides:"Slides"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/academic.min.19912f59e37190f8d23e7f331b162e03.js></script><div class=container><footer class=site-footer><p class=powered-by><a href=/tag/privacy/>privacy</a></p><p class=powered-by>© 2024 - FORRT > Framework for Open and Reproducible Research Training</p><p class="powered-by copyright-license-text">Except where otherwise noted, content on this site is licensed under a <a href=https://creativecommons.org/licenses/by-nc-sa/4.0 rel="noopener noreferrer" target=_blank>CC BY NC SA 4.0</a> license</p><div class="d-flex justify-content-center powered-by footer-license-icons pb-2"><a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png></a></div><p class=powered-by>This website is published using two great open source tools:
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a> & the
    <a href=https://hugoblox.com/ target=_blank rel=noopener>Academic theme.</a>
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div></body></html>