<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Pedagogies | FORRT - Framework for Open and Reproducible Research Training</title><link>https://forrt.org/pedagogies/</link><atom:link href="https://forrt.org/pedagogies/index.xml" rel="self" type="application/rss+xml"/><description>Pedagogies</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2024 - FORRT Framework for Open and Reproducible Research Training</copyright><image><url>https://forrt.org/pedagogies/featured.png</url><title>Pedagogies</title><link>https://forrt.org/pedagogies/</link></image><item><title>Open Science education through student participation</title><link>https://forrt.org/pedagogies/003-crep/</link><pubDate>Fri, 20 Oct 2023 10:10:49 +0000</pubDate><guid>https://forrt.org/pedagogies/003-crep/</guid><description>&lt;br>
&lt;p>We are back with a very special Pedagogies, this time including also the perspectives of students on learning about Open Science (OS)! We have three amazing guests: Prof. Dr. Jordan Wagge and her two outstanding undergraduate students, Jasmine Beltran and Amy Hernandez. Over the past years, Jordan has led the way in developing CREP so that it can i) accomplish much needed replications, and ii) provide tools/structure for instructors who desire to train their students in OS. In this FORRT’s Pedagogies, Jordan and her students share their experiences with CREP and their thoughts about the trials and tribulations of involving students in the process of OS. We hope that this can inspire and help many scholars wishing to incorporate more OS into their teaching, mentoring and research.&lt;/p>
&lt;br>
&lt;p>Jordan Wagge is a Professor of Psychology and Cognitive Science at the University of Avila (UA) and the Executive Director of CREP. Her research focuses on three areas including replication work, pedagogy, and critical work studies. She has a strong record supporting the OS movement at all levels - from her teaching philosophy, to the development of open teaching materials and resources, and the involvement of students in OS training and practice. But be sure to
&lt;a href="https://jordanwagge.com/" target="_blank" rel="noopener">learn more about Jordan from her website&lt;/a> (all links posted below). We are also joined by Jasmine Beltran and Amy Hernandez, Jordan’s students, who have experienced the implementation of CREP in their classrooms first hand. They discuss their perspective as a student, their challenges, and the benefits they gained through this process.&lt;/p>
&lt;p>&lt;img src="image1.png" alt="A Zoom screenshot of Jasmine Beltran, Jordan Wagge and Amy Hernandez.">&lt;/p>
&lt;p>FORRT’s Team Pedagogies took the opportunity to ask Jordan, Jasmine, and Amy some questions on their journey with CREP (shoutout to the FORRT and academic Twitter community for sending so many great questions). You can watch or listen to the interview in the video or read a summary of their main points below!&lt;/p>
&lt;p>&lt;em>&lt;strong>Check out the full interview here&lt;/strong>&lt;/em>&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/OLI_2UAapSc" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;ol>
&lt;li>&lt;strong>Could you tell us a little bit about yourself and how you got involved with Open Science and, more specifically, with CREP?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: I got involved with OS pretty naturally. In graduate school, I taught Statistics and Research Methods. When I taught, I would highlight best practices and how science works. There were all these topics that I felt hypocritical teaching because I would also say “Psychologists don’t do this in practice”. It led me to ask, &lt;strong>why don’t we do these things in practice?&lt;/strong> I naturally fit into the OS and transparency movement because it made sense. I got involved with CREP after it was founded. At a conference, I was seeking co-presenters on how to teach undergraduate students research methods most effectively. I wanted to know how others maximized the limited amount of time given all the learning outcomes associated with a methods course.
&lt;a href="https://www.plu.edu/psychology/staff/jon-e-grahe/" target="_blank" rel="noopener">John Grahe&lt;/a> responded. The angle he took is to make the course time to capitalize on a meaningful contribution to the field especially if students are already investing so much energy. At the same time,
&lt;a href="https://www.socialsciencespace.com/author/markbrandt/" target="_blank" rel="noopener">Mark Brandt&lt;/a> and
&lt;a href="https://nias.knaw.nl/fellow/ijzerman-hans/" target="_blank" rel="noopener">Hans Ijzerman&lt;/a> from Tilburg University were interested in replication efforts and began CREP. I reached out and joined from there.&lt;/p>
&lt;p>&lt;strong>&lt;em>Jasmine&lt;/em>&lt;/strong>: We’ve had Dr. Wagge as an instructor for a year now. Our Statistics course is a 2-semester course. During the first semester, we focused on doing a literature review and collecting material. This semester we are currently collecting data. We were required to engage with CREP but it’s been a fun, educational experience.&lt;/p>
&lt;p>&lt;strong>&lt;em>Amy&lt;/em>&lt;/strong>: I am in the class as well as in Dr. Wagge’s lab, so I’ve double dipped with the CREP experience.&lt;/p>
&lt;br>
&lt;ol start="2">
&lt;li>&lt;strong>Could you give a brief description of what CREP does and an overview of the process from selecting studies to publication?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jasmine&lt;/em>&lt;/strong>: I can talk about the CREP steps from a student perspective. It’s a Psychology project designed to tackle the replication crisis as well as provide a way for undergraduate students to gain that quality experience in the research process which I think is super important. I am completing a senior research thesis [final year undergraduate dissertation project for undergraduates who want to complete a PhD]. It’s important to gain this experience from CREP before just diving into research without knowing really anything. I would have had no idea how the research process looks like. With CREP, the main steps we took were the following:&lt;/p>
&lt;ol>
&lt;li>Studies are selected by the CREP Team. Across 9 disciplines, they select the most highly cited papers published in the previous 3 years. The studies undergo scrutiny by executive reviewers and are judged on how likely a student would have the ability to complete the replication in just 1 semester. The reviewers then do a final screening and reach out to the original authors of the selected studies to ensure the highest level of consistency with the original study.&lt;/li>
&lt;li>Now, students enter the process. Students are first introduced to CREP by their instructor. They then create an Open Science Framework (OSF) page and assemble components.&lt;/li>
&lt;li>Once the OSF page is drafted, it is submitted to a CREP executive reviewer to assess quality and provide feedback.&lt;/li>
&lt;li>Students pursue Institutional Review Board (IRB) approval, revise and resubmit the OSF page if needed, pre-register the study and post that on OSF as well.&lt;/li>
&lt;li>Data is collected, and once complete, students write up the results, discussion, submit materials, and sign a completion pledge.&lt;/li>
&lt;li>Students are e-mailed completion certificates. Once enough data is collected by several labs, students are invited by the CREP Team to contribute to a meta-analysis manuscript, ideally in a 1st author position, which, as we know, is a pretty big deal for an undergraduate student.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: There’s a publication (
&lt;a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00247/full" target="_blank" rel="noopener">Wagge et al., 2019&lt;/a>) which has a flow chart of how the process works from both the instructor’s end as well as the students (see image below). We also have a step by step manual (linked below) that walks students through their exact responsibilities. Of the 19 studies originally selected, we collected data on approximately 15 of them. Three of those studies led to a publication and &lt;strong>one of them has a student first author&lt;/strong>. I am also working on writing another paper right now and it has &lt;strong>30 authors that started in 2013&lt;/strong>. There are several factors that impact the publication timeline. Some studies have few people choosing to collect data and other studies use software students may not have a background in, like Matlab. These lead to areas CREP is improving on. CREP publications need content experts to ensure high quality work. We started CREP with a sample size rule of thumb (2.5x the original); however, we want to move to conducting power analyses prior to data collection. We warn instructors that studies will eventually end after 1-2 years of being posted. That means that the publication timeline for a study will be at least 1.5 years until we receive a manuscript. Once a content expert has been obtained, they help mentor students writing it up. Independent sites who participate in CREP are able to publish their own collected data. We recommend they publish any extension hypotheses data; however, if they want to publish the data regarding the original hypothesis, they can. We simply note in the CREP manuscript that some of the data has been published already. We are constantly thinking of ways to make this process as efficient as possible.&lt;/p>
&lt;p>&lt;img src="image2.png" alt="A flow chart outlining the CREP Process. Firstly, under the guidance of their faculty mentor, students contact the CREP Executive director to claim a study and be assigned a project code. Secondly, students create an OSF page forked form their replication study’s CREP page and begin collecting materials (includes scripts, surveys, and a video of in-person experimental procedures). At the third step, there are two branches: Student teams work on getting Institutional Review Board approval at their own institution (this may also be done prior to the semester by faculty members who have pre-selected replication studies); while a CREP executive reviewer, reviewer, and student administrator review the project, with a typical turnaround of 1.5 weeks. Next, the project is revised and resubmitted (if needed), with a typical turnaround of 1-2 days after resubmission. Following approval, the student team preregisters their page on the OSF and begins data collection. Following data collection, students write up results and discussion (full manuscripts might be required for courses, but are not required by CREP). Students post anonymised raw data with a codebook and preferably analysis code, sign a completion pledge, and notify the CREP Executive Reviewer for the project that they are ready for their final review. Next, the OSF page and materials are revised and resubmitted (if needed), including a completion pledge, with a typical turnaround of one week. Following final approval, students are emailed completion certificates. When enough data has been collected, students are invited by the CREP team to contribute to the meta-analysis manuscript (ideally in first-author position).">&lt;/p>
&lt;p>&lt;em>Flowchart of the CREP Process (Wagge et al., 2019)&lt;/em>&lt;/p>
&lt;br>
&lt;ol start="3">
&lt;li>&lt;strong>The focus on students is what sets CREP apart from other large-scale replication projects. Are students also involved in the publication process? How is authorship discussed and decided?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: We currently give independent site publications autonomy on student authorship. There have been no sites that have published their data, but we have thought of providing guidance through the OSF page’s bibliography. Currently OSF lists the graduate students first alphabetically, and I am last. Students can raise their position by contributing to more
&lt;a href="https://credit.niso.org/" target="_blank" rel="noopener">CREdiT&lt;/a> categories (e.g., collecting data, contributing to the manuscript). For example, if several students write up the results section, the best writer’s draft is used and they are considered to give additional contributions meriting higher authorship. Ideally, we contact every person who has contributed to data. One challenge we face is if instructors still work at their original institution and if students’ emails still work if they graduated. &lt;strong>When students are involved, they are also hesitant about their ability to provide meaningful feedback&lt;/strong>. In a recent project, we developed a survey and we sent the manuscript in that survey, along with guiding questions for students to provide feedback. We had several students contribute that way and that earns them authorship. We may not use all the feedback students provide, but it is considered and makes our manuscript stronger. We will see how this process goes and get students’ feedback on whether they felt they were contributing to authorship in that way.&lt;/p>
&lt;br>
&lt;ol start="4">
&lt;li>&lt;strong>There are many aspects of Open Science that can be taught to students. Could you tell us why CREP chose to focus on replications and what are the benefits of this approach?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: The reason we focus on replications with students is because - without wanting to sound too negative - student projects done in research methods courses are often not heavily based on theories or quality methodology. There is definite value in having this traditional method. Students learn how to test questions and think about how to break down a question through an empirical lens. I joke with my students that topics often chosen are usually pre-workout, sleep, stress, attachment styles, and the Big 5. These topics are interesting, but the questions are often not grounded in theory nor are they the cutting edge questions of what the field is doing. That’s to be expected from someone’s first research project. My own 1st project I conducted was extremely sloppy. I knew that I didn’t have any idea what I was doing. &lt;strong>In other scientific fields, it is common for students to conduct replications of classic findings many, many times.&lt;/strong> Imagine an introductory chemistry student is asked to create a compound in the lab: they are given a manual, told the exact steps, and get the desired outcome. Chemistry instructors never ask their students to form their own hypothesis from the get-go, never ask to imagine what would happen if you mix Chemical X with Chemical Z. Instead, &lt;strong>students are first trained by doing&lt;/strong>. In psychology, a student who wants to study depression is now exposed to several depression inventories and asked to uncover the exact methodology of a study. What CREP offers are curated studies with materials and the opportunity of providing a meaningful contribution to our field by replicating highly cited recent work. Instructors and students don’t have to worry about a lot of the decision making regarding the study. More time can be used in-class to discuss why we pursue the IRB, why this actual research study chose this method, and facing the challenges of being a replicator (e.g., ambiguous language for certain sections). &lt;strong>CREP comes from an apprenticeship model and provides scaffolding&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>&lt;em>Jasmine&lt;/em>&lt;/strong>: When our class went over 5 or 6 studies we could do, it gave us &lt;strong>freedom&lt;/strong> even if we didn’t get to do our own idea. We still had the choice of what to replicate and those days were my favorite. I appreciate the experience rather than being thrown in the deep-end and told ‘good luck!’.&lt;/p>
&lt;br>
&lt;ol start="5">
&lt;li>&lt;strong>What would you say are the major learning goals for students in these replication projects? For the students, what did you personally take away from this experience?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Amy&lt;/em>&lt;/strong>: I was definitely scared of APA [American Psychological Association] style the first time, but I have improved my writing in APA since then. I am also less intimidated talking with faculty members and generally communicating with them.&lt;/p>
&lt;p>&lt;strong>&lt;em>Jasmine&lt;/em>&lt;/strong>: I agree with the point about APA style as well as improving my ability to read scientific papers and their different sections. All students are contributing to every section of the research process, including the literature review. I believe the constant exposure to papers makes me feel &lt;strong>more confident in understanding scientific papers&lt;/strong>, knowing I can write similarly&amp;hellip; I think students need to build that confidence because nobody wants to sound stupid. By practicing in class, reading gets easier. Nobody is perfect at it, but practice helps get us there.&lt;/p>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: I originally chose one study to replicate, but now I choose a pool of studies I am willing to lead and have students vote on which one they would like to do. All students in my class write their own papers and get exposure to all parts of the process. I see CREP &lt;strong>as a model to implement your own learning outcomes&lt;/strong>, those of your department, and
&lt;a href="https://www.apa.org/ed/precollege/about/undergraduate-major" target="_blank" rel="noopener">APA’s listed 2.0 outcomes&lt;/a>. We are currently &lt;strong>working on a resource putting together writing assignments that would align with different learning outcomes&lt;/strong>. Instructors can then pick and choose assignments that suit the learning outcomes of their courses or departments.&lt;/p>
&lt;br>
&lt;ol start="6">
&lt;li>&lt;strong>What are students’ initial reactions when they start with the replication projects? What are the major challenges they may face? For students, what was your experience when you started with CREP?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jasmine&lt;/em>&lt;/strong>: When we first started, I was intimidated and thought my semester would be difficult. As we continued to move into the course, we spent a good amount of time on each step of the CREP process. This helped us maximize our learning. Currently, I am about to start my senior thesis and I am not nervous about that now. &lt;strong>The writing ability is definitely the biggest thing I took away from this process&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>&lt;em>Amy&lt;/em>&lt;/strong>: I was intimidated, too. And overwhelmed, thinking about all the things I would not know how to do. The challenge others and myself faced is that we were scared to make mistakes. Many of us wanted to be perfect at it the first time so that fear of ‘screwing up’ held us back from going on.&lt;/p>
&lt;br>
&lt;ol start="7">
&lt;li>&lt;strong>Imagine I would now start a replication project with a group of students at my university. Could you tell us what you think would be the advantage of doing these student-replications together with CREP? What are the benefits for instructors and for students?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: Having the structure, assignments, and pre-selected studies are important strengths of CREP. We do have lots of materials, for example tutorials on creating an OSF page. CREP also does have external reviewers who aim to get reviews back within 1-2 weeks. It is nice to have feedback from someone else on the project. We provide a huge advantage for replications in general. &lt;strong>CREP can be thought of as a professional network&lt;/strong>. You meet collaborators and build relationships, and I’ve written letters of recommendations for Tenure and Promotion committees for those involved with CREP. And finally, you do have something that you can add for authorship. This is especially important for educators from small teaching schools, who might have difficulties maintaining their own lines of independent research besides the teaching duties. &lt;strong>With that being said, if you are interested in doing replications with students, do it your way. Look at CREP materials, download the step by step guide and adapt it to your needs.&lt;/strong>&lt;/p>
&lt;br>
&lt;ol start="8">
&lt;li>&lt;strong>What are the different ways in which instructors can incorporate the work with CREP into their teaching/mentoring (e.g., lab course, seminar, other)? Which types of incorporation work best in your opinion? Which challenges do instructors usually experience?&lt;/strong> &lt;br > 8a. &lt;strong>For you students, how was the collaboration with CREP set up? What was your role in the replication and what did you like the most? Do all students have the exact same roles, or do some students have unique roles?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: An instructor could implement replications with CREP in an Introductory to Psychology course up to a graduate level course. If the class is for earlier undergraduates, I recommend the instructor handling some of the ‘behind-the-scenes’ paperwork to make the process easier instead of having students be in charge of everything. Instructors could allow students to do their Master thesis on CREP replications; however, I personally ask my students to have extension hypotheses. I agree with work done by Daniel Quintana that student theses &lt;em>should&lt;/em> be replications (
&lt;a href="https://doi.org/10.1038/s41562-021-01192-8" target="_blank" rel="noopener">Quintana, 2021&lt;/a>). Instructors can do replications with CREP on a variety of topics and disciplines, although some fields like biopsychology, developmental, or certain populations (e.g., children) might be more challenging. Instructors often face timeline issues from their institution such as slow IRBs. I would recommend getting IRB approval before the semester starts. It is also important to get familiar with the projects before proposing them to students. For example, knowing which type of resources and materials the replications require and whether you, as the instructor, would have access to those in your institution. I also think it can be easier for first time instructors to implement CREP either in smaller classes or for 1-1 mentoring.&lt;/p>
&lt;p>&lt;strong>&lt;em>Jasmine&lt;/em>&lt;/strong>: I mentioned that our Statistics and Methods class was shown several pre-selected studies to choose from. My favorite part was to go through each study in detail and discuss how many participants we would need to collect, what potential problems could arise, and so on. We were given ~100 voting points and each of the 20 students could allocate their points to the different studies. I also did an additional contribution to the project which involved recording myself doing the study procedures for the OSF. Amy also contributed with coding for an ongoing study.&lt;/p>
&lt;br>
&lt;ol start="9">
&lt;li>&lt;strong>You recently got the National Science Foundation (NSF) grant to fund, evaluate, and enhance the activities of CREP. Congratulations! Can you share a little with us how you envision the future of CREP?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: It’s really exciting that we got NSF funding to do research on CREP and learning outcomes. Right now, we have a couple of classes at different universities that are doing pre- and post-testing, and we&amp;rsquo;re gonna keep doing that for the next couple of rounds. We are also implementing a &lt;strong>‘peer mentor’ system that pays students&lt;/strong> who have undergone a project through CREP a 1-year stipend. These students would then have office hours and mentor other students around the world currently undergoing a replication with CREP. This is because students can feel more comfortable asking other students when learning about the research process. Chosen peer mentors will also be taken to a conference. For any students who have participated in CREP prior, we are also doing a Summer CREP conference to give an opportunity for students who participated in CREP research to present their results. Some of the money is going to &lt;strong>building infrastructure for a submission system. We also got a second grant that will be used to create instructor workshops&lt;/strong> on how to implement CREP in their curriculum. This will be really helpful in sort of getting people to incorporate CREP, but also build out materials that other people can use. One of the sessions will be dedicated to mentoring students in replications with extension hypotheses (specifically ones grounded in Diversity, Equity and Inclusion hypotheses). Lastly, we are investing in &lt;strong>more teaching resources and material&lt;/strong>. We hope to make CREP more accessible so that students get authentic, genuine research experience. We want students to have the opportunity to be real scholars. So we are thinking of more ways to engage students with professional development.&lt;/p>
&lt;p>&lt;img src="image3.png" alt="A quote from Jordan Wagge, which says: “One of the most attractive things about CREP is that it is real research. It’s an authentic research experience that students get. They are contributing to the field. They are doing something that is real, genuine research. They engage with scholars. (…) We want all students to have an opportunity to do so. We want them to have an opportunity to contribute to research and to be scholars. And I think that’s sort of where the future is for our profession, but also, you know, for CREP: how can we engage students in a more meaningful professional development.">&lt;/p>
&lt;br>
&lt;ol start="10">
&lt;li>&lt;strong>What is the best way to keep updated with the results of your conducted replications? Is there for example a sort of metadata containing all replications and the results?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: That’s definitely on my wishlist items for the future. I’ve currently been posting results on Twitter (
&lt;a href="https://twitter.com/CREP_psych" target="_blank" rel="noopener">@CREP_psych&lt;/a>) to communicate these manuscripts. We are hoping to also improve the website in the future. This is also a good &lt;strong>call for volunteers&lt;/strong>. If anybody wants to help set any of this stuff up, there are lots of places where people can help. Besides &lt;strong>help with the website and communication, we also always need reviewers, who are paid 10$ for the review&lt;/strong>.&lt;/p>
&lt;br>
&lt;ol start="11">
&lt;li>&lt;strong>Since CREP started, what have you learned so far about teaching Open Science that you could share with us? Any specific tips for instructors/educators who would like to incorporate OS into their teaching and mentoring?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>&lt;em>Jordan&lt;/em>&lt;/strong>: The most surprising thing regarding replications is just how invested students were. I was really worried it would feel forced. I don’t have data to support this, but in my experience students seem as interested in these topics as in topics they choose on their own.&lt;/p>
&lt;p>Regarding tips, &lt;strong>I don’t believe I have to be the ‘perfect’ teacher&lt;/strong>. I would say, don’t worry about doing everything. Do what you can and don’t be afraid to reach out and ask people what/how they are doing their class. We have a wonderful community. Being involved in things like SIPS [Society for the Improvement of Psychological Science], FORRT and Twitter really helps to see what other people are saying and doing. My biggest tip is to reach out whenever you have a question. If you are facing an issue about how to run your classroom, there is someone out there who has faced something similar and can help.&lt;/p>
&lt;br>
&lt;hr>
&lt;br>
&lt;h2 id="creps-resources">CREP’s resources&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://osf.io/wfc6u/" target="_blank" rel="noopener">CREP’s OSF page&lt;/a>: The landing page for instructors who would like to start their journey with CREP. It includes CREP’s
&lt;a href="https://docs.google.com/document/d/1Wtv514fz-_xDgH7UdOQcxUWvB8RtdKU1SCm2G04YMEs/edit#heading=h.jyyw1x9ofb9x" target="_blank" rel="noopener"> step-by-step directions&lt;/a> and
&lt;a href="https://osf.io/ey4h6/" target="_blank" rel="noopener">example syllabi&lt;/a> that incorporate CREP&lt;/li>
&lt;li>
&lt;a href="https://twitter.com/CREP_psych" target="_blank" rel="noopener">CREP’s Twitter page &lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://jordanwagge.com/" target="_blank" rel="noopener">Jordan Wagge’s Website&lt;/a>: more information about Jordan and her Replication &amp;amp; Open Science Lab (ROSE)&lt;/li>
&lt;li>Read more about Jordan’s thoughts on CREP from her interview given to Avila University:
&lt;a href="https://www.avila.edu/2022/05/18/helping-students-become-better-scientists-through-authentic-research/" target="_blank" rel="noopener">Helping students become better scientists through authentic research&lt;/a>&lt;/li>
&lt;li>See
&lt;a href="https://www.canal-u.tv/chaines/univ-bordeaux/rkts-workshop/teaching-open-science-introducing-the-crep" target="_blank" rel="noopener">Dr. Fieke Wagemans&lt;/a> from the University of Duisburg Essen lead a conference session introducing CREP: recorded on September 2018 at the University of Bordeaux&lt;/li>
&lt;li>
&lt;a href="https://www.youtube.com/playlist?list=PLECcejm-vUj-kOyCGXxN2TeAFTRFj1HU1" target="_blank" rel="noopener">Youtube Playlist of CREP tutorials&lt;/a>: information on how to sign up for CREP, how to create a class OSF page, how to prepare and submit to CREP, and how to complete a CREP project&lt;/li>
&lt;li>
&lt;a href="https://docs.google.com/presentation/d/1s8BRZgHGhc1ncTy4rVIvr1KnmEm0qTrZzT7zyz_w12E/edit#slide=id.g1d4f756a301_0_0" target="_blank" rel="noopener">Google Slides presentation&lt;/a> on available studies for replication at CREP&lt;/li>
&lt;/ul>
&lt;br>
&lt;h2 id="suggested-citation">Suggested citation&lt;/h2>
&lt;p>Wagge, J., Beltran, J., &amp;amp; Hernandez, A. (2023). &lt;em>Open Science education through student participation: Integrating replication training into the classroom.&lt;/em> FORRT Pedagogies.
&lt;a href="https://doi.org/10.17605/OSF.IO/4JRFA" target="_blank" rel="noopener">https://doi.org/10.17605/OSF.IO/4JRFA&lt;/a>&lt;/p>
&lt;br>
&lt;hr>
&lt;br>
&lt;p>&lt;strong>Team Pedagogies Contributors:&lt;/strong>&lt;/p>
&lt;p>Jacob Miranda, California State University - East Bay, U.S.&lt;/p>
&lt;p>Julia Wolska, Manchester Metropolitan University, UK.&lt;/p>
&lt;p>Giorgia Andreolli, Verona University, Italy.&lt;/p>
&lt;p>Leticia Micheli, Leiden University, the Netherlands.&lt;/p>
&lt;p>Alessio Merighi, Video Editor,
&lt;a href="https://vimeo.com/user62908209" target="_blank" rel="noopener">https://vimeo.com/user62908209&lt;/a>&lt;/p></description></item><item><title>Developing principled pedagogies - An Open Science journey</title><link>https://forrt.org/pedagogies/002-gilad-feldman/</link><pubDate>Mon, 28 Nov 2022 10:44:40 -0400</pubDate><guid>https://forrt.org/pedagogies/002-gilad-feldman/</guid><description>&lt;br>
&lt;p>FORRT’s Pedagogies are back with no less than Gilad Feldman. Over the past years, Gilad has completely remodelled his research and teaching to incorporate several aspects of Open Science in a way that is certainly exemplary to many of us. In this FORRT’s Pedagogies, Gilad shares his materials and his insights about his own journey in Open Science. We hope that this can inspire and help many scholars wishing to incorporate more Open Science into their teaching and research.&lt;/p>
&lt;br>
&lt;p>Gilad Feldman is Assistant Professor at the Department of Psychology at the University of Hong Kong (HKU). His research focuses on judgement and decision making and he strongly supports the Open Science movement at all levels - from his teaching philosophy, to the development of open teaching materials and resources, and the involvement of students in Open Science training and practice. One of Gilad’s most known projects is the student-led pre-registered replications and extensions,
&lt;a href="https://mgto.org/core-team/" target="_blank" rel="noopener">which you can find here&lt;/a>. But be sure to check all his other amazing meta science resources such as his course syllabi and the “Check me, Replicate me” initiative (all links can be found below).&lt;/p>
&lt;p>FORRT’s Team Pedagogies took the opportunity to ask Gilad some questions on his journey through and with Open Science (shoutout to the FORRT and academic Twitter community for sending so many great questions). You can watch or listen to the interview in the video or read a summary of his main points below! We hope you enjoy and learn as much as we did!&lt;/p>
&lt;p>&lt;em>&lt;strong>Check out the full interview here&lt;/strong>&lt;/em>&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/kDEGwrz4V-E" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;ol>
&lt;li>&lt;strong>You have an incredible amount of Open Science resources ranging from courses and replications to incentives to other researchers to replicate or find mistakes in your own work. How did you embark on this Open Science journey?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: In 2015,
&lt;a href="https://www.science.org/doi/full/10.1126/science.aac4716" target="_blank" rel="noopener">the big Science paper&lt;/a> came out, showing replication rates that in my opinion were alarming. I didn’t understand how bad things really were until this paper came out. I remember being a postdoc and thinking that something big was happening and that I couldn’t in good faith continue with the research I was doing without figuring this out. I then started to think about my principles and decided on my main goals: my research has to be trustworthy, reproducible, replicable. Over time, I also started thinking about equity and inclusion issues. I set my own principles, such as to share materials, data and code. Back in 2016, this was scary stuff! I started to supervise students according to Open Science principles, and the CORE team (Collaborative Open-science and meta REsearch) developed from this. &lt;img src="FigQ1.PNG" alt="">&lt;/p>
&lt;br>
&lt;ol start="2">
&lt;li>&lt;strong>You have managed to put Open Science at the core of your teaching and research. Can you briefly mention the materials and activities you have developed in your own work to accelerate Open Science?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: First of all, I have not developed this on my own. I’ve decided that every time I’m going to make a guide or a template, I’m going to make it collaborative. Everyone who contributes to the document puts their name down and if we submit to a journal, they’re co-authors - from students to professors! We have created a bunch of resources, such as research assessments, community resources (e.g., guides on how to do replications and extensions, how to calculate effect sizes, etc.) and collaborative open resources for statistical analysis, such as the
&lt;a href="https://mgto.org/jamovijaspguide" target="_blank" rel="noopener">Jamovi guide&lt;/a>. Every time I see a need, I open a collaborative guide and share it with others (teaching assistants, students, external reviewers, the CORE team) and advertise it on Twitter. Guides have grown exponentially thanks to the community and now anybody can implement them. &lt;img src="FigQ2.PNG" alt="">&lt;/p>
&lt;br>
&lt;ol start="3">
&lt;li>&lt;strong>Did you face any challenges or critical incidents when incorporating Open Science into your teaching or research? What can scholars expect when embarking on this Open Science journey?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: Being completely open can be intimidating, and it takes some time to convince students that this model works. At the beginning the major issue was the lack of ready-made resources, but I feel that many of the initial challenges have been overcome.&lt;/p>
&lt;p>Psychologists study people, but we rarely point the research that we do to ourselves. I study judgment and decision-making and cognitive biases, and it is amazing how many of these biases we experience ourselves in the academic community and throughout the scientific process. There are lots of biases on how Open Science folks versus more status-quo researchers look at each other. I try to shield my team and students as much as possible from negative comments, but also want them to get a realistic view of the academic world, where there are lots of problems with ego, interests, cognitive biases and heuristics. I try to tell my students that in the end we all want the same thing: the science world is all of us working together. There are lots of challenges, we are humans, but we are learning as a community how to discuss these issues in the open. &lt;strong>Humility is key.&lt;/strong> Taking a step back and listening can help overcome these biases and help us learn from each other. &lt;img src="FigQ3.PNG" alt="">&lt;/p>
&lt;br>
&lt;h4 id="fostering-collaboration-from-the-teaching-portfolio-to-course-redesign">Fostering collaboration: from the teaching portfolio to course (re)design&lt;/h4>
&lt;hr>
&lt;br>
&lt;ol start="4">
&lt;li>&lt;strong>You have an amazing
&lt;a href="https://mgto.org/giladteachingportfolio" target="_blank" rel="noopener">teaching portfolio&lt;/a> where you detail all your teaching activities and present your teaching philosophy and goals. Could you tell us what you think are the key elements of your teaching philosophy?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: We really need to reorient what we do in education. I got a lot of inspiration from various projects, such as
&lt;a href="https://osf.io/wfc6u/" target="_blank" rel="noopener">CREP&lt;/a> and the
&lt;a href="https://psysciacc.org/" target="_blank" rel="noopener">Psychology Science Accelerator&lt;/a>. I believe that students and early-career researchers are key actors to address the replication crisis in science. We need to move away from the model of the professor standing in front of students with their powerpoint slides. I believe in alternative approaches such as &lt;strong>flipping the classroom&lt;/strong>. I’m also a fan of &lt;strong>problem-based learning&lt;/strong>: you give problems to students and they work together to figure it out. This works brilliantly in the undergraduate courses that I’m teaching in Hong-Kong. We need to teach students how to learn. We need to understand that science is messy. These are the principles I set (see image below):&lt;/p>
&lt;p>&lt;img src="FigQ4.PNG" alt="">&lt;/p>
&lt;p>I decided to share everything I create: slides, lectures, videos&amp;hellip; complete transparency! Everything students do is shared on
&lt;a href="https://osf.io/cyvtb/" target="_blank" rel="noopener">OSF&lt;/a>, which may be scary initially, but increases the sense of accountability. And students understand the importance of doing this: even if there’s the possibility of error, you want to be transparent about the process, &lt;strong>so other people can help you do better&lt;/strong> or find your mistake. In fact, there are lots of reasons why I started with replications and extensions: they are more practical, measurable, systematic, valuable for students in their learning journeys and overall more instructive. I believe that this helps students develop their &lt;strong>scientific thinking&lt;/strong>, whatever career path they decide to take.&lt;/p>
&lt;br>
&lt;ol start="5">
&lt;li>&lt;strong>Collaboration is one of the pillars of your pedagogy, and in your syllabi you mention a
&lt;a href="https://mgto.org/teamcontracttemplate" target="_blank" rel="noopener">“team contract”&lt;/a> that is created together with the students. Could you explain what this team contract is? Why and how investing in/learning team communication can be connected with Open Science practices?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: Team contract is something relatively new that really boosted collaborative work in my courses, mostly because it helps to align expectations. Students sometimes do not like to work together, and they’re used to multiple choice exams and a more structured model. But there is something very important about teamwork, also later when starting to work in a paid job. The most common complaint in my teaching evaluations at the beginning was: “we do not like to work in teams, we prefer to work individually, whenever we work in teams there are a lot of free-riders”. The team contract helps the team to solve issues students might face and it can be adjusted over the semester: basically, it’s about getting the team together to get to know each other and discuss their project following a
&lt;a href="https://mgto.org/teamcontracttemplate" target="_blank" rel="noopener">flexible template&lt;/a>. For example, as part of the team contract, students do a “pre-mortem”: they are asked to imagine an issue has happened, what they would do and how they could have prevented it from happening. At the end of the semester, we ask students to
&lt;a href="https://mgto.org/teamworkreporttemplate" target="_blank" rel="noopener">&lt;strong>reflect on their learning journey&lt;/strong>&lt;/a> (what they did compared to what they planned). Then, students are required to grade themselves. Everyone was very humble and understood that it is not about me telling them “you have to learn this way”. It is about them setting their own goals, holding themselves accountable, overcoming challenges and reflecting on their journey. In fact, they all got precisely the grade they assigned themselves.&lt;/p>
&lt;br>
&lt;ol start="6">
&lt;li>&lt;strong>Over time, how did you (re)design your courses to include Open Science principles?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: At the University of Hong Kong, I am very privileged. I have a lot of freedom and flexibility. It is not a big deal to include Open Science principles into my own courses. &lt;strong>I just try things out.&lt;/strong> Whenever I see a good idea, I try to embed it in my teaching. My students are very open-minded and let me do this and evolve together with me.&lt;/p>
&lt;br>
&lt;h4 id="mass-replications--extensions-workflow-students-feedback-and-co-authorship">Mass Replications &amp;amp; Extensions: workflow, students’ feedback and co-authorship&lt;/h4>
&lt;hr>
&lt;br>
&lt;ol start="7">
&lt;li>&lt;strong>You have conducted several replications within your courses. Could you walk us through how it works from beginning to end? For example could you share the administrative/organisational side of it? How many students are involved in each course/replication and how do you motivate students to participate in replications?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: This is complex - I usually give 3 hour workshops on replications! In terms of numbers, some of the courses I teach are large, with 70 students per class. Recently, in the more advanced courses I got about 20 students. &lt;strong>We do two types of projects.&lt;/strong> At the beginning, we completed &lt;strong>pre-registered replications and extensions.&lt;/strong> Within one semester, students went from basic statistics skills to a completed manuscript that was ready to be submitted - with everything written up, from preregistration to data analysis and so on. In 2020, we moved to a model of Registered Reports Stage 1. We got a lot of rejection letters from journals telling us about all the issues in our replications, based on outcome bias and hindsight bias. This is something that &lt;strong>Registered Reports&lt;/strong> tackle very well: I got students to write a Stage 1 Report with a simulated dataset (Qualtrics helps with this) and detailed methodology and analysis sections. The workflow is shown in the image below: &lt;img src="FigQ7.PNG" alt="">&lt;/p>
&lt;p>For pre-registered replications, the schedule is very tight, and everything is done within a month and a half. Then, I usually don’t sleep for two or three weeks and give two or three teams the same dataset, so that they can peer review one another. Finally, they produce a final report and an early-career researcher takes the lead as first author. Everybody takes credit and everything is written down. We still have about 25 unfinished projects - so if anybody in the FORRT community is interested, they can come and work with us!&lt;/p>
&lt;p>A very similar model is applied to Stage 1 Registered Reports, but without the data collection, while the model for thesis students is a bit different. They have one year, and they do a registered report. We then submit everything to
&lt;a href="https://peerj.com/blog/post/115284884044/peerj-journals-support-peer-community-in-registered-reports/#:~:text=Peer%20Community%20In%20Registered%20Reports%20%28PCI%20RR%29%20is%20a%20community,design%2C%20rather%20than%20the%20results." target="_blank" rel="noopener">Peer Community in Registered Reports&lt;/a>. In terms of impact, students not only gain a publication but they have their chances of being hired (both in academia and industry) increased. This can make a difference for them, so they are very &lt;strong>enthusiastic and motivated.&lt;/strong> They are serious about the work and they know the course itself is different from other courses - hands-on, &lt;strong>learning by doing&amp;hellip;&lt;/strong> Some students appreciate this, but not everybody. Students with other preferences can drop out and choose other courses offered at HKU.&lt;/p>
&lt;br>
&lt;ol start="8">
&lt;li>&lt;strong>As one of your teaching goals, you have mentioned that “students experience the research process from beginning to end”. One of the most amazing things of the Mass Replications and Extensions is that students do make actual contributions to science. In your view, what is the role of students’ contributions to academic literature? Could you share with us the feedback that you got from students involved in replications?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: Students can feel a lot of pressure, a lot of tension, during the process. Especially at the beginning. It’s so different from everything they have done before, so this can lead to some frustrations… I get some emails from students who have graduated and transitioned to industry, and reflecting back they are able to see these courses as a &lt;strong>meaningful&lt;/strong> part of their journey (for good or bad). Some of them understand that science is messy, and others had never imagined they could have a contribution as undergraduates. It’s about empowering &lt;strong>students to take part in the process&lt;/strong>. One thing I try to show them is how many mistakes professors make and that everybody is capable of contributing, helping us do better. Overall, many students find it meaningful, if not memorable - and they’ve learned important skills in the end. This is my aim and what I was hoping for.&lt;/p>
&lt;br>
&lt;ol start="9">
&lt;li>&lt;strong>You published several replications that started out as replications in classrooms. Were students interested in contributing to the research papers as co-authors after the end of the course? Can you explain how authorship is attributed and agreed upon?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: This is an aspect that needs to be sorted out very early on, and we follow a very strict model. In my syllabus there’s a passage about “what it means to take part in this course”. &lt;strong>Everybody is a co-author by default&lt;/strong>, but it’s possible to opt out if one makes it clear at the beginning (and reiterates it at each submission). Until now, and it’s been four years, nobody has opted out. In addition, we don’t want people to be forced by omission, and must ensure that the &lt;strong>implications of this model are clear to them.&lt;/strong> The co-authorship model is explained to them early on, like a co-authorship contract: this is definitely very important to align expectations. I use a mandatory &lt;strong>quiz&lt;/strong> on the course to collect their agreement and keep a written record (we also ask permission to submit articles in their name even after graduation). So, generally, every student is a co-author, with clear documentation of their contribution. We also have a &lt;strong>credit contributorship&lt;/strong> where we keep track of what students, teaching assistants and early-career researchers bring in. Sometimes reviewers push back, so this document is useful to support and justify authorship attribution. Students did everything in their submissions. I guided them here and there but it’s really them who deserve the credit for the initial draft. It is open, transparent and collaborative work, with no room for misunderstandings.&lt;/p>
&lt;p>In my PhD, I just remember a lot of interactions between students and professors where professors put themselves as first authors and some students were not even mentioned. I don&amp;rsquo;t understand how this is &lt;strong>a sustainable system&lt;/strong>. It&amp;rsquo;s not fair, it&amp;rsquo;s not equitable, it’s not ethical. Undergraduate students, sometimes even high school students, can do science. There&amp;rsquo;s nothing about me having a professor title that makes me more eligible for co-authorship than a student. I believe in as much inclusion as possible, and &lt;strong>it doesn&amp;rsquo;t matter where you come from, what rank you are, how old you are. Everybody should be acknowledged and included.&lt;/strong>&lt;/p>
&lt;br>
&lt;ol start="10">
&lt;li>&lt;strong>You also encourage other researchers to check and replicate your own work (Check me, Replicate me). Do you also incorporate this in your courses, letting students check your own work? Can you explain how that works?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: I started in 2019 to do assessments with students, because I understood that before we do replications students need to see how others do replications. I just wanted them to go and have a look at the top-notch replication work in our field. I realized that I really worry that in ten, twenty years somebody is going to find an error that I have made… and funding, millions of dollars, hundreds of hours are going to be wasted! This is partially why I open up everything: I want others to be able to check, for example, my code - which is something that, when you go through peer review, can be overlooked. So I turned this into a learning opportunity. In 2020, we checked our replication reports from 2019. In 2021, we checked our replication reports from 2020, and so on. I was hoping (praying!) that, on the one hand, students wouldn’t find mistakes. On the other hand, though, if there were mistakes I really wanted students to find them.
&lt;a href="https://mgto.org/check-me-replicate-me/" target="_blank" rel="noopener">Last year I created a section of my website&lt;/a> where I wrote “I will pay you 5 USD for a minor error, and 50 USD for a major error”. To my great surprise, students found mistakes and I paid them quite a bit of money (which they decided to donate to charity). Win-win. I’m promoting this “Check me, Replicate me” as a pledge that other people can also incorporate and I hope that we&amp;rsquo;ll be able to do more of that in the future.&lt;/p>
&lt;br>
&lt;ol start="11">
&lt;li>&lt;strong>Do you have any general advice for new(ish) researchers wanting to be more open and transparent about their research and to educators wanting to implement Open Science in their teaching and mentoring?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Gilad&lt;/strong>&lt;/em>: The best way is to just get started. I was able to put my research aside for a year. If you can’t, try to incorporate some Open Science principles in your work. If you can’t free yourself, start doing this with a masters student, as part of a collaboration. Join a team that does this kind of stuff. &lt;strong>I suggest starting very, very simple, and building up.&lt;/strong> We started with a very simple replication, a very simple main effect. It doesn’t have to be complicated, just be as transparent as possible. If you’re too scared, invite me, and I’ll show you how to do it. But in general, start small, or join a big team and see what you can learn. &lt;img src="FigQ11.PNG" alt="">&lt;/p>
&lt;br>
&lt;br>
&lt;p>&lt;em>&lt;strong>All links to Gilad Feldman’s teaching resources&lt;/strong>&lt;/em>&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://mgto.org/giladteachingportfolio" target="_blank" rel="noopener">Teaching Portfolio:&lt;/a> a document detailing achievements, teaching philosophy, goals and practices at HKU (2021)&lt;/li>
&lt;li>
&lt;a href="https://osf.io/cyvtb/" target="_blank" rel="noopener">Course Materials:&lt;/a> these include course summaries, syllabi, lecture slides, tutorials, teaching evaluations, and videos&lt;/li>
&lt;li>Open Science Talks and Workshops (since 2020): recordings are available on
&lt;a href="https://osf.io/df9tj/" target="_blank" rel="noopener">OSF | Open Science Talks and Workshops&lt;/a> and Gilad&amp;rsquo;s
&lt;a href="https://www.youtube.com/c/GiladFeldmanScience/playlists" target="_blank" rel="noopener">Youtube channel&lt;/a>&lt;/li>
&lt;li>A list of
&lt;a href="https://mgto.org/resources/" target="_blank" rel="noopener">collaborative and open resources:&lt;/a> guides and tutorials, examples of students’ work, templates, open projects for early-career researchers&lt;/li>
&lt;li>Resources about
&lt;a href="https://mgto.org/open-science/" target="_blank" rel="noopener">Open Science and the Science Reform&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://mgto.org/core-team" target="_blank" rel="noopener">Collaborative Open-science and meta REsearch:&lt;/a> information on the project, mass replications and extensions, the team and how to get involved&lt;/li>
&lt;li>
&lt;a href="GF-interview.pdf">The .pdf version of this page, with Gilad&amp;rsquo;s answers to the community&amp;rsquo;s question&lt;/a>&lt;/li>
&lt;/ul>
&lt;br>
&lt;p>&lt;em>&lt;strong>Suggested Citation&lt;/strong>&lt;/em>&lt;/p>
&lt;hr>
&lt;p>Feldman, G. (2022). Developing principled pedagogies - An Open Science journey: Insights from incorporating open science into teaching and mentoring. &lt;em>FORRT Pedagogies&lt;/em>. &lt;a href="https://doi.org/10.17605/OSF.IO/QNCBF">https://doi.org/10.17605/OSF.IO/QNCBF&lt;/a>&lt;/p>
&lt;br>
&lt;p>&lt;strong>Team-Pedagogy Contributors&lt;/strong>:&lt;/p>
&lt;hr>
&lt;p>
&lt;a href="mailto:giorgia.andreolli@univr.it">Giorgia Andreolli&lt;/a>, Verona University, Italy&lt;/p>
&lt;p>
&lt;a href="mailto:juliawolska@gmx.de">Julia Wolska&lt;/a>, Manchester Metropolitan University, UK&lt;/p>
&lt;p>
&lt;a href="mailto:fa441@cam.ac.uk">Flavio Azevedo&lt;/a>, Cambridge University, UK.&lt;/p>
&lt;p>
&lt;a href="mailto:l.rettore.micheli@fsw.leidenuniv.nl">Leticia Micheli&lt;/a>, Leiden University, the Netherlands.&lt;/p></description></item><item><title>Open and Reproducible Science walks into a classroom</title><link>https://forrt.org/pedagogies/001-julia-strand/</link><pubDate>Sat, 03 Oct 2020 10:44:40 -0400</pubDate><guid>https://forrt.org/pedagogies/001-julia-strand/</guid><description>&lt;br>
&lt;p>Welcome to FORRT&amp;rsquo;s first Pedagogy. And what better way to kickstart this initiative than hosting a researcher and educator who has been widely recognized by her peers for her outstanding course and materials on theory of Open and Reproducible Science called &lt;em>Psychology’s Credibility Revolution&lt;/em>?&lt;/p>
&lt;p>FORRT is delighted to partner up with
&lt;a href="https://apps.carleton.edu/curricular/psyc/jstrand/" target="_blank" rel="noopener">&lt;em>Julia Strand&lt;/em>&lt;/a> for its first Pedagogy!&lt;/p>
&lt;p>&lt;em>&lt;strong>Check out her course announcement (and teaser!)&lt;/strong>&lt;/em>&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/k4MJkLR-rvw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;p>Julia Strand is Associate Professor of Psychology at Carleton College and she teaches courses such as Introduction to Psychology, The Psychology of Spoken Words and Sensation and Perception. Julia has also recently prepared and taught a course on Psychology’s Credibility Revolution (
&lt;a href="https://docs.google.com/presentation/d/e/2PACX-1vREwmeADm5WZCBfjAKyAkzYC_cQb7xtYv6C7e_wBJx0BUhJ3lFY0WABpIb0XotJake0Xrh-CC6g1Vwy/pub?start=false&amp;amp;amp;loop=false&amp;amp;amp;delayms=99999999&amp;amp;slide=id.g93d3e0908d_0_316" target="_blank" rel="noopener">link&lt;/a>) which excels in all aspects (e.g., content, creativity, visuals, &amp;amp; functionality).&lt;/p>
&lt;p>FORRT has reached out to the academic community on social media to ask which questions other scholars would like Julia to answer about her teaching materials on the Psychology’s Credibility Revolution course (on both technical and non-technical spheres). Below you can find Julia’s answers to these questions. And you can also find
&lt;a href="https://osf.io/zpb8a/" target="_blank" rel="noopener">in this OSF repository&lt;/a> Julia’s complete teaching materials, from which everyone can learn, adapt, or repurpose.&lt;/p>
&lt;p>Kudos to Julia for preparing such an amazing course and many thanks to her for being so open to partner up with FORRT to share her pedagogies with the wider community. We hope this can serve as an inspiration and help scholars, instructors and educational institutions interested in integrating open and reproducible scholarship tenets in their teaching and mentoring. &lt;img src="interview.jpg" alt="">&lt;/p>
&lt;br>
&lt;ol>
&lt;li>&lt;strong>What is your teaching philosophy behind the course
&lt;a href="https://docs.google.com/presentation/d/e/2PACX-1vREwmeADm5WZCBfjAKyAkzYC_cQb7xtYv6C7e_wBJx0BUhJ3lFY0WABpIb0XotJake0Xrh-CC6g1Vwy/pub?start=false&amp;amp;amp;loop=false&amp;amp;amp;delayms=99999999&amp;amp;slide=id.g93d3e0908d_0_316" target="_blank" rel="noopener">&lt;em>“Psychology’s Credibility Revolution”&lt;/em>&lt;/a>?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: I’m trying to do two things with this class. The first is to familiarize students with concepts related to the replication crisis and subsequent credibility revolution. The second is to prepare my students to write their senior honors theses. At Carleton, all students complete a capstone project for their major (“comps”). In the Psychology department, the foundation of that comps is the term paper written in a seminar students take in the fall of their senior year. My Credibility Revolution course is one of those seminars. So in this course, I’m balancing teaching content with helping provide students with the tools they need to write their comps. The comps papers from my section are on a research topic of the student’s choosing, but written through the lens of something we’ve discussed. I’ve had students conduct systematic reviews, trace how findings have replicated (or not) on a particular topic, and evaluate the construct validity of measurement scales, among many others.&lt;/p>
&lt;p>I want students to come away from this course with an appreciation for how research is actually conducted, how the incentive structure of academia can be at odds with scientific rigor, and how we can change our field to encourage science that is rigorous, transparent, and reproducible. I’ve found that teaching open science is a great way to help students be more critical consumers of the literature. I know that many of my students won’t go on to do research in Psychology themselves, but I want them all to have an appreciation for how to evaluate research.&lt;/p>
&lt;ol start="2">
&lt;li>&lt;strong>Could you share your thoughts on how well the students grappled with the material and assignment in this course? Do you have an impression of whether this course influenced your students’ approaches to their own research projects?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: Students can really get into this content! I’ve found that talking about open science has a relatively low barrier to entry, even for undergrads. Although it may take time to build up enough subject area expertise to evaluate psychological theories or models, students can readily understand why misplaced incentives will affect behavior, why questionable research practices lead to findings that can’t replicate, and so on. For example, I’ll describe two studies that are intended to test the same question (i.e., studies on age-related priming conducted by
&lt;a href="https://psych.unl.edu/mdodd/Psy498/BarghPrime.pdf" target="_blank" rel="noopener">John Bargh&lt;/a> vs
&lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029081" target="_blank" rel="noopener">Stéphane Doyen&lt;/a>) but differ in methodology. Students then brainstorm all the reasons why the two studies may have reached different conclusions. They are incredibly thoughtful and thorough in identifying all the ways the choices that researchers make can influence the outcome of the study.&lt;/p>
&lt;p>I ask my students for their impressions of how the course has changed how they engage with the literature, and they almost uniformly say they read more critically. They also regularly say (to my great delight!) that they pay much more attention to the methods sections.&lt;/p>
&lt;ol start="3">
&lt;li>&lt;strong>Did you face any barriers to teaching about the credibility revolution? And if so, how did you overcome these?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: I haven’t, really! My department is very supportive of letting faculty choose their own topics in these seminars and has been quite receptive to my incorporating open science principles in my teaching and research.&lt;/p>
&lt;ol start="4">
&lt;li>&lt;strong>How many times have you taught this course? Could you give an indication of how much the course has developed over time?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: I’ve taught it twice and will teach it again next year. The course has changed somewhat as I’ve looked for the right balance between teaching content and preparing my students for working on their senior theses. It also changes a bit each time because open science moves fast, so I need to update the content! But the basic bones of the course have been fairly consistent.&lt;/p>
&lt;ol start="5">
&lt;li>&lt;strong>Is there anything that you didn&amp;rsquo;t have time to cover in this course but wish you did?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: So many things. Given that Carleton is on trimesters and our terms are a short 9.5 weeks, and we also spend a substantial portion of that doing things related to comps, there are many topics I’d love to be able to include:
&lt;a href="https://www.barelysignificant.com/post/summersaga/" target="_blank" rel="noopener">the alpha wars&lt;/a>, philosophy of science, computational and statistical reproducibility, meta-analyses, Bayesian vs frequentist approaches, and more. I ended up cutting content this year to take off pressure around the U.S election, as well.&lt;/p>
&lt;ol start="6">
&lt;li>&lt;strong>What aspects of the course material do you think are the most important? For example if you only had 6 weeks to deliver this course.&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: It can be very easy for courses of this nature to be very pessimistic. The last thing I want is for students to come away with the sense “science is broken and everything is doomed.” So I spend a lot of time and energy helping them to understand all the ways our discipline, and science generally, has figured out to improve the practice of how we do science! I named this course Psychology&amp;rsquo;s Credibility Revolution rather than Psychology’s Replication Crisis because I really wanted to emphasize that the reforms of the last decade are changing how we do science, for the better.&lt;/p>
&lt;ol start="7">
&lt;li>&lt;strong>Do you have a favorite part of the course? Do you think your students have a favorite too?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: I love thinking about and teaching measurement and construct validation. I also love Halloween, and it works very nicely that my lessons on those topics tend to be around Halloween time. I created a fake scale that is intended to measure a construct called “Halloweenophilia” (an overwhelming love of all things halloween related) and ask students how they’d assess the construct validation of the instrument. It’s both spooky and fun.&lt;/p>
&lt;ol start="8">
&lt;li>&lt;strong>Did you develop your materials from other teaching materials you found? And, what are your thoughts on adapting other’s teaching materials and making these available?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: One reason I was keen to make my course publicly available is that others who teach similar courses have been so generous in sharing their materials! When I started designing this course, I combed through all the syllabi I could find online and made lots of notes about strategies I wanted to emulate and readings to adopt. So I’m happy to facilitate others doing the same.&lt;/p>
&lt;p>A thing about teaching I wish I’d known earlier is that teaching doesn’t have to include a high proportion of invention. I adopt ideas from other teachers all the time. In fact, even if we don’t intend to, all of our teaching philosophies and approaches must be shaped by the courses we’ve taken and strategies we’ve seen others use.&lt;/p>
&lt;p>Instructors need to curate the available resources/readings/assignments/approaches to achieve their course goals, fit their student population, etc, but they don’t need to design every single thing from scratch. In fact, adopting some materials from others frees you up to put more thought and energy into the aspects of your class that you create from scratch.&lt;/p>
&lt;ol start="9">
&lt;li>&lt;strong>Do you have any general advice for a new(ish) lecturer wanting to organise a course similar to this?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: Don’t be afraid to take inspiration from and borrow from others (see answer to question 8 above)!&lt;/p>
&lt;ol start="10">
&lt;li>&lt;strong>In addition to the materials themselves (which are awesome), what should other teachers know or bear in mind when teaching this/similar material?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;em>&lt;strong>Julia&lt;/strong>&lt;/em>: One challenge I faced is that much of this content is very interconnected—it’s hard to talk about low rates of replication without discussing publication bias, which is hard to talk about without mentioning null hypothesis significance testing, which then gets you into talking about alternatives to p-values….Which is all great, but it can be hard to wait weeks to talk about some topic that seems integral to understanding earlier content. So I think teaching this content requires coming to terms with the fact that you can’t do everything, and can’t do everything at once.&lt;/p>
&lt;p>I’d also recommend using concrete examples from content areas you know well. My research is on spoken word recognition and listening effort (the cognitive resources necessary to understand speech), so when I teach content on measurement for example, I talk a lot about different ways of measuring listening effort. Working through examples that you are very familiar with can help students get an appreciation of the complexities of decisions about experiment design.&lt;/p>
&lt;ol start="11">
&lt;li>&lt;strong>A few final, quick-fire technical questions: how did you record the lectures? How did you edit the lectures (e.g. to have your face and slides on screen)? How do you make the cartoon character of yourself?&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>See Julia’s response to all these technical questions in this great video she prepared!&lt;/p>
&lt;br>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/vi1BxZ1MIaE" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;br>
&lt;p>&lt;em>&lt;strong>All links&lt;/strong>&lt;/em>&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://docs.google.com/presentation/d/e/2PACX-1vREwmeADm5WZCBfjAKyAkzYC_cQb7xtYv6C7e_wBJx0BUhJ3lFY0WABpIb0XotJake0Xrh-CC6g1Vwy/pub?start=false&amp;amp;amp;loop=false&amp;amp;amp;delayms=99999999&amp;amp;slide=id.g93d3e0908d_0_316" target="_blank" rel="noopener">Course Syllabus&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://osf.io/zpb8a/" target="_blank" rel="noopener">OSF Component in Pedagogies with all Julia&amp;rsquo;s course materials and assignments&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://youtu.be/vi1BxZ1MIaE" target="_blank" rel="noopener">YouTube video on technical details of her course&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.youtube.com/watch?v=k4MJkLR-rvw" target="_blank" rel="noopener">Teaser for Julia’s Psychology course on “Psychology&amp;rsquo;s credibility revolution&lt;/a>&lt;/li>
&lt;li>
&lt;a href="JS-interview.pdf">The .pdf version of this page, with Julia&amp;rsquo;s answers from the community&amp;rsquo;s question&lt;/a>&lt;/li>
&lt;/ul>
&lt;br>
&lt;p>&lt;em>&lt;strong>Suggested Citation&lt;/strong>&lt;/em>&lt;/p>
&lt;p>Strand, J. (2020) Open and Reproducible Science walks into a classroom: Insights from teaching a course on Psychology’s Credibility Revolution. &lt;em>FORRT Pedagogies&lt;/em>. &lt;a href="https://doi.org/10.17605/OSF.IO/ZPB8A">https://doi.org/10.17605/OSF.IO/ZPB8A&lt;/a>&lt;/p>
&lt;p>&lt;strong>Team-Pedagogy Contributors&lt;/strong>:&lt;/p>
&lt;hr>
&lt;p>
&lt;a href="mailto:l.rettore.micheli@fsw.leidenuniv.nl">Leticia Micheli&lt;/a>, Leiden University, the Netherlands.&lt;/p>
&lt;p>
&lt;a href="mailto:fa441@cam.ac.uk">Flavio Azevedo&lt;/a>, Cambridge University, UK.&lt;/p></description></item></channel></rss>