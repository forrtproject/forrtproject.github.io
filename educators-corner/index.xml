<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Educators' Corner | FORRT - Framework for Open and Reproducible Research Training</title><link>https://forrt.org/educators-corner/</link><atom:link href="https://forrt.org/educators-corner/index.xml" rel="self" type="application/rss+xml"/><description>Educators' Corner</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2024 - FORRT Framework for Open and Reproducible Research Training</copyright><image><url>https://forrt.org/img/FORRT_banner.svg</url><title>Educators' Corner</title><link>https://forrt.org/educators-corner/</link></image><item><title>Shifting the culture of peer review with Reviewer Zero</title><link>https://forrt.org/educators-corner/016-reviewer-zero/</link><pubDate>Fri, 01 Dec 2023 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/016-reviewer-zero/</guid><description>&lt;br>
&lt;h3 id="background-of-reviewer-zero">Background of Reviewer Zero&lt;/h3>
&lt;p>The experiences with peer review that we share here are, unfortunately, not uncommon. Comments like these – and others that are unduly harsh, belittling, racist, sexist, or otherwise inappropriate – have been received by scholars at all career stages during peer review. These experiences provide a starting point to question normative practices in scientific peer review, and identify the hidden and blatant consequences for early career scholars - particularly those from underserved groups. Most importantly, we can ask what each of us might do to shift this culture.&lt;/p>
&lt;p>
&lt;a href="https://www.reviewerzero.net/" target="_blank" rel="noopener">Reviewer Zero&lt;/a> is a collective founded in 2020 to take concrete, data-driven, anti-racist action to improve the culture of scientific peer review. We were formed with guidance from
&lt;a href="https://www.sparksociety.org/" target="_blank" rel="noopener">SPARK Society&lt;/a> — an organization that improves visibility and provides mentorship opportunities for cognitive scientists of color. Our broad aim is to change cultural norms in the peer review process, in order to improve the recruitment, retention, and advancement of minoritized scholars in psychology. Collectively, we are a group who has experienced hundreds of rejections and written hundreds of reviews. We’ve received decision letters accepting and rejecting our work, and we have written decision letters accepting or rejecting others’ work.&lt;/p>
&lt;p>Like readers of this blog, Reviewer Zero members know that science can be better than it is, and that shifting the status quo is not easy. The culture of science matters for who engages with it, and normative experiences within a culture can produce different consequences if individuals see themselves as safe or threatened within that culture. The experience of peer review as hostile or negative sets the stage for disparate impacts for minoritized individuals. For example, a survey of peer review experience
&lt;a href="https://www.zotero.org/google-docs/?wtZdP5" target="_blank" rel="noopener">(Silbiger &amp;amp; Stubler, 2019)&lt;/a> found that experiences of unprofessional peer review were quite common - reported by 50% of scientists in the survey. However, individuals from minoritized groups reported a stronger negative impact of these unprofessional reviews, compounding the impact of other biases against such individuals (see our forthcoming review Aly et al., in press, for further discussion;
&lt;a href="https://psyarxiv.com/435xz/" target="_blank" rel="noopener">preprint available&lt;/a>).&lt;/p>
&lt;p>To understand peer review from the perspective of early career researchers who are underserved by the status quo, Reviewer Zero conducted a survey in 2020 of early career researchers in psychology / neuroscience.
&lt;a href="https://osf.io/jqy4k" target="_blank" rel="noopener">Our results&lt;/a> are not surprising: We found that cis-men of color reported less helpful feedback compared to White cis-men, and women/nonbinary respondents were more likely than cis-men to report that their peer review experience reduced their belonging in science. Qualitative results from a free-response question about the most memorable experiences with peer review were eye-opening, and heartbreaking. Respondents reported receiving harsh feedback, racist comments, and feeling so demotivated that they left those research topics behind. But there is also opportunity for change: This survey also showed that authors can feel motivated when the process is perceived as fair or when reviews note strengths of the work.&lt;/p>
&lt;p>&lt;img src="pic_rz.jpg" alt="Picture showing harsh reviewer comments" title="Picture showing harsh reviewer comments">&lt;/p>
&lt;p>Harsh reviewer comments can have disparate impacts, demotivating early career researchers and driving them away from the field.&lt;/p>
&lt;p>Photo by
&lt;a href="https://unsplash.com/@kobuagency?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener">KOBU Agency&lt;/a> on
&lt;a href="https://unsplash.com/photos/7okkFhxrxNw?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash&lt;/a>&lt;/p>
&lt;h3 id="how-reviewer-zeros-mission-intersects-with-the-open-science-community">How Reviewer Zero’s Mission Intersects with the Open Science Community&lt;/h3>
&lt;p>As efforts to improve scientific practice and policy toward more openness and transparency take shape, it is essential to consider who is designing these systems and what perspectives they reflect. To build systems that are truly open and accessible for a global psychological science, we must take proactive steps to include different perspectives, identities, and voices in creating and changing systems. Here, we walk through examples of two kinds of openness that can have implications for minoritized or underserved groups. The essential questions are who is being asked to be “open,” and at what cost?&lt;/p>
&lt;p>One innovation in peer review is
&lt;a href="https://forrt.org/glossary/open-peer-review/" target="_blank" rel="noopener">open peer review&lt;/a>, which includes disclosure of author and reviewer identities and reviews. Open peer review can include different levels of disclosure: For example, greater transparency without identification can occur if reviews are public but reviewers are not identified. Although identified peer review can have some advantages in that reviewers are clearly accountable to what they write in a review, this system may not be equitably open to all. Individuals who occupy less powerful positions, whether due to their career stage or underrepresented group identities, may experience more backlash or more negative consequences in offering critique – or their perspectives may simply be dismissed in favor of reviews from people who hold more power or come from majority groups. Transparent peer review, where reviews are public but reviewer identities are not, might offer greater security to reviewers. From an author perspective, though, individuals who are contending with identity threat may be unwilling (for good reason) to have critiques of their work openly aired (for further discussion, see our forthcoming review paper; Aly et al., in press). The very ability to engage in different aspects of open peer review can vary across individuals with different levels of power in a system.&lt;/p>
&lt;p>Would greater openness in peer review make hostile and unprofessional reviews less likely, or would greater openness in peer review exacerbate negative consequences for members of historically excluded groups? We don’t know the answer to these questions, but we need to ask them.&lt;/p>
&lt;p>Given that hostile or unprofessional reviews can be common, individuals from historically excluded groups might steer away from participating in open review processes. Navigating peer review is challenging enough without doing so in public. One example comes from Dr. Colleen Murphy, who tweeted in response to
&lt;a href="https://elifesciences.org/inside-elife/54d63486/elife-s-new-model-changing-the-way-you-share-your-research" target="_blank" rel="noopener">eLife’s move to drop accept/reject decisions&lt;/a>:&lt;/p>
&lt;p>&lt;img src="tweet_rz.png" alt="Tweet about misogynistic peer-review" title="Tweet about misogynistic peer-review">&lt;/p>
&lt;p>The inequities present in peer review need to be addressed before there is any possibility of open review serving a wide range of scholars. Without a deliberate effort to change the existing culture in a way that advances diversity, equity, and inclusion, other efforts might perpetuate or exacerbate these inequities.&lt;/p>
&lt;p>A different form of openness, transparency, and accountability in peer review comes from institutions or organizations. It is not yet routine for journals, societies, or editors to collect or share aggregate-level data about the demographic or identity characteristics of editors, editorial board members, reviewers, or authors. Yet knowing this information could provide valuable insights about who is served by the current practices and how that might change with reforms. What are the demographic or identity characteristics of the editorial board and reviewers? Who is submitting papers, who is being invited to resubmit papers, who appeals editorial decisions, and what are the outcomes? Data about these aspects of scientific publishing are rarely collected, rarely examined by journal staff, and are even more rarely shared with the community. Without transparency and accountability in terms of representation, editor and reviewer choices tend to rely on individuals’ own social networks and perpetuate gender and race homophily. This reliance on social networks may be exacerbated by the growing difficulties with finding scholars to agree to provide peer reviews (Petrescu &amp;amp; Krishen, 2022). Editors may rely on close colleagues who are willing to do them a favor by providing a review, which can in turn further narrow the pool of reviewers and the types of feedback authors get. To counteract this tendency, journals can publicize calls for individuals to register as new reviewers, so that editors have accessible and current listings of scholars with expertise and availability. Generally speaking, clearer and more transparent data about who engages with peer review and how they do so can inform innovations to ease burdens on editors and provide more diverse slates of reviewers.&lt;/p>
&lt;h3 id="how-reviewer-zero-and-forrt-work-together">How Reviewer Zero and FORRT work together&lt;/h3>
&lt;p>Like FORRT, Reviewer Zero seeks to illuminate the black box of scientific and academic culture. Peer review is central to scientific careers, but peer review is often left to the “hidden curriculum” of processes that people learn as they go without explicit discussion or training. To bring some light to these unknown processes, Reviewer Zero hosts workshops (both online and at in-person conferences) for both early-career scholars and for editors and reviewers. In the sessions aimed at trainees and early career scholars, we introduce the basics of peer review, to consider the emotional and motivational aspects of navigating peer review, and to provide concrete tools and strategies for responding to editorial decisions. In workshops with editorial teams, we lead discussions about the current culture of peer review and its implications for perpetuating disparities in who contributes to and advances in science, and we discuss concrete steps toward a more constructive and inclusive peer review culture.&lt;/p>
&lt;p>Reviewer Zero is developing
&lt;a href="https://osf.io/e7z5k/" target="_blank" rel="noopener">on-demand resources&lt;/a> based on these workshops, and these can complement FORRT resources offered in the adopting principled education section of the website. We particularly advocate for collaboration and conversation moving forward, for identification and promotion of strategies that can advance diversity, equity, and inclusion both in peer review systems and the goals of open science. At times, as noted above, these goals might appear to be in tension with each other - but that should be the start rather than the end of the conversation.&lt;/p>
&lt;h3 id="call-to-action">Call to action&lt;/h3>
&lt;p>Each of us plays a part in maintaining or changing the culture of scientific peer review. We invite you to join us to stay updated on activities at
&lt;a href="http://www.reviewerzero.net" target="_blank" rel="noopener">www.reviewerzero.net&lt;/a> and to explore our developing
&lt;a href="https://osf.io/e7z5k/wiki/Resources/" target="_blank" rel="noopener">on-demand resources&lt;/a>.&lt;/p>
&lt;p>There are steps you can take today to move toward a more constructive and equitable peer review system. As with any culture change, shifting a culture requires multiple actors to begin to think and act differently, and cultural change is more possible when actors at different levels of the system take part
&lt;a href="https://www.zotero.org/google-docs/?fmR3wF" target="_blank" rel="noopener">(Hamedani &amp;amp; Markus, 2019)&lt;/a>. If you are someone with power in the system, with experience, and/or with a majority group identity, support minoritized and early career scholars to learn more about the unspoken aspects of peer review. If you have experience in scientific publication, speak about your rejections as well as your successes. When you deliver critique, remember there is a human on the other end of that communication, even if that person is not identified. If there is something promising or exciting about the work, note it explicitly. Recognize what power you have, and amplify the voices and perspectives of people whose voices are not yet central to the conversation.&lt;/p>
&lt;p>If you are someone who has been underserved by the current system, know that there are communities and allies who deeply value your contributions to science. Find friends and mentors who can interpret and contextualize reviews with you. If you encounter hostile or unprofessional reviews, know that you have options (including alerting the editor of the journal), and that unfortunately you are not alone.&lt;/p>
&lt;p>We at Reviewer Zero see equitable practices and reducing group disparities as essential to cultivating excellent science - science that is fair, meaningful, robust, and rigorous. Any move to improve scientific practice can ultimately succeed only if it centers building systems and spaces that represent a diverse range of identities, uphold equitable practices and outcomes, and prioritize inclusivity. Peer review is central to the practice and progress of science, and bettering it to serve a wider range of scientists will improve the rigor, quality, and contribution of science.&lt;/p>
&lt;p>&lt;br >&lt;/p>
&lt;h3 id="references">References&lt;/h3>
&lt;p>Aly, M., Colunga, E., Crockett, M., Goldrick, M., Gomez, P., Kung, F. Y. H., McKee, P., Perez, M., Stilwell, S., &amp;amp; Diekman, A. B. (in press). Changing the culture of peer review for a more inclusive and equitable psychological science. &lt;em>Journal of Experimental Psychology: General&lt;/em>.&lt;/p>
&lt;p>Hamedani, M. Y. G., &amp;amp; Markus, H. R. (2019). Understanding Culture Clashes and Catalyzing Change: A Culture Cycle Approach. Frontiers in Psychology, 10. &lt;a href="https://www.frontiersin.org/article/10.3389/fpsyg.2019.00700">https://www.frontiersin.org/article/10.3389/fpsyg.2019.00700&lt;/a>&lt;/p>
&lt;p>Petrescu, M., &amp;amp; Krishen, A. S. (2022). The evolving crisis of the peer-review process. &lt;em>Journal of Marketing Analytics, 10&lt;/em>(3), 185-186.&lt;/p>
&lt;p>Silbiger, N. J., &amp;amp; Stubler, A. D. (2019). Unprofessional peer reviews disproportionately harm underrepresented groups in STEM. PeerJ, 7, e8247. &lt;a href="https://doi.org/10.7717/peerj.8247">https://doi.org/10.7717/peerj.8247&lt;/a>&lt;/p>
&lt;p>&lt;br >&lt;/p>
&lt;h3 id="author-biography">Author Biography&lt;/h3>
&lt;p>Reviewer Zero
&lt;a href="https://www.reviewerzero.net/team" target="_blank" rel="noopener">Organizing Committee&lt;/a>. Contact information: &lt;a href="mailto:admin@reviewerzero.net">admin@reviewerzero.net&lt;/a>.&lt;/p></description></item><item><title>Academic Jobs in the US vs. the UK</title><link>https://forrt.org/educators-corner/015-academic-jobs-us-vs-uk/</link><pubDate>Tue, 30 May 2023 16:00:00 +0100</pubDate><guid>https://forrt.org/educators-corner/015-academic-jobs-us-vs-uk/</guid><description>&lt;br>
&lt;p>Given the scarcity of full-time, permanent academic jobs, more and more PhDs are looking abroad for employment. When I was on the job market in 2020–21, I applied to positions in 7 countries. I landed at the
&lt;a href="https://www.nottingham.ac.uk/politics/people/anna.meier" target="_blank" rel="noopener">University of Nottingham&lt;/a> in the UK—which, despite being ostensibly close to my home country of the US in terms of culture and primary language, proved to be
&lt;a href="http://annameier.net/the-big-us-uk-comparison-post/" target="_blank" rel="noopener">an entirely different world&lt;/a>. This was apparent from the job application stage, yet at the time, there was no publicly available guidance on differences between the academic job markets in the US and UK.&lt;/p>
&lt;p>Earlier this month, I set out to address this. I ran a webinar, “The Academic Job Market: US vs. UK,” aimed at demystifying both markets for applicants. Interest was so great that I added a second installment; in the end, over 200 people registered. You can watch a recording of the webinar below, which will remain freely accessible to all. The slides are also
&lt;a href="http://annameier.net/wp-content/uploads/2023/04/USUKworkshop.pptx" target="_blank" rel="noopener">available to download&lt;/a> from my website. I hope this can be a helpful resource to anyone looking to make sense of different market timelines, varying employment structures, and why you can’t address anyone below the rank of full professor in the UK as “Professor.” (This still trips me up constantly.)&lt;/p>
&lt;p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/jAVGsRDzA1A" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br >&lt;/p>
&lt;h2 id="structural-factors-shape-employment">Structural Factors Shape Employment&lt;/h2>
&lt;p>What I’d like to expand on here, however, is something only briefly touched on in the webinar: the structural factors shaping employment in higher education in the US and UK. Whereas much of the academic job market comparison in the two countries is apples and oranges, paying attention to the sociopolitical forces changing higher education reveals much common ground.&lt;/p>
&lt;p>Let me start with a timely example. In mid-April, faculty (teaching staff in UK parlance), postdoctoral fellows, graduate students, and counselors at Rutgers University joined together in unprecedented collective action. In the US, different categories of university staff are represented by different unions, and these are at best loosely networked nationally—there is no equivalent of the University and College Union (UCU), which represents all research and teaching staff, professional services staff, and PhD students at every university in the UK. Yet despite organizational hurdles, some
&lt;a href="https://www.npr.org/2023/04/15/1170284149/rutgers-university-faculty-strike-ends-tentative-deal" target="_blank" rel="noopener">9,000 Rutgers workers&lt;/a> went on strike together for living wages and an end to race and gender pay gaps. I can recall no similar university-wide coordinated action in the US in my lifetime.&lt;/p>
&lt;p>There are echoes in this struggle of the dispute UCU has waged since before the pandemic. Wages for UK university staff
&lt;a href="https://www.theguardian.com/education/2022/aug/22/universities-surplus-ucu-union-staff-pay-strikes" target="_blank" rel="noopener">have fallen some 25%&lt;/a> in real terms since 2009; the
&lt;a href="https://www.ucu.org.uk/media/975/The-diverse-academy---pay-and-employment-of-academic-and-professional-staff-in-UK-HE-by-gender-and-ethnicity-AUT-Oct-05/pdf/diverseacademy_oct05.pdf" target="_blank" rel="noopener">race and gender pay gaps&lt;/a> remain unacceptable for universities who claim commitment to equality, diversity, and inclusion (EDI, the UK twist on the US’s DEI: diversity, equity and inclusion). Equally troubling are the echoes in both disputes’ resolutions. The deal at Rutgers, agreed to after a week of action,
&lt;a href="https://twitter.com/jjjjjjjjohannah/status/1647625266854780928?s=20" target="_blank" rel="noopener">has been criticized&lt;/a> for
&lt;a href="https://twitter.com/CliffConnolly/status/1647285805658898432?s=20" target="_blank" rel="noopener">marginalizing graduate workers’ voices&lt;/a>, just as the current proposal under consideration by UCU provides
&lt;a href="https://docs.google.com/document/d/e/2PACX-1vRQJ-7uKjBazxCnxy-tjfXaFExSR779WTIszmXppAivDuoOkYezg7SKZ_jrOrmBT07Dt15n6lvBDSA0/pub" target="_blank" rel="noopener">no concrete improvements for PhD students&lt;/a> on casualized contracts. Solidarity at Rutgers, as in the UK, has been strongest among the most financially secure staff, with some of the least powerful university employees being left behind. Depending on the discipline, US PhDs will graduate into an academic job market where
&lt;a href="https://www.aaup.org/issues/contingency/background-facts" target="_blank" rel="noopener">around 70 percent of jobs&lt;/a> are temporary or contingent—a
&lt;a href="https://www.ucu.org.uk/stampout" target="_blank" rel="noopener">similar landscape&lt;/a> to that facing UK PhDs.&lt;/p>
&lt;p>&lt;img src="ucu-strike.jpeg" alt="A UCU picket line at the University of Nottingham">&lt;/p>
&lt;h2 id="features-not-bugs">Features, Not Bugs&lt;/h2>
&lt;p>Where do these analogous structural failings come from? The answer to this starts with deconstructing the idea that these are “failings,” rather than intentional components of a system that views degrees as commodities and people as cogs in machines. A system wherein the task of teaching is secondary to that of shoring up a university’s research reputation will not mind if teachers have to
&lt;a href="https://www.nea.org/advocating-for-change/new-from-nea/homeless-professor-who-lives-her-car" target="_blank" rel="noopener">live in their cars&lt;/a> or
&lt;a href="https://www.timeshighereducation.com/news/casualised-staff-dehumanised-uk-universities" target="_blank" rel="noopener">move from city to city every semester&lt;/a> in search of work. Likewise, a system where
&lt;a href="https://www.nytimes.com/2012/12/14/business/colleges-debt-falls-on-students-after-construction-binges.html" target="_blank" rel="noopener">glossy building façades&lt;/a> matter more than what happens inside of those buildings will not mind using historically excluded groups, particularly women of color,
&lt;a href="https://www.tandfonline.com/doi/full/10.1080/01419870701356015" target="_blank" rel="noopener">as PR fodder&lt;/a> while
&lt;a href="https://psycnet.apa.org/record/2023-37109-001" target="_blank" rel="noopener">exploiting their labor&lt;/a> until they burn out.&lt;/p>
&lt;p>Others have written
&lt;a href="https://journals.sagepub.com/doi/full/10.1177/1478210317719792" target="_blank" rel="noopener">far more comprehensively&lt;/a> about how these features of higher education (not bugs)
&lt;a href="https://www.boldtypebooks.com/titles/davarian-l-baldwin/in-the-shadow-of-the-ivory-tower/9781568588919/" target="_blank" rel="noopener">have become ever more present&lt;/a> in the past few decades. My point is simply that they are unavoidable, regardless of country of residence. Some might claim that coming to the UK will bring reduced research pressures compared to US research-intensive universities, which may be true in terms of the number of publications required but overlooks how the UK’s massive (and growing)
&lt;a href="https://annameier.substack.com/p/grant-culture" target="_blank" rel="noopener">grant-grubbing apparatus&lt;/a> saps staff time and discourages counterhegemonic work. Others might note that US academic salaries are generally higher than in the UK, which may be true even at poorer institutions but masks the
&lt;a href="https://www.nature.com/articles/d41586-021-01183-9" target="_blank" rel="noopener">massive (and growing) disparities&lt;/a> across and within US institutions. Regardless, the “it’s better over there” narrative sidesteps the reality of the academic job market for many: that, if they are able, they will go wherever hires them.&lt;/p>
&lt;p>&lt;img src="labour-situation.jpg" alt="Differences between the UK and US labour situation include differences in pay, job expectations, benefits and industrial relations. The webinar recording provides more information.">&lt;/p>
&lt;h2 id="trans-national-sharing">Trans-National Sharing&lt;/h2>
&lt;p>It&amp;rsquo;s easy to despair. What’s necessary—and what I hope sharing information across the pond helps encourage, however minimally—is turning collective despair into solidarity. Faculty in the US and UK face different day-to-day pressures, different career benchmarks, and different alphabet soups of acronyms. (Ask me sometime why Master’s students are PGTs but doctoral students are PGRs.) But underneath the surface, our struggles rhyme. It behooves those of us on both sides of the Atlantic to learn about how academia works in the US and UK, as well as in other countries. Our sector is transnational, and transparent, accessible information about that sector is an important foundation from which to exchange expertise, build campaigns, and push for change.&lt;/p>
&lt;p>&lt;br >&lt;/p>
&lt;h3 id="author-biography">Author Biography&lt;/h3>
&lt;p>Anna A. Meier (she/her/hers) is Assistant Professor in the School of Politics and International Relations at the University of Nottingham. She is a committed advocate for graduate students, solidarity-building, and collective care in higher education. Email: &lt;a href="mailto:anna.meier@nottingham.ac.uk">anna.meier@nottingham.ac.uk&lt;/a>; Twitter:
&lt;a href="https://twitter.com/AnnaMeierPS" target="_blank" rel="noopener">@AnnaMeierPS&lt;/a>; website:
&lt;a href="http://annameier.net/" target="_blank" rel="noopener">annameier.net&lt;/a>.&lt;/p></description></item><item><title>A Student’s Guide to Open Science: Using the Replication Crisis to Reform Psychology</title><link>https://forrt.org/educators-corner/014-students-guide-to-open-science/</link><pubDate>Thu, 09 Feb 2023 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/014-students-guide-to-open-science/</guid><description>&lt;br>
&lt;h2 id="a-child-of-the-replication-crisis">A child of the replication crisis&lt;/h2>
&lt;p>When Open University Press approached me to write a book on the “replication crisis in psychology”, I was filled with excitement as I knew that discussion of replication issues is scarce within teaching and psychology textbooks. If they don’t teach it, then I could! But I also knew it had to be more than the so-called ‘crisis’; a term associated with pessimism. It had to be about how far the discipline of psychology has come, and the opportunities that open research can bring to reform research training and the wider culture.&lt;/p>
&lt;p>I am a ‘child of the replication crisis’. I completed my PhD in 2016 on &amp;lsquo;stereotype threat&amp;rsquo;; an influential phenomenon that suggests negative societal stereotypes deplete performance. But I got stuck time and time again trying to replicate these classic effects. I felt like a failure. I wish I had known what I know now: that the experiences I was facing were more common than what was gleaned from the published literature. Science is not perfect and nor should it be, but this was not what I was taught through my undergraduate education. So I wrote a book – &lt;em>A Student’s Guide to Open Science&lt;/em> – for my younger self. In other words, for the talented and passionate students studying Psychology. By knowing our history – the good parts but also the messy parts – our students represent the grassroots that can make this discipline the best it can be!&lt;/p>
&lt;h2 id="what-is-this-book-about-and-why-is-it-needed">What is this book about and why is it needed?&lt;/h2>
&lt;p>By now, many researchers have heard about the ‘replication crisis’ that has swept research disciplines, and the fast-paced improvements brought about by open research reform. However, there is still a gap in educational practices – in the teaching of the replication crisis – which FORRT and its members strive to overcome. Furthermore, when trying to learn about the replication crisis and open science, it can feel overwhelming and there are lots of different resources in many different places. With this in mind, I wrote a “&lt;em>A Student’s Guide to Open Science&lt;/em>” as a way of pulling together all of these various pieces of information and useful resources that are currently out there.&lt;/p>
&lt;p>The book walks students (and their educators) through a recent history of the replication crisis in psychology, the causes and drivers of crises (including academic incentive structures, questionable research practices, and cognitive biases), and open science reform, its benefits and associated challenges. Importantly, to ensure that students understand how to put these new practices into practice, it also includes a handy, digestible guide to implementing open science practices such as preprints, preregistration, Registered Reports, and open materials, data, and code. It is my hope that this book becomes an essential guide to navigating the replication crisis.&lt;/p>
&lt;h2 id="pedagogic-resources-within-the-book">Pedagogic resources within the book&lt;/h2>
&lt;p>This book is primarily aimed at students studying psychology at both undergraduate and postgraduate level, but throughout I include useful pedagogic resources that educators can use to teach the replication crisis and open science reform. For example, there is an activity where students plan to replicate a study and can understand the various difficulties they may stumble upon in their quest. Here, they find their favourite article from the journal it was published and walk themselves through different questions to assess whether there is enough information to perform an exact replication – what is the aim of the study? Do the researchers specify their main hypotheses? What is the research design? Are the measures they used detailed enough to understand how they were scored? Do they report whether (and how) they screened or cleaned their data? (see Box 1).&lt;/p>
&lt;p>&lt;strong>Box 1. The seat of a replicator. An example pedagogic activity from “A Student’s Guide to Open Science”.&lt;/strong>&lt;/p>
&lt;p>&lt;img src="seat-of-a-replicator.png" alt="The seat of a replicator is a pedagogic activity which asks students to plan an exact replication of their favourite journal article. It set out a number of questions they need to ask about the study, such as &amp;ldquo;what is the sample size? Are there any inclusion or exclusion criteria?&amp;rdquo; The learning outcomes of this activity are: To know the difference between an exact and conceptual replication. To understand how to conduct an independent replication. To identify challenges when replicating published research. To understand the importance of transparent reporting to aid replications.">&lt;/p>
&lt;p>This same pedagogic activity can then be expanded to teach about open science reform. Specifically, using the notes that students have taken from their “seat of a replicator activity”, they can then have a go at preregistering their replication using a template from a verified repository (e.g., AsPredicted.org/Open Science Framework). These templates can be downloaded from each repository and students can either complete these as a formative (e.g., seminar activity) or summative assessment (e.g., written report; see Box 2).&lt;/p>
&lt;p>&lt;strong>Box 2. Pedagogic activity: preregistering a replication study.&lt;/strong>&lt;/p>
&lt;p>&lt;img src="aspredicted-template.png" alt="This activity asks students to write a preregistration for a replication study, using the As Predicted dot org template. The learning outcomes for this are: To understand how to transparently plan a study. To demonstrate understanding of how open science practices can aid transparency, replication, and reproducibility. To interpret research articles and apply this learning to conducting independent research studies.">&lt;/p>
&lt;p>In addition to these pedagogic resources, the book also contains top tips for implementing open science practices into student’s research training, including for preprints, preregistration, Registered Reports, and open materials, data, and code. Whilst the focus is mainly on quantitative research, it also provides links and resources to qualitative research. In addition, throughout it discusses the many different organisations and initiatives that have shaped my own learning of open science (see Box 3), thus providing a detailed overview of everything we have learnt so far from the advent of the replication crisis through to current open science reform.&lt;/p>
&lt;p>&lt;strong>Box 3. Key resources to get started with open science.&lt;/strong>&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>&lt;strong>Charlotte&amp;rsquo;s Key Open Science Resources&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>“A Student’s Guide to Open Science” (Pennington, 2023, Open University Press)&lt;/li>
&lt;li>FORRT’s open educational resources including a &lt;a href="https://forrt.org/lesson-plans">bank of lesson plans&lt;/a>, &lt;a href="https://forrt.org/reversals">replications and reversals&lt;/a>, and &lt;a href="https://forrt.org/glossary">open science glossary&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://riotscience.co.uk/">RIOT Science Club&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://reproducibilitea.org/">ReproducibiliTea Journal Clubs&lt;/a>&lt;/li>
&lt;li>Podcasts, such as &lt;a href="https://everythinghertz.com/">Everything Hertz&lt;/a>&lt;/li>
&lt;li>Global Reproducibility Networks, such as the &lt;a href="https://www.ukrn.org/">UKRN&lt;/a> and their &lt;a href="https://www.ukrn.org/primers/">primers on open science practices&lt;/a>&lt;/li>
&lt;li>The &lt;a href="https://openresearchcalendar.org/">Open Research Calendar&lt;/a>&lt;/li>
&lt;li>New meta-research articles via &lt;a href="https://osf.io/preprints/metaarxiv/">MetaArXiv&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;h2 id="become-a-student-of-open-science">Become a student of open science!&lt;/h2>
&lt;p>The replication crisis and open science reform is not currently embedded within the teaching of psychology. It is my hope that with all of these wonderful new and ever-evolving resources, today’s students become critical consumers of science and pave the way to creating a truly robust, transparent, replicable, reproducible and representative psychological science.&lt;/p>
&lt;h2 id="author-bio--contact">Author Bio &amp;amp; Contact:&lt;/h2>
&lt;p>Dr Charlotte Pennington is a Lecturer in Psychology at Aston University, Birmingham, a Fellow of the Higher Education Academy, and a member of FORRT. Her book, “&lt;em>A Student’s Guide to Open Science: Using the Replication Crisis to Reform Psychology&lt;/em>” is available in all good bookstores and inspection copies are available from
&lt;a href="https://www.mheducation.com.au/a-student-s-guide-to-open-science-using-the-replication-crisis-to-reform-psychology-9780335251162-aus" target="_blank" rel="noopener">McGraw Hill&lt;/a> for review. If you have trouble accessing it, please let Charlotte know via the contact details below and she will do her best to help.&lt;/p>
&lt;p>Email:
&lt;a href="mailto:c.pennington@aston.ac.uk">c.pennington@aston.ac.uk&lt;/a>&lt;/p>
&lt;p>Twitter:
&lt;a href="https://twitter.com/drcpennington" target="_blank" rel="noopener">@drcpennington&lt;/a>&lt;/p>
&lt;p>Mastodon:
&lt;a href="https://mastodon.social/@drcpennington" target="_blank" rel="noopener">@drcpennington@mastodon.social&lt;/a>&lt;/p></description></item><item><title>Introducing Nowhere Lab</title><link>https://forrt.org/educators-corner/013-introducing-nowhere-lab/</link><pubDate>Thu, 01 Sep 2022 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/013-introducing-nowhere-lab/</guid><description>&lt;br>
&lt;blockquote>
&lt;p>&lt;strong>Nowhere Lab &amp;amp; FORRT&lt;/strong>.
Nowhere Lab has partnered with FORRT as part of FORRT’s efforts to promote social justice and enable equality of access to open scholarship training! Nowhere Lab members benefit from weekly meetings where they can bring any questions they have about adopting any open scholarship practices (or anything else related to science and/or academia). Dr. Priya Silverstein (Nowhere Lab founder) is also available to answer any questions about engaging in other FORRT initiatives either during the weekly meetings, by reaching out via the Nowhere Lab or FORRT Slack workspaces, or by email. Nowhere Lab also operates informal mentorship – rather than matching mentors and mentees, people with mutual interests and skills are able to be connected and there are several channels in our Slack for seeking help or support for a variety of issues.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>Background&lt;/strong>&lt;/p>
&lt;p>Throughout my academic career, I loved being in a lab. I looked forward to biweekly lab meetings as a research assistant, hearing about what the Ph.D. students were up to and wondering about what my own Ph.D. would hold (if I ever got that far). When I finally got a Ph.D. position, I had not one but TWO weekly lab meetings with each of my two supervisors. In the first, we always held journal clubs – taking some of the newest and most exciting developmental science research and dissecting the theory and methods to bits. In the second, we had a mix of journal clubs, presentations, and catch-ups. A Ph.D. can be quite lonely – just you and your super-specific topic – so lab meetings were a welcome time to reflect, process, and think with labmates. During a pandemic-induced furlough from my postdoc, and when I took two alt-academic jobs after this, I really missed this chance to connect with labmates. So, I decided to create my own lab. That’s where Nowhere Lab began.&lt;/p>
&lt;p>&lt;strong>Who we are&lt;/strong>&lt;/p>
&lt;p>Nowhere Lab (
&lt;a href="http://nowherelab.com/" target="_blank" rel="noopener">http://nowherelab.com/&lt;/a>) is an online community for people who would like the lab meeting experience but don’t currently have one. We have members from across all populated continents and career stages: undergraduate students, master&amp;rsquo;s students, Ph.D. students, postdocs, faculty members, and people working outside of academia. We hold weekly meetings and have an active Slack (
&lt;a href="https://join.slack.com/t/nowherelab/shared_invite/zt-1b9ky398h-z5QaNohPP613EBX~zpXQFw" target="_blank" rel="noopener">join here&lt;/a>).&lt;/p>
&lt;p>It has been a humbling and often emotional experience to hear the stories of those who have joined Nowhere Lab. Some members have joined when caught at a difficult and awkward time where they don’t feel embedded within their Ph.D. lab (e.g. they’re currently writing up) but also don’t have a new lab. Some members have joined when they get their first faculty job and don’t have any students for their lab yet. Some members have recently left academia and have mixed emotions about this transition. Some have joined because they’re considering postgraduate research but have never had any experience of research due to educational priorities in their country. One member even joined because health issues meant they weren’t able to take on new students and thus no longer had their own lab. We’re a home for the lost and are brought closer together by the stories of why we need Nowhere Lab.&lt;/p>
&lt;p>&lt;strong>What we do&lt;/strong>&lt;/p>
&lt;p>What we do weekly is entirely dictated by members and has included job interview prep, advice on ongoing projects, discussions, statistical training, journal clubs, and much more. For example, we often have conversations where people who have done a Ph.D. share advice with members who are considering one. We decided to share this advice openly in a
&lt;a href="https://docs.google.com/document/d/1dsb8VzoP8HfaYy_oherlqP3qOqr0xHoqvYwnAqlbtts/edit#" target="_blank" rel="noopener">Ph.D. survival guide&lt;/a>, in the hope that it will help people who are considering embarking on a Ph.D. or have just started. This guide covers things to know about doing a Ph.D., what’s great and not great about doing one, top tips, how to choose between two programmes, what to do when you think you’ve made the wrong choice, signs of a toxic environment, and how (not) to handle stress. As well as being useful, creating this guide was also a cathartic process for some members who had less than ideal Ph.D. experiences and wanted to share things they wished they’d known at the time.&lt;/p>
&lt;p>&lt;strong>Our goals&lt;/strong>&lt;/p>
&lt;p>Nowhere Lab aims to open science up to anyone and everyone. For example, we have members who work in tech and nonprofits who would not normally consider themselves scientists or get to engage in a scientific community. In addition to advancing diversity as an essential part of open science, we often focus explicitly on methods-based open science skills and knowledge advancement too. For example, we often read papers on open science and metascience in our journal clubs.&lt;/p>
&lt;p>&lt;strong>Achievements&lt;/strong>&lt;/p>
&lt;p>Although the Ph.D. survival guide is Nowhere Lab’s first “output”, we have many other success stories that have come from the lab. We have now had several Ph.D. vivas and graduations – we even got to virtually attend one member’s viva which was really interesting for members who’d never seen one before. Careers have been changed – one member got a job from a Nowhere Lab referral, and two members were offered jobs after doing interview prep with the lab. And friendships have been forged – one member even visited me and stayed at my home!&lt;/p>
&lt;p>&lt;strong>Join us&lt;/strong>&lt;/p>
&lt;p>There are many reasons why someone might want to join Nowhere Lab:&lt;/p>
&lt;ul>
&lt;li>New faculty who have no one in their lab yet&lt;/li>
&lt;li>Ex-academics who now work in industry&lt;/li>
&lt;li>Keen undergraduates and masters students&lt;/li>
&lt;li>Freelance sci-commers/consultants&lt;/li>
&lt;li>People who are in a toxic lab&lt;/li>
&lt;li>People between jobs&lt;/li>
&lt;li>…and many many more!&lt;/li>
&lt;/ul>
&lt;p>If you’re interested in joining Nowhere Lab, email me at
&lt;a href="mailto:priyasilverstein@gmail.com">priyasilverstein@gmail.com&lt;/a>. We can’t wait to meet you!&lt;/p>
&lt;p>&lt;strong>Contact information&lt;/strong>:&lt;/p>
&lt;p>Priya Silverstein [priyasilverstein@gmail.com]&lt;/p></description></item><item><title>Research and data lessons from a non-academic job:</title><link>https://forrt.org/educators-corner/012-lessons-from-non-academic-jobs/</link><pubDate>Sat, 09 Jul 2022 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/012-lessons-from-non-academic-jobs/</guid><description>&lt;br>
&lt;h2 id="five-lessons-from-a-non-academic-job">Five lessons from a non-academic job&lt;/h2>
&lt;blockquote>
&lt;p>It’s been one year after &lt;strong>leaving academia&lt;/strong> and starting to work for a charity organisation. For a bit of context, I did my PhD in Psychology, after which I spent four years across two postdocs (one in France, one in England) and I got to the point where I could no longer see my career progress in academia. There are many reasons why I came to this crossroad, but above all, I realised that my passion is with research and data, and less so with the other aspects of academic life. &lt;strong>To my delight, my non-academic journey&lt;/strong> so far has been full of development and challenges and here are some of the lessons I shared, with some additional thoughts. Here are five things I learnt:&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>The three &lt;em>data&lt;/em> lessons&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>I learnt a lot about data. Real life data is messy AF. I learnt how to join complicated datasets with missing data and how to deal with types of variables I rarely encountered like strings and dates. I cannot underestimate how neat data from academic research is compared to what real life data looks like.&lt;/li>
&lt;li>I learnt how organisations store their data. Unlike any other datasets I worked with before, organisational data is dynamic. There isn&amp;rsquo;t just one database but rather multiple sets that are related to one another. You need tools like SQL to pull data from internal data systems. SQL queries are also used to power live dashboards which are used to display data in the simplest form. This is where most teams take their data from. Tools like PowerBi and Tableau are the major players here when it comes to data visualisation and internal data sharing. This was a completely new lesson to me because like most academics, I have been used to dealing with only static data, pulled from Qualtrics or arranged neatly within one Excel sheet. The good news about SQL is that I was able to pick it up relatively easily with my programming skills in R but what I still find tricky is finding the piece of data I need in columns and columns of data that aren’t always neatly labelled. I really miss having a neat codebook with all variable names listed!&lt;/li>
&lt;li>I also had to revisit my thoughts on descriptive statistics. In academia, inferential stats are king because we infer something about a population from a sample. With organisational data, you have access to the whole population so descriptive stats become very powerful. I had to resist an urge to ask “yes, but is this increase statistically significant?” because if all 100 programme members answered the same question about the satisfaction in the following year, and we saw an increase of 5% in satisfaction, this in itself is informational and quantified in terms of the effect size - we don’t need inferential statistics to tell us if this difference was significant at the 0.01 level or at the 0.001 level and whether this would apply to the wider population - this isn’t the point.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>The two (new) &lt;em>methodological approaches&lt;/em> lessons.&lt;/strong>&lt;/p>
&lt;ol start="4">
&lt;li>I learnt about quasi-experimental approaches using matching. While in academia I often ran experiments, establishing causation to evidence the impact of established programmes and interventions is more tricky as you often can&amp;rsquo;t randomly assign participants to treatment and control. This led me to learning about quasi-experimental statistical approaches and methods like propensity score matching to estimate the likelihood of treatment and select the ideal matched pairs. Lack of random assignment is also the least of all issues. The environment in which programmes and interventions happen in the real world is far from the controlled experiments we run in labs/online. So how do you assess whether participating in a long-term teacher training programme has a real life impact for the pupils they teach? How do you establish causation and the process by which it happens? These are a lot more tricky questions than I ever thought I had to approach. It turns out there is a whole host of methodologies to address this issue - these are a lot more prevalent approaches in disciplines such as policy (think: policymakers often want to know what impact introducing policy X had on the local population but they aren’t always able to randomly assign two groups of population into an intervention with policy application versus not).&lt;/li>
&lt;li>I learnt how to run a discrete choice experiment. This is a method that is often employed in marketing, I&amp;rsquo;ve rarely heard of it before but I found an excellent application of this method in the work we were doing. By designing a discrete choice experiment, we were able to assess what changes we could make to programmes we offer to increase their propensity. Would this programme be more popular if we introduced element X or increased Y? This technique looks at implicit preferences for various factors (not just two factors but many at the same time). It puts them directly in competition with one another to calculate propensity of each factor. It&amp;rsquo;s also often used in medical sciences and economics.I had a lot of fun designing this research and I am currently working with internal stakeholders to develop actions from this research - how can we turn this knowledge to attract more people to our programmes? It&amp;rsquo;s fascinating how quickly you can turn research into action.&lt;/li>
&lt;/ol>
&lt;p>I find the process of reflecting on these lessons somewhat therapeutic because this time last year, I was full of excitement but also filled with some worries as I was embarking on my non-academic path. These lessons tell me that I not only was able to build on my research and data skills that I developed during my academic career, but also this move has allowed me to expand my development in ways I didn’t anticipate before.&lt;/p>
&lt;p>I originally went into academia because I loved this process of learning and developing, stumbling across new challenges and new approaches, but after 7 years I started getting worn out by discussing the same issues while using the same approaches and I craved new challenges. This first year of the non-academic pathway has certainly fulfilled that goal. I’m not saying that academia can’t be a fulfilling path with lots of challenges - I think it’s more about the fit. &lt;strong>Digging deeper into what it is really about your job that makes you happy is going to lead you down the right pathways, academic or not.&lt;/strong>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Contact information&lt;/strong>: Karolina Urbanska (
&lt;a href="mailto:k.urbanska@sheffield.ac.uk">k.urbanska@sheffield.ac.uk&lt;/a>), Twitter
&lt;a href="https://twitter.com/karo_urb" target="_blank" rel="noopener">@karo_urb&lt;/a>, &amp;amp; website
&lt;a href="https://www.karolinaurbanska.co.uk/" target="_blank" rel="noopener">https://www.karolinaurbanska.co.uk/&lt;/a>, and link to the original thread:
&lt;a href="https://twitter.com/karo_urb/status/1529784303885885441" target="_blank" rel="noopener">https://twitter.com/karo_urb/status/1529784303885885441&lt;/a>.&lt;/p>
&lt;hr>
&lt;p>&lt;em>Editor&amp;rsquo;s note: The present text is an adapted and expanded version of the widely shared
&lt;a href="https://twitter.com/karo_urb/status/1529784303885885441" target="_blank" rel="noopener">Twitter thread&lt;/a> by Karolina which resonated with so many of us. We invited the author if she would be willing to adapt &amp;amp; expand her thread to an Open Scholarship audience.&lt;/em>&lt;/p></description></item><item><title>Addressing the grand challenges facing psychological science</title><link>https://forrt.org/educators-corner/011-intersectionality-open-science/</link><pubDate>Thu, 21 Apr 2022 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/011-intersectionality-open-science/</guid><description>&lt;br>
&lt;h2 id="what-are-the-four-grand-challenges-identified-by-aps-members">What are the four grand challenges identified by APS members?&lt;/h2>
&lt;h3 id="1-globalization-and-diversity">1. Globalization and diversity&lt;/h3>
&lt;p>Psychological science has been repeatedly described as WEIRD, meaning Western, Educated, Industrial, Rich, and Democratic. In particular, the persistent use of predominately White and North American college students to study human behaviour has raised concerns about the generalizability of our findings, as well as our legitimacy as a science (Arnett, 2008; Henrich, Heine, &amp;amp; Norenzayan, 2010; IJzerman et al., 2021; Thalmayer et al., 2021; Tindle, 2021). Others argue that we should get rid of the dichotomy altogether (Ghai, 2021).&lt;/p>
&lt;p>&lt;strong>Here’s what you can do to enhance globalization and diversity within psychological science:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Invite international speakers to participate in opportunities that historically privilege U.S. citizens (e.g., colloquium series, workshops, awards, fellowships)&lt;/li>
&lt;li>Explicitly cite the achievements and ideas of Black, Indigenous, and People of Color within undergraduate and postgraduate courses, particularly Black women (e.g., see existing resources such as the
&lt;a href="https://docs.google.com/spreadsheets/d/1i7Eacoyv9VVg2lBbCV-KJZg4nSGvR_VZFOysOyOGG8g/edit#gid=666010790" target="_blank" rel="noopener">BIPOC-authored Psychology Papers spreadsheet&lt;/a> for a detailed list of available scholarship; reference Smith, et al., 2021 for a description of the
&lt;a href="https://www.citeblackwomencollective.org/" target="_blank" rel="noopener">Cite Black Women campaign&lt;/a>)&lt;/li>
&lt;li>Encourage people to engage with marginalized groups, including Disabled people; reference Educator’s Corner on
&lt;a href="https://forrt.org/educators-corner/010-neurodiversity/" target="_blank" rel="noopener">Navigating Open scholarship for neurodivergent researchers&lt;/a>&lt;/li>
&lt;li>Acknowledge your positionality, meaning the social-historical-political aspects of a researcher that influence your orientations (see Bourke, 2014; Secules, et al., 2021) and include reflexive practice for all research pursuits, including quantitative research programmes (see Jamieson, Pownall, &amp;amp; Govaart, 2022)&lt;/li>
&lt;li>Consider context and identity by reporting sample demographics (Sabik, et al., 2020), as well as incorporating informed frameworks (e.g., interpret results via critical race theory or open scholarship)&lt;/li>
&lt;/ul>
&lt;h3 id="2-research-integrity-and-applicability">2. Research integrity and applicability&lt;/h3>
&lt;p>Many of us have been warned about the replication crisis in psychology (also commonly referred to as the replicability or reproducibility crisis, as well as the credibility revolution). Not unique to psychology, the crisis highlights that the results of many peer-reviewed scientific studies are either difficult or impossible to replicate (Open Science Collaboration, 2015). However, the legitimacy of the concern with regards to replication remains hotly contested (Feest, 2019; Maxwell, et al., 2015).&lt;/p>
&lt;p>&lt;strong>Here’s what you can do to promote research integrity and applicability within psychological science:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Challenge bias against open science as valuable or legitimate; incentivize early career and contingent scientists to participate by reshaping institutional norms or program milestones (e.g., encouraging students to pre-register dissertation studies; Bahlai, et al., 2019)&lt;/li>
&lt;li>Shift mentality to encourage collaboration rather than competition (e.g., scientists working across departments or multiple working groups rather than in a singular lab at a particular campus)&lt;/li>
&lt;li>Raise awareness about the unique experiences of intersectionally invisible participants (e.g., people who share two or more marginalized identities such as Black women; Coles &amp;amp; Pasek, 2020; Purdie-Vaughns &amp;amp; Eibach, 2008)&lt;/li>
&lt;li>Use existing resources, such as
&lt;a href="https://osf.io/" target="_blank" rel="noopener">the Open Science Framework&lt;/a> or
&lt;a href="http://aspredicted.org" target="_blank" rel="noopener">aspredicted.org&lt;/a> to collaborate, document, archive, share and register research projects, materials, code, and data; join the
&lt;a href="https://psysciacc.org/" target="_blank" rel="noopener">Psychological Science Accelerator&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="3-collaboration-across-fields-and-disciplines">3. Collaboration across fields and disciplines&lt;/h3>
&lt;p>As psychologists, we rarely cross borders, whether real or imagined (e.g., departments, universities, countries)! Collaboration across disciplines and fields, however, is extremely beneficial to psychological scientists seeking to identify connections between psychological processes, history, and broader context (2020). Take, for instance, work from Henderson and colleagues on Confederate monuments; they find that the number of lynching victims in a county is a positive and significant predictor of Confederate memorialization in that county (2021). An intersectional lens can be applied to their findings to illustrate how race and social forces such as the Civil War contributed to anti-Black racism in the U.S., particularly during Reconstruction in the South. Through this example, we can also see how the present work invites participation from other fields like American politics, history, and Africana studies.&lt;/p>
&lt;p>&lt;strong>Here’s what you can do to collaborate across fields and disciplines within psychological science:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Participate in scholarly events outside of psychology, such as the
&lt;a href="https://minoritypolitics.netlify.app/" target="_blank" rel="noopener">Minority Politics Online Seminar Series&lt;/a>&lt;/li>
&lt;li>Invite speakers from other disciplines to department- or University-led symposiums or conferences; provide remote options for attendance and accessibility grants to stimulate broader participation (e.g., the
&lt;a href="https://uva.theopenscholar.com/diversifyingscholarship/" target="_blank" rel="noopener">University of Virginia Diversifying Scholarship Conference&lt;/a>)&lt;/li>
&lt;li>Initiate cross-discipline collaborations (e.g.,
&lt;a href="https://www.mdpi.com/2076-0760/11/3/90" target="_blank" rel="noopener">Gaither &amp;amp; Sims, 2022&lt;/a>)&lt;/li>
&lt;li>Leverage existing networks such as Academic Twitter to incorporate the views of people from relevant disciplines and achieve shared goals (e.g., a systematic co-creation of new knowledge on a specific topic)&lt;/li>
&lt;/ul>
&lt;h3 id="4-strengthening-theory">4. Strengthening theory&lt;/h3>
&lt;p>In science, a theory is a well-supported explanation of natural phenomena, confirmed repeatedly through observation and experimentation. Theory changes, however, if and when evidence accumulates that the theory cannot explain. Adaptive research in psychology must therefore follow the assumption that our knowledge will expand along with our understanding of human diversity (and vice versa). Doing so will allow room for concepts such as intersectionality and open science to be integrated within psychological science. Take, for instance, Bronfenbrenner’s ecological systems theory. Frustrated with the centrality of white boys, Stern and colleagues developed a new version centered on Black girls (2021). You can see the model here:&lt;/p>
&lt;p>&lt;img src="image.png" alt="Bronfenbrenner’s ecological systems theory" title="Bronfenbrenner’s ecological systems theory">&lt;/p>
&lt;p>&lt;strong>Here’s what you can do to strengthen theory within psychological science:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Expand theory regarding the mind and behavior to represent human diversity; the development of reliable theories is essential to scientific progress (&lt;em>see&lt;/em> Eronen &amp;amp; Bringmann, 2021 for insights into developing good psychological theories)&lt;/li>
&lt;li>Compile evidence to advance new theories if and when they are no longer applicable or outdated due to history or context (e.g., COVID-19); create theories that center marginalized people and the real-world scenarios they experience in day-to-day life, controlling for relevant covariates&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Join me!&lt;/strong>&lt;/p>
&lt;p>It is possible that I am overoptimistic about the future of psychological science or naive to the systematic obstacles that must be overcome. Still, I would rather be naive than conform to a system that is stagnant to change. When we stand outside the Ivory Tower, aware that the system is corrupt but alone, helpless, and discouraged, we know that the master&amp;rsquo;s tools will never dismantle the master&amp;rsquo;s house (Lorde, 2018). We were meant to be kept out of the house. Ergo, the time has come to build a house of our own, a house founded on principles that reflect and affirm our identities as the marginalized, unconventional, and historically excluded. It is within our avant-garde that we will find our true power, and grapple with the many challenges requiring redress to create a stronger, more robust science.&lt;/p>
&lt;p>&lt;strong>Here’s what you can do:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Strengthen our existing community by
&lt;a href="https://t.co/iFqoW5tIRh" target="_blank" rel="noopener">joining our Slack group&lt;/a>&lt;/li>
&lt;li>Seek collaborations to pursue broader work exploring intersectionality, open science, and related topics and crowdsource manuscripts&lt;/li>
&lt;li>Identify funding opportunities to advance our goals: research transparency, reproducibility, rigor, and ethics (e.g.,
&lt;a href="https://www.einsteinfoundation.de/en/award/" target="_blank" rel="noopener">Einstein Foundation Award for Promoting Quality in Research&lt;/a>)&lt;/li>
&lt;li>Spearhead initiatives (e.g., write a post for the
&lt;a href="https://forrt.org/educators-corner/" target="_blank" rel="noopener">Educators’ Corner&lt;/a>)&lt;/li>
&lt;li>Spread the word about FORRT (e.g., share this post with your colleagues, tag us on Twitter)&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contact information&lt;/strong>: Annalisa Myer (
&lt;a href="mailto:amyer@gradcenter.cuny.edu">amyer@gradcenter.cuny.edu&lt;/a>), Twitter
&lt;a href="https://twitter.com/MyerAnnalisa" target="_blank" rel="noopener">@MyerAnnalisa&lt;/a>.&lt;/p></description></item><item><title>Navigating Open scholarship for neurodivergent researchers</title><link>https://forrt.org/educators-corner/010-neurodiversity/</link><pubDate>Sun, 23 Jan 2022 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/010-neurodiversity/</guid><description>&lt;br>
&lt;h2 id="navigating-open-scholarship-for-neurodivergent-researchers">Navigating Open scholarship for neurodivergent researchers&lt;/h2>
&lt;h3 id="who-we-are-and-why-is-this-important">Who we are and why is this important?&lt;/h3>
&lt;p>In academia, there has been much discussion about how open scholarship can benefit marginalised voices (e.g. Robertson, 2020; Pownall et al., 2020). However, neurodivergent individuals (e.g. dyslexic, autistic, ADHD) have received little attention. According to the
&lt;a href="https://www.hesa.ac.uk/data-and-analysis" target="_blank" rel="noopener">Higher Education Statistics Agency&lt;/a>, only 2.2% in 2003/04, 3.9% in 2012/13 to 5.5% in 2019/2020 of staff at universities in the UK disclosed having a physical or neurological disability. However, the true figures are likely to be higher. Despite increased coverage and interest regarding disability issues in academia, concerns regarding negative perceptions of disability disclosure remain. More open discussions are taking place about the lived experiences of disabilities and chronic illnesses, as people with disability are becoming less stigmatised, leading to more disclosures being discussed. However, there is still a question being asked: ‘where are the disabled academics?’ (We are here but you don’t see us!).&lt;/p>
&lt;br>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/L-B8YasT-UE" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;p>Disability? How do you have a disability? You do not have a deficit with your body, you can still function in society, earn a living and participate in community life. Disability is portrayed as a personal tragedy, with some heroic individuals “overcoming” their terrible handicap. So how are you disabled? The answer is that not all disabilities are visible. The relative proportion of disabled academics is widely underestimated (e.g. Farahar, 2021), likely due to the stigma attached to the concept of disability (Mellifont, 2021). In addition, there are too many assumptions about disability being a physical or intellectual impairment with no discussion on difficulties regarding cognition and mental health. This discussion also fails to encapsulate that the range of difficulties people face may be connected to an individual’s neurodevelopmental characteristics (Singer, 2017). This is in spite of the fact that there are conditions that are described by psychologists as disabling but people with these conditions are treated as if they are not disabled. This is the ‘neurodiverse’ group.&lt;/p>
&lt;p>Neurodiversity is the non-pathological variation in the human brain regarding sociability, learning, attention, mood and other mental functions at a group level (Singer, 2017). An individual is neurodivergent if their neurology diverges from that of the neurological majority. Neurodiversity is critically relevant to the social sciences as it discusses the diverse cognitive behaviours forming the foundations of what it means to be unique and human. Importantly, the neurodiversity movement questions the assumption that all humans must conform to the same expectations in order to flourish.&lt;/p>
&lt;p>&lt;img src="fig1.png" alt="Neurodiversity" title="Neurodiversity">&lt;/p>
&lt;p>So, you may still be wondering how neurodivergent individuals are disabled? The labelling of disability is a personal matter. It depends on what models we use to interpret it. Under the medical model, disability is portrayed as a flaw, weakness or a biological limitation of the individual. Put simply, it is a personal tragedy that was inflicted on you. Disability under the social theory of disability is defined not as a personal tragedy but as the result of barriers – environmental and social practices that disable, as opposed to enabling, the individual. In addition, the social model makes the distinction that an impairment is a property of an individual body, while disability is a social process. However, it is important to remember that both models are not mutually exclusive, but are required to be used together to open a constructive dialogue between able-bodied and disabled individuals, even among disabled individuals. The important message is that disabilities are &lt;strong>dynamic&lt;/strong> and reasonable adjustments should be made for all groups.&lt;/p>
&lt;p>In today’s academic environment, the economic and political system of universities, among many other industries, focus on productivity and profit. As a result, measures that focus on productivity and profit such as standards, norms, league tables, achievements and publications are becoming more and more important. Health and wellbeing and slow science are becoming less important, despite the fact that slow science and resting are important for creativity, critical thinking and understanding data, three crucial components to help accumulate knowledge. As a result of this development, burnout becomes more common and this is more prevalent among people with disabilities (Burns et al., 2021).&lt;/p>
&lt;p>People with disabilities are more likely to be excluded from the academic workforce with its demands for speed, efficiency and productivity, leading to normalised, ingrained and internalised ableism to an extent that they desire to be able-bodied. As a result of this exclusion, able-bodied individuals may believe that disabled individuals do not contribute to the productivity of the community and argue that their unemployment is the ‘fate of the idle’ (Singer, 2017). This means that in academia and industry, people with disabilities become oppressed, mocked, ridiculed and perceived as a nuisance.&lt;/p>
&lt;p>Many gatekeepers determine whether an individual is neurodivergent and these processes are driven by individuals who are neurotypical. As a result, referral time for these services vary widely, from 4 weeks to 201 weeks within the UK (Lloyd, 2019) and if a person does not fit the criteria, the individual can be ignored and may not receive the much-needed help that they require. This can lead to poor self-esteem, unemployment (e.g. around 22% in autistic people are in any type of employment; see Figure 2 in
&lt;a href="https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/disability/articles/outcomesfordisabledpeopleintheuk/2020" target="_blank" rel="noopener">fact sheet&lt;/a>). As a result, neurodivergent individuals may blame themselves for the difficulties they encounter, as opposed to the barriers that society has placed on them.&lt;/p>
&lt;p>Despite this, people of different neurodivergent conditions or families of the people with the conditions have begun meeting and talking to each other about their experiences and one common shared experience is a history of misinterpretation and mistreatment by the dominant neurotypical cultures and its institutions such as academia. As a result of centuries of oppression of disabled people worldwide and a hyper-normalised environment, in addition to seeing the disproportionate impact of the coronavirus pandemic on disabled students (see this amazing
&lt;a href="https://link.springer.com/article/10.1007/s10639-021-10559-3" target="_blank" rel="noopener">paper &lt;/a>by Dr Joanna Zawadka), many neurodivergent and disabled staff feel discouraged in an environment that should aim to support them. They do not feel like they belong, their differences are seen as an impairment and their voice does not seem to matter. They do not see themselves represented in psychological science, academia, business, teaching or elsewhere.&lt;/p>
&lt;p>We are a group of early-career neurotypical and neurodivergent researchers that are a part of the Framework of Open Reproducible Research and Training (FORRT) community, aiming to make academia and the open scholarship community more open to neurodiversity. Everyone, no matter what they identify with, is welcome in this group. We aim to discuss how open scholarship can be intersected with the neurodiversity movement, and emphasise how differences should be highlighted and accepted, whilst supporting the idea of accessibility. Our neurodiversity team is a group that currently consists of individuals that have autism, dyspraxia/DCD, speech-language differences, ADHD, dyslexia, or are neurotypical allies. If you have these or other neurominorities and wish to be part of the team, you are more than welcome to join!&lt;/p>
&lt;h3 id="what-do-we-want">What do we want?&lt;/h3>
&lt;p>We want academia and open scholarship not to be covertly homophobic, racist, sexist and ableist. However, by attempting to adapt and work within the existing defined rules of academia and its power structures, what we do is reinforce that system, irrespective of intentions. Lorde (2018) illustrates this well in the metaphor: the master’s tools (i.e. the dynamics, language, and conceptual framework that create and maintain social inequities) never serve to dismantle the master’s house, but somehow end up building another extension of that mansion. Similarly, the fundamental assumption under the medical model of disability serves to both disempower the individual and strengthen societal perception that the neurodivergent person is the problem. Thus, we need lasting, sustainable, and widespread empowerment that can be obtained by making and propagating the shift from the medical to the social model, or use both in order to encourage a constructive dialogue. Put simply, in order to fulfil our potential, we as neurodivergent people cannot say that there is something wrong with us, and we must use the tools of the social model to temper or remove barriers provided by the medical model.&lt;/p>
&lt;p>According to Feminist Standpoint theory (Harding, 1992; Pohlhaus, 2002), it is important that we empower under-represented and marginalised voices in knowledge production, and draw upon the lived experience when designing for under-represented voices. However, this is not possible, as we still follow psychology&amp;rsquo;s positivist (i.e., all authentic knowledge is scientific knowledge) tradition; this assumes that there is a fundamental truth of human diversity and that scientists should be objective. However, the research conducted on neurominorities is marred by the fact scientists are like everyone else. We are humans with different political views and lived experiences as well as biases (e.g. confirmation bias), which affect the questions that are asked and influence researchers’ degrees of freedom. Therefore, studies into neurodiversity are undertaken within structures that are characterised by power relationships, where colour, gender and neurological makeup are in no way neutral. This leads to neurodivergent individuals being treated as an _object _of the conversation, rather than the &lt;em>subject&lt;/em>. This is analogous to the way the Eastern Societies and their members were treated by Western Researchers in the mid and late 20th Century (see Said&amp;rsquo;s Orientalism for further discussion; Said, 1976). &amp;ldquo;The Orient&amp;rdquo; was othered, misunderstood and seen as inferior, which led to a very skewed depiction which reflected Western biases. In post-colonial times, our awareness of power relations is, at least in some academic publications, greater than before. However, in the case of neurodiversity, there has been little change as most studies in the area are still conducted by those in possession of greater social power, with little input from neurodivergent researchers. This approach is not only patronising, but very dangerous as it will take centuries to counteract the discrimination it produces.&lt;/p>
&lt;p>The power structure that dominates psychology and social sciences is from white, male and able-bodied people who treat neurodivergent people as an &lt;em>object&lt;/em> of the conversation, not the &lt;em>subject&lt;/em>. As argued by Jackson (1998, p.8), &amp;ldquo;Each person is at once a subject for himself or herself - a _who _- and an object for others - a &lt;em>what&lt;/em>. And though individuals speak, act, and work toward belonging to a world of others, they simultaneously strive to experience themselves as world makers&amp;rdquo;. Once we consider that scientists are human, and neurodivergent people can be included in this research, then we can co-create projects that allow us to discover the truth about diversity from different perspectives. This is more commonly discussed in qualitative research but rarely even considered in quantitative research. In addition, with different perspectives, there is an emphasis on moving away from the typical White, Educated, Industrial, Rich, Democratic (WEIRD) samples that account for 80% of study samples but only 12% of the world population, despite the fact that this movement does not acknowledge the neurodiversity movement or neurominorities (e.g. autistic, ADHD, dyslexic). In addition, there is a lack of patient involvement in how to make the research more likely to improve the quality of life of neurodivergent people. The need to address this issue and to ensure disabled and marginalised individuals are directly included in research and policy-making decisions that affect them can be expressed by the commonly used slogan “Nothing about us without us”. Emancipatory and/or participatory approaches such as participatory action research (e.g. Bertilsdotter-Rosqvist et al., 2019; Fletcher-Watson et al., 2018; Grant &amp;amp; Kara, 2021; Leadbitter et al., 2021; Strang et al., 2019; Strang et al., 2021) have considerable potential for facilitating this type of collective knowledge creation and driving social change that benefits neurodivergent people in areas that may contrast with many mainstream research approaches.&lt;/p>
&lt;p>A recent movement has become important in education: open scholarship. This reflects the idea that knowledge of all kinds should be openly shared, transparent, rigorous, reproducible, replicable, accumulative, and inclusive (allowing for all knowledge systems). Open scholarship includes all activities that are not solely limited to research such as teaching and pedagogy. One key foundation of open scholarship is accessibility, a key facet that also belongs to the neurodiverse movement (e.g. Brown &amp;amp; Leigh, 2018; Brown et al., 2018). Accessibility and inclusion is where your content, activities and all their components are accessible to all people with disabilities, learning differences, mental health conditions or other health conditions that may affect their learning or engagement with the materials and activities, research activities, clinical training, and teaching (Victor et al., 2021a). It highlights the importance of embracing diversity and making everyone feel welcome and valued (see
&lt;a href="http://www.bristol.ac.uk/digital-education/inclusion/neurodiversity/" target="_blank" rel="noopener">information sheet&lt;/a>). Discussions have been, however, scarce regarding not only how open scholarship can advance the neurodiverse movement, but also how it can benefit from it. It is thus a priority to build community to discuss how the neurodiversity movement can be included in open scholarship, as the lived experience of neurodivergent individuals (including encountered barriers) may help to enhance accessibility, allowing open scholarship to be truly open (Whitaker &amp;amp; Guest, 2020). This in turn may help to dismantle the harmful stereotypes about disabled individuals (Devendorf et al., 2021), providing more specific provisions for neurodivergent and/or disabled researchers (e.g. virtual conferences; see Levitis et al., 2021). Furthermore, including this population in academia will help promote work-life balance, by denormalising overwork and practices that lead to burnout.&lt;/p>
&lt;p>There has been a recent shift towards the use of Universal Design for Learning (UDL) (i.e., an approach to teaching highlighting that academics/tutors should be proactively, not reactively, inclusive by making adjustments to their teaching without students having to disclose their disability to student disability services) in higher education (Burgstahler &amp;amp; Cory, 2010). UDL has several benefits: by offering a more flexible and inclusive practice, there is no need to disclose one’s disability, irrespective of student status (Clouder et al., 2020). In addition, making the assumption about the student’s intention based on your interpretation of their behaviour can be damaging for neurodivergent students’ self-esteem. University staff should recognise the different manners in which students may communicate and contribute, whilst being open to collaborating with students to find suitable approaches. Put simply, it can be described as neurodiversity involvement for pedagogy.&lt;/p>
&lt;p>In addition, UDL allows students to engage in the material that best suits their learning. Traditionally, university students are assessed through essays/ dissertations, group/individual presentations or examinations with very little discussion but neurodivergent students may find these types of assignments challenging that otherwise may succeed. UDL encourages educators to examine the students’ strengths, as opposed to weaknesses and allows students to have more choice. Learners could do a recorded presentation, as opposed to presenting in a group or present the skills they have acquired on the course in a different form that may suit them better. This would benefit the students in terms of better preparation for employment, by focusing on the student’s ability and professional values, as opposed to the challenges. This approach is also fully aligned with the UK Professional Standards Framework in Higher Education (UKPSF) as it facilitates educators' continuous development (A5), focuses on respecting individual learners and diverse learning communities (V1), promotes participation in higher education and equality of opportunity for learners (V2) and acknowledges the wider context in which higher education operates recognising the implications for recognising the implications for professional practice (V4). Another example is that attendance should not be used as a marker of class engagement, as there are several variables that predict class attendance (e.g. keeping pace with other students, attentional demands, and attendance being socially impossible). At the start of class, educators should signpost the expected outline and inform students before an activity is finished or changed. This lack of physical attendance and/or inability to follow attentional cues is not evidence of a lack of engagement but that students may engage in ways that are not expected and we should meet them where they are now, as opposed to where we expect them to be.&lt;/p>
&lt;p>An important core property of UDL is to provide choice to allow students to develop agency in their own learning. Lecturers may feel that academic standards will not be maintained or students will not learn the learning outcomes but this choice aims to remove structural barriers that are faced when perhaps making a specific activity unnecessarily difficult, as opposed to reducing the academic level. For instance, lecture capture allows the student to learn in an environment that suits them and to learn at their own pace. Over decades, lecturers have questioned the effectiveness of lecture capture (Nordmann et al., 2021), but students such as dyslexic students, who otherwise struggled, may engage with learning and develop at their own speed (Nightingale et al., 2019). Rather than develop concerns on whether students will continue to engage, UDL offers students an opportunity to develop agency in their learning, a goal that lecturers should encourage. And applied more broadly to the academic employees’ relationships, UDL can also improve the academic culture, providing academic workers with opportunities to engage in their trade in a way that fits their neurocognitive style. Last but not least, UDL promotes and facilitates social justice and equality.&lt;/p>
&lt;p>Finally, we want academia to approach neurodiversity in the same way that true cosmopolitans approach cultural diversity. We want academics to reject the idea that the lived experiences of neurominorities such as dyslexia, autism, ADHD, which differs from the neuromajority, should be pathologised. Rather, these experiences should be accepted as fundamental to the human experience, to allow us to have different perspectives to understand what it means to be human. As a result, by considering this perspective, ‘‘our strengths and deficits will shape, not deny, our humanity’ (Grinker, 2010, p.173).&lt;/p>
&lt;p>Put simply, our team wants people in academia and the open scholarship community to understand that: “Being disabled does not make a person any less of a scientist. Actively listen to your students and/or peers if they disclose their disabilities, as they have entrusted you with sharing this important part about themselves. **If you are in a position of power and a disabled person asks for accommodations, give it to them. **Learn to recognise that disabilities are unique and dynamic. Ultimately, we should strive for universal design, of both our workspaces and pedagogy, as this gives everybody the best chance to fully be themselves and blossom in science” (
&lt;a href="https://ecoevocommunity.nature.com/posts/disability-pride-month-at-communications-biology" target="_blank" rel="noopener">Middleton, 2021&lt;/a>).&lt;/p>
&lt;h3 id="our-plans">Our plans&lt;/h3>
&lt;p>Our overall aims are to: reduce the stigma neurodivergent individuals face by raising awareness of the contributions neurodivergent researchers have made, encourage neurodivergent researchers that there is no need to mask or hide our differences, and show that neurodiversity is an asset to open scholarship and academia. Open scholarship, like psychological science, benefits from neurodiversity and disabled perspectives, which have been growing in the past decade (e.g. Chown et al., 2017; Gillespie-Lynch et al., 2017; Grant &amp;amp; Kara, 2021; Kapp, 2020).&lt;/p>
&lt;p>Currently, we are in the initial stages of creating a database of papers written by neurodivergent researchers. This will be a comprehensive crowd-sourced database of research written by neurodivergent researchers with the aim to allow educators to diversify their syllabi to include neurodivergent researchers to help counteract the bias towards able-bodied researchers. This database will help students feel that they can belong in academia, and that neurodivergent or disabled people can have some important strengths in research contexts (Grant &amp;amp; Kara, 2021). This project aims to be a “living“ resource, which will be regularly updated to include new studies authored by neurodivergent researchers.&lt;/p>
&lt;p>In addition, we will engender a survey which will be similar to Victor et al. (2021b) and Devendorf et al. (2021). Their surveys investigated prevalence of lived experience, discussed the lived experiences and stigma (e.g. attitudes towards self-relevant research, help-seeking, disclosure) of mental health challenges among applied psychology researchers. The neurodiversity survey will detail the proportion of neurodivergent students and researchers (e.g. undergraduate students, graduate students, post-doctoral researchers) from different countries and different disciplines. It will investigate experiences in academia, possible concerns and barriers (e.g. external stigma, self stigma and difficulties in help-seeking) of neurodivergent students and researchers. In addition, we will discuss attitudes towards the neurodiversity movement, open scholarship, and the intersectionality between neurodiversity and open scholarship. We believe our work will improve neurodiverse representation and awareness. More importantly, we hope our work will also promote the inclusion of neurodiversity within the scientific community and the next generation of neurodivergent scientists. By including a neurodiverse population, “we have a huge opportunity to not only advance our science but also to equitably serve all of humanity” (Ghai, 2021, p2). Thus, we can encourage ourselves to broaden our minds and to truly be “open” in open scholarship.&lt;/p>
&lt;p>Finally, we are also currently planning a manuscript that will take the form of a position statement, detailing how neurodiversity and open scholarship can benefit from each other. With these additional resources to combat the biases, prejudices and misconceptions of disability, you may be surprised what we can bring to the table and we hope these resources can enable us to do just that.&lt;/p>
&lt;h3 id="join-us">Join us!&lt;/h3>
&lt;p>We need to discuss the challenges faced by neurodivergent people, so they can feel seen. It is a wonderful experience to be seen and heard. We feel sad that not all neurodivergent people will encounter the same privileges that we have encountered. They feel these things so hard and this impacts their mental health, and in turn, leads to very upsetting ends. Neurodivergent people have been marginalised in so many ways that we have missed so many opportunities to make their lives that much better. We cannot change what has happened in the past; however, we hope that the resources we create will help improve representation early in students’ careers, so then they can hold their head high and smile, knowing they do not need to mask anymore. Also, they can feel proud that they can be themselves, achieve things with the correct reasonable adjustments and be treated as an equal, not an inferior. Put simply, we would like ally neurotypical academics of the neurodiverse movement and disabled academics to
&lt;a href="https://forrt.org/about/get-involved/" target="_blank" rel="noopener">join us&lt;/a> at FORRT, so we can provide &amp;ldquo;more effective support…[including] specific provisions for disabled researchers, online conferences and the ability to work from home&amp;rdquo; (Niedernhuber et al., 2021 p.34). These provisions need to continue post-COVID-19 pandemic because we cannot return back to normalcy. Not because it is not possible, but because the conversation about disability, race and gender has truly started and we are not letting this conversation end until everyone feels included in their environment. We want everyone not to just survive, but to thrive and flourish in their respective environment.&lt;/p>
&lt;h3 id="history-of-team-neurodiversity">History of Team-Neurodiversity&lt;/h3>
&lt;p>This project began on the 24th June 2021 meeting of the Society for the Improvement of Psychological Science in a roundtable discussion,
&lt;a href="https://docs.google.com/document/d/e/2PACX-1vSGIkhtdNoTURaeCkpCWrVS64md_U2cCXNape5nAa1cZOuz1vKGg66wblntTSiH6JtuS6FXDiu9PFm0/pub#id.jjj4ixyqr7k" target="_blank" rel="noopener">“How can open scholarship support evidence-based learning in people with neurodiverse conditions?”&lt;/a> led by Dr. Tamara Kalandaze and Dr. Mahmoud Elsherif. During this roundtable discussion, Dr. Amélie Gourdon-Kanhukamwe attended this discussion. As a result of a fruitful discussion, an initial framework was developed that led to a discussion about how open scholarship and neurodiversity intersect, and on the 28th of June 2021, Team Neurodiversity was created. However, Team Neurodiversity did not have a home to discuss open scholarship and neurodiversity topics. The Framework for Open and Reproducible Research Training (FORRT) kindly offered us a base so we could establish ourselves and become a tour de force in this area. Although it started with five members, it has grown to a smashing total of 56 members based in more than 8 countries and is still increasing! The team has finished working on a database on neurodivergent scholars; a blog about open scholarship and its intersection with neurodiversity, which has been expanded to a position statement manuscript; a manuscript accepted in the British Psychological Society Cognitive Psychology Bulletin and a manuscript accepted in Association in Psychological Science. Currently, we are developing a survey to assess masking and neurodivergence in academia and the convergence between open scholarship values and neurodivergent values. We have a rotating leadership team which changes every six months. To promote diverse and inclusive leadership, anyone can put themselves forward for this role, regardless of their experience. The current team leaders are Magdalena Grose-Hodge and Bethan Iley. Thank you to our previous team leaders: Amélie Gourdon-Kanhukamwe, Flávio Azevedo, and Mahmoud Elsherif.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>Bertilsdotter Rosqvist, H., Kourti, M., Jackson-Perry, D., Brownlow, C., Fletcher, K., Bendelman, D., &amp;amp; O&amp;rsquo;Dell, L. (2019). Doing it differently: emancipatory autism studies within a neurodiverse academic space. Disability &amp;amp; Society, 34(7-8), 1082-1101. &lt;a href="https://doi.org/10.1080/09687599.2019.1603102">https://doi.org/10.1080/09687599.2019.1603102&lt;/a>&lt;/p>
&lt;p>Botha M. (2021). Academic, Activist, or Advocate? Angry, Entangled, and Emerging: A Critical Reflection on Autism Knowledge Production. Frontiers in psychology, 12, 727542. &lt;a href="https://doi.org/10.3389/fpsyg.2021.727542">https://doi.org/10.3389/fpsyg.2021.727542&lt;/a>&lt;/p>
&lt;p>Brown, N., &amp;amp; Leigh, J. (2018). Ableism in academia: where are the disabled and ill academics?. Disability &amp;amp; Society, 33(6), 985-989. https:/doi.org/10.1080/09687599.2018.1455627&lt;/p>
&lt;p>Brown, N., Thompson, P., &amp;amp; Leigh, J. S. (2018). Making academia more accessible. Journal of Perspectives in Applied Academic Practice, 6(2), 82-90. &lt;a href="https://doi.org/10.14297/jpaap.v6i2.348">https://doi.org/10.14297/jpaap.v6i2.348&lt;/a>&lt;/p>
&lt;p>Burns, K. E., Pattani, R., Lorens, E., Straus, S. E., &amp;amp; Hawker, G. A. (2021). The impact of organizational culture on professional fulfillment and burnout in an academic department of medicine. PloS one, 16(6), e0252778. &lt;a href="https://doi.org/10.1371/journal.pone.0252778">https://doi.org/10.1371/journal.pone.0252778&lt;/a>&lt;/p>
&lt;p>Burgstahler, S. E., &amp;amp; Cory, R. C. (2010). Universal design in higher education: From principles to practice. Harvard Education Press.&lt;/p>
&lt;p>Chown, N., Robinson, J., Beardon, L., Downing, J., Hughes, L., Leatherland, J., &amp;hellip; &amp;amp; MacGregor, D. (2017). Improving research about us, with us: a draft framework for inclusive autism research. Disability &amp;amp; society, 32(5), 720-734.https://doi.org/10.1080/09687599.2017.1320273&lt;/p>
&lt;p>Clouder, L., Karakus, M., Cinotti, A., Ferreyra, M. V., Fierros, G. A., &amp;amp; Rojo, P. (2020). Neurodiversity in higher education: A narrative synthesis. Higher Education, 80(4), 757-778. &lt;a href="https://doi.org/10.1007/s10734-020-00513-6">https://doi.org/10.1007/s10734-020-00513-6&lt;/a>&lt;/p>
&lt;p>Devendorf, A., Victor, S. E., Rottenberg, J., Miller, R., Lewis, S., Muehlenkamp, J. J., &amp;amp; Stage, D. L. (2021, November 7). Stigmatizing our own: Self-relevant research is common but frowned upon in clinical, counseling, and school psychology. &lt;a href="https://doi.org/10.31234/osf.io/szg5d">https://doi.org/10.31234/osf.io/szg5d&lt;/a>&lt;/p>
&lt;p>Farahar, C. (2021, May 13) How can we enable neurodivergent academics to thrive? LSE Higher Education Blog.&lt;/p>
&lt;p>Fletcher-Watson, S., Adams, J., Brook, K., Charman, T., Crane, L., Cusack, J., &amp;hellip; &amp;amp; Pellicano, E. (2019). Making the future together: Shaping autism research through meaningful participation. Autism, 23(4), 943-953. &lt;a href="https://doi.org/10.1177/1362361318786721">https://doi.org/10.1177/1362361318786721&lt;/a>&lt;/p>
&lt;p>Gillespie-Lynch, K., Kapp, S. K., Brooks, P. J., Pickens, J., &amp;amp; Schwartzman, B. (2017). Whose expertise is it? Evidence for autistic adults as critical autism experts. Frontiers in psychology, 8, 438. &lt;a href="https://doi.org/10.3389/fpsyg.2017.00438">https://doi.org/10.3389/fpsyg.2017.00438&lt;/a>&lt;/p>
&lt;p>Grant, A., &amp;amp; Kara, H. (2021). Considering the Autistic advantage in qualitative research: the strengths of Autistic researchers. Contemporary Social Science, 16(5), 589-603. &lt;a href="https://doi.org/10.1080/21582041.2021.1998589">https://doi.org/10.1080/21582041.2021.1998589&lt;/a>&lt;/p>
&lt;p>Grinker R R. (2010). Commentary: On being autistic and social. Ethos, 38 (1), 172-8.&lt;/p>
&lt;p>Harding, S. (1992). Rethinking standpoint epistemology: What is&amp;quot; strong objectivity?&amp;quot;. The Centennial Review, 36(3), 437-470. &lt;a href="https://www.jstor.org/stable/23739232">https://www.jstor.org/stable/23739232&lt;/a>&lt;/p>
&lt;p>Jackson, M. (1998) Minima Ethnographica: Intersubjectivity and the Anthropological Project. Chicago: University of Chicago Press.&lt;/p>
&lt;p>Kapp, S. K. (2020). Autistic community and the neurodiversity movement: Stories from the frontline. Springer Nature.&lt;/p>
&lt;p>Leadbitter, K., Buckle, K. L., Ellis, C., &amp;amp; Dekker, M. (2021). Autistic self-advocacy and the neurodiversity movement: Implications for autism early intervention research and practice. Frontiers in Psychology, 782.https://doi.org/10.3389/fpsyg.2021.635690&lt;/p>
&lt;p>Levitis, E., Van Praag, C. D. G., Gau, R., Heunis, S., DuPre, E., Kiar, G., &amp;hellip; &amp;amp; Maumet, C. (2021). Centering inclusivity in the design of online conferences—An OHBM–Open Science perspective. GigaScience, 10(8), giab051.https://doi.org/10.1093/gigascience/giab051&lt;/p>
&lt;p>Lloyd, T. (2019). An audit of ADHD service provision for adults in England. &lt;a href="https://www.adhdfoundation.org.uk/wp-content/uploads/2019/07/Takeda_Will-the-doctor-see-me-now_ADHD-Report.pdf">https://www.adhdfoundation.org.uk/wp-content/uploads/2019/07/Takeda_Will-the-doctor-see-me-now_ADHD-Report.pdf&lt;/a>&lt;/p>
&lt;p>Lorde, A. (2018). The master&amp;rsquo;s tools will never dismantle the master&amp;rsquo;s house. Penguin UK.&lt;/p>
&lt;p>Mellifont, D. (2021). Ableist ivory towers: a narrative review informing about the lived experiences of neurodivergent staff in contemporary higher education. Disability &amp;amp; Society, 1-22. &lt;a href="https://doi.org/10.1080/09687599.2021.1965547">https://doi.org/10.1080/09687599.2021.1965547&lt;/a>&lt;/p>
&lt;p>Niedernhuber, M., Haroon, H., &amp;amp; Brown, N. (2021). Disabled scientists’ networks call for more support. Nature, 591(7848), 34-34. &lt;a href="https://doi.org/10.1038/d41586-021-00544-8">https://doi.org/10.1038/d41586-021-00544-8&lt;/a>&lt;/p>
&lt;p>Nightingale, K. P., Anderson, V., Onens, S., Fazil, Q., &amp;amp; Davies, H. (2019). Developing the inclusive curriculum: Is supplementary lecture recording an effective approach in supporting students with Specific Learning Difficulties (SpLDs)?. Computers &amp;amp; Education, 130, 13-25. &lt;a href="https://doi.org/10.1016/j.compedu.2018.11.006">https://doi.org/10.1016/j.compedu.2018.11.006&lt;/a>.&lt;/p>
&lt;p>Nordmann, E., Clark, A., Spaeth, E., &amp;amp; MacKay, J. R. (2021). Lights, camera, active! appreciation of active learning predicts positive attitudes towards lecture capture. Higher Education, 1-22. &lt;a href="https://doi.org/10.1007/s10734-020-00674-4">https://doi.org/10.1007/s10734-020-00674-4&lt;/a>&lt;/p>
&lt;p>Pohlhaus, G. (2002). Knowing communities: An investigation of Harding&amp;rsquo;s standpoint epistemology. Social epistemology, 16(3), 283-293. &lt;a href="https://doi.org/10.1080/0269172022000025633">https://doi.org/10.1080/0269172022000025633&lt;/a>&lt;/p>
&lt;p>Said, E.W. (1978). Orientalism. New York: Pantheon&lt;/p>
&lt;p>Singer, J. (2017). NeuroDiversity: The Birth of an Idea. Amazon Kindle eBook, self-published.&lt;/p>
&lt;p>Strang, J. F., Klomp, S. E., Caplan, R., Griffin, A. D., Anthony, L. G., Harris, M. C., &amp;hellip; &amp;amp; van der Miesen, A. I. (2019). Community-based participatory design for research that impacts the lives of transgender and/or gender-diverse autistic and/or neurodiverse people. Clinical practice in pediatric psychology, 7(4), 396 .https://doi.org/10.1037/cpp0000310&lt;/p>
&lt;p>Strang, J. F., Knauss, M., van der Miesen, A., McGuire, J. K., Kenworthy, L., Caplan, R., &amp;hellip; &amp;amp; Anthony, L. G. (2021). A clinical program for transgender and gender-diverse neurodiverse/autistic adolescents developed through community-based participatory design. Journal of Clinical Child &amp;amp; Adolescent Psychology, 50(6), 730-745. &lt;a href="https://doi.org/10.1080/15374416.2020.1731817">https://doi.org/10.1080/15374416.2020.1731817&lt;/a>&lt;/p>
&lt;p>Victor, S. E., Schleider, J. L., Ammerman, B. A., Bradford, D. E., Devendorf, A., Gruber, J., … Stage, D. L. (2021a, July 12). Leveraging the Strengths of Psychologists with Lived Experience of Psychopathology. &lt;a href="https://doi.org/10.31234/osf.io/ksnfd">https://doi.org/10.31234/osf.io/ksnfd&lt;/a>&lt;/p>
&lt;p>Victor, S. E., Devendorf, A., Lewis, S., ROTTENBERG, J., Muehlenkamp, J. J., Stage, D. L., &amp;amp; Miller, R. (2021b, July 12). Only human: Mental health difficulties among clinical, counseling, and school psychology faculty and trainees. &lt;a href="https://doi.org/10.31234/osf.io/xbfr6">https://doi.org/10.31234/osf.io/xbfr6&lt;/a>&lt;/p>
&lt;br></description></item><item><title>The PaPOR TRaIL Course</title><link>https://forrt.org/educators-corner/009-papor-trail/</link><pubDate>Mon, 10 Jan 2022 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/009-papor-trail/</guid><description>&lt;br>
&lt;p>Open research is an umbrella term incorporating a range of principles and practices that make research more transparent, reproducible and accessible to everyone in the society. Open and transparent research practices, including research conduct and dissemination of findings, are essential to both those who produce and those who engage with research can access knowledge. Such principles and practices are relevant at all stages of the research cycle and are applicable to all disciplines, though it has been predominantly highlighted in the sciences and medicine. Further, though the principles of open research are consistent across disciplines, open research practices can be implemented differently across disciplines, thereby enhancing the transparency and robustness of research within and across disciplines&lt;/p>
&lt;p>There are benefits of open research for individual researchers, including improved research quality and discoverability, shorter publication embargo periods, and reduced engagement in questionable research practices (QRPs). Open research practices also support the democratisation of scientific knowledge, and enables a greater number of people to engage with research. Training and education in open research principles and practices at early stages of individuals research journey is essential to maximise use of open research practices contributing the aforementioned benefits. Undergraduate and postgraduate students in particular can benefit significantly from training and education in open research at these formative stages. To date, open research educational resources have typically been aimed at PhD students, postdoctoral and more senior researchers, rather than undergraduate and master’s-level students, despite this learning period serving as the foundation to everything that follows.&lt;/p>
&lt;p>The Principles and Practices in Open Research: Teaching, Research, Impact and Learning (PaPOR TRaIL) course was developed to provide a foundation in best scientific practice that benefits students, universities, and research as a whole. Our focus was to develop an open educational resource that would provide a comprehensive introduction to open research, and to help students incorporate open research in their research projects.&lt;/p>
&lt;p>PaPOR TRaIL is a freely available online course that was developed with students and research supervisors and funded by a National Forum for the Enhancement of Teaching and Learning in Higher Education award. Though primarily designed for undergraduate and Masters level students, the course is also applicable for PhD students and researchers looking for an introduction to open research. The course includes text-based materials, visuals, videos, templates, real-world examples, and activities for students to complete.&lt;/p>
&lt;p>The course is comprised of an introductory module that introduces students to what open research is, why it is important, and how to do it. This introductory module can be completed by students as a standalone self-directed module that they complete in their own time. The introductory module is also designed so that it can be used as a Lecture that can be integrated into existing research courses by educators. The introductory module sections are shown below&lt;/p>
&lt;p>&lt;img src="Picture1.jpg" alt="The introductory module sections" width="700" >&lt;/p>
&lt;p>Once students complete the introductory module they can complete any or all of the six practice-based modules that provide a more hands-on approach to _doing _open research Students do not need to complete all six modules, some modules may be more or less relevant to the stage of their research project and they can always come back to do other modules at a later date. When students complete the introductory and all practice modules, they receive a certificate of completion. The six practice-based modules are shown below:&lt;/p>
&lt;p>&lt;img src="Picture2.jpg" alt="The six practice-based modules" width="700" >&lt;/p>
&lt;p>The course is openly available to anyone who is interested, and is open for free enrolment here:
&lt;a href="https://open.ucc.ie/browse/all/cpd/courses/papor-trail-principles-and-practices-of-open-research-003cpd" target="_blank" rel="noopener">PaPOR TRaIL&lt;/a>&lt;/p>
&lt;p>The course also has an open licence (CC BY), which means the course content can be re-used and remixed to suit different educator and institutional/organisation needs, provided attribution is given to the PaPOR TRaIL team.&lt;/p>
&lt;p>To download course content, please enrol at the
&lt;a href="https://open.ucc.ie/browse/all/cpd/courses/papor-trail-principles-and-practices-of-open-research-003cpd" target="_blank" rel="noopener">PaPOR TRaIL&lt;/a> site.&lt;/p>
&lt;p>All course materials will be made available on our OSF page in 2022, following any refinements required in the course based on initial student feedback.&lt;/p>
&lt;p>Details of the course development can be found here:
&lt;a href="https://hrbopenresearch.org/articles/3-84" target="_blank" rel="noopener">https://hrbopenresearch.org/articles/3-84&lt;/a>&lt;/p>
&lt;p>Further information, including our PaPOR TRaIL video, can be found here:
&lt;a href="https://osf.io/863ks/" target="_blank" rel="noopener">https://osf.io/863ks/&lt;/a>&lt;/p>
&lt;br>
&lt;p>&lt;strong>Contact information&lt;/strong>&lt;/p>
&lt;hr>
&lt;p>
&lt;a href="https://open.ucc.ie/browse/all/cpd/courses/papor-trail-principles-and-practices-of-open-research-003cpd" target="_blank" rel="noopener">The PaPOR TRaIL Course&lt;/a>&lt;/p>
&lt;p>
&lt;a href="mailto:karen.msikar@ucc.ie">Dr Karen Matvienko-Sikar&lt;/a>, , School of Public Health, University College Cork, on behalf of the PaPOR TRaIL team.&lt;/p></description></item><item><title>The Open Research Toolkit</title><link>https://forrt.org/educators-corner/008-open-research-toolkit/</link><pubDate>Sat, 13 Nov 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/008-open-research-toolkit/</guid><description>&lt;p>Open research helps increase the visibility of important discoveries and extend them to new places. It also helps to increase participation in research by underrepresented and underfunded groups. The open research ecosystem extends beyond just open access to data and publications. The principles of openness in research should extend to the entire research lifecycle, including education. I have chosen the term ecosystem because open research is an interconnected system. This system consists of philosophies, concepts, principles, practices, tools, and resources which when taken together are intended to make the research process open, transparent, accessible, and reusable by anyone.&lt;/p>
&lt;p>I have been the Data Curation Librarian at
&lt;a href="https://www.lib.utk.edu/" target="_blank" rel="noopener">University of Tennessee, Knoxville, Libraries&lt;/a> since 2013. During this time, I have helped hundreds of researchers meet the requirements of research funders and publishers to make their research data openly accessible. I have taught countless webinars and workshops on data management best practices, FAIR data principles, and open data. While open data is a major pillar of open research, it is only one component of the broad landscape of open research. I felt it would be a disservice to the research community I served if I did not situate my work within the larger context of open research and embrace the principles and practices in my own work. This began my quest to learn more about the open research landscape. To have the focused time to learn and to develop a resource for others, I applied and was approved for faculty development leave to devote one full semester to developing a series of training modules on various topics within open research. They were partly for my own benefit to learn the landscape and partly for the benefit of others who I was sure would be interested in learning more about the topic. The resulting product is the
&lt;a href="https://doi.org/10.17605/OSF.IO/A4FTW" target="_blank" rel="noopener">Open Research Toolkit&lt;/a> (ORT).&lt;/p>
&lt;p>Feedback on the ORT has been positive. My primary goal in creating this was to help librarians skill up on open research principles and practices. The feedback from this audience has been especially positive and grateful. Colleagues have indicated that the ORT’s publication is timely as they are teaching a course on open research or are implementing internal training in their library next semester. I have also heard from domain specialist scientists who have noted it would be helpful as a first introduction to open research concepts for non-academic audiences or early career researchers. My hope for the ORT is that it could be used as a continuing education resource or supplemental materials in courses across a wide range of sciences and social sciences disciplines. To encourage adoption and reuse, I decided to assign it the least restrictive Creative Commons License (CC-By) to all original materials.&lt;/p>
&lt;p>The process of creating the ORT spanned about a year. I initially began reading and collecting resources on myriad open research topics around January of 2021. All resources were added to an EndNote library organized by topic. I then methodically went through these resources and created a list of main topics I wanted to cover. Once my faculty development leave officially began, I actively created the modules on the identified topics. The first step was creating an outline for each module which pulled in content from all the resources gathered. Next, I created PowerPoint slides for each module. Then I created a script for the modules for someone to follow if they wanted to deliver the module. Then I created a narrated YouTube video of the content of each module to which I added subtitles for accessibility. Finally, I created Google Slides of each module and narration files in PDF and Word formats. All these materials are available on the Open Science Framework.&lt;/p>
&lt;blockquote>
&lt;p>Each module contains a slide deck in both PowerPoint and Google Slides, presentation notes in docx and pdf, a narrated video of the slides, and a bibliography of resources related to the topic.&lt;/p>
&lt;/blockquote>
&lt;p>All videos are publicly accessible on
&lt;a href="http://doi.org/10.7290/ORT_Videos" target="_blank" rel="noopener">YouTube&lt;/a>, and the video files are available for download from the
&lt;a href="https://doi.org/10.17605/OSF.IO/A4FTW" target="_blank" rel="noopener">Open Science Framework&lt;/a>. Videos on YouTube contain both English and Spanish subtitles. ORT has been assigned a Creative Commons 4.0 Attribution (
&lt;a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener">CC-By&lt;/a>) license to all original work in the ORT, so anyone can use and adapt however they like with attribution to the author.&lt;/p>
&lt;p>The modules in the Open Research Toolkit currently cover the following topics. Links to each module’s materials are provided.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Module 1: The Open Research Ecosystem [
&lt;a href="https://youtu.be/XnI3HmiJ_TU" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/cmh2r/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/gqwta/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/ahvxd/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 2: Principles &amp;amp; Practices of Open Research [
&lt;a href="https://youtu.be/6eV6YHgvpSk" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/q439h/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/v9g7q/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/qw5mk/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 3: The Philosophical Underpinning of Open Research [
&lt;a href="https://youtu.be/i6_RRYBH7uc" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/2mgkr/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/ak682/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/hp7n5/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 4: Open Access to Published Research [
&lt;a href="https://youtu.be/9UUGv93-hTA" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/vhmnz/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/prenk/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/pektx/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 5: Open Access to Research Data [
&lt;a href="https://youtu.be/LW849Rqf8hg" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/am49n/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/y754z/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/v6jk2/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 6: FAIR Data Principles [
&lt;a href="https://youtu.be/XPhIgL5phFo" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/xchjp/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/szxav/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/9un5c/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 7: Reproducibility of Research [
&lt;a href="https://youtu.be/MyzQSe6KiLs" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/9t8xm/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/xazqr/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/x65dh/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 8: The Five Rs of Open Research [
&lt;a href="https://youtu.be/AcKBNPPNgp0" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/kywpx/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/tcky6/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/84mex/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 9: Open Peer Review [
&lt;a href="https://youtu.be/GHVoVHV1xyk" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/q6bpz/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/68agv/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/tnjk8/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 10: Open Licensing of Data &amp;amp; Software [
&lt;a href="https://youtu.be/_gnIAejr_js" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/52nyk/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/avpme/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/ekygv/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 11: Open Advocacy [
&lt;a href="https://youtu.be/pCxb2wgZZEI" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/p798v/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/5d78q/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/zac8p/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 12: Citizen Science [
&lt;a href="https://youtu.be/kj053ov8Qfg" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/s8z5c/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/z26e3/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/kymwe/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 13: Open Policies [
&lt;a href="https://youtu.be/pw6faLOdTdc" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/zpje3/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/zqc3t/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/27xuv/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 14: Open Education Resources [
&lt;a href="https://youtu.be/_BlrPmtM938" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/v83rg/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/qm82w/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/5pv86/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>More resources and additional modules may be added over time. Future resources and modules may include topics such as open research ethics, open source software and collaborative platforms, and creating more detailed curricula for those interested in using the ORT for a course. Please let me know how you use the material so I can track its adoption and use.&lt;/p>
&lt;p>In the spirit of openness, if you have ideas for additions or would like to collaborate on new modules, please contact me (info below).&lt;/p>
&lt;p>All resources in the ORT can be found at the following DOI:
&lt;a href="https://doi.org/10.17605/OSF.IO/A4FTW" target="_blank" rel="noopener">https://doi.org/10.17605/OSF.IO/A4FTW&lt;/a>.&lt;/p>
&lt;p>All videos are on the ORT channel on YouTube at the following DOI:
&lt;a href="http://doi.org/10.7290/ORT_Videos" target="_blank" rel="noopener">http://doi.org/10.7290/ORT_Videos&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Contact information&lt;/strong>:&lt;/p>
&lt;hr>
&lt;p>
&lt;a href="mailto:OpenResearch@utk.edu">Open Research Toolkit&lt;/a>&lt;/p>
&lt;p>
&lt;a href="mailto:ceaker@utk.edu">Christopher Eaker&lt;/a>&lt;/p>
&lt;p>Data Curation Librarian, University of Tennessee Libraries&lt;/p></description></item><item><title>Innovative Mentoring</title><link>https://forrt.org/educators-corner/007-easy-steps-to-elevate-your-mentoring/</link><pubDate>Mon, 13 Sep 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/007-easy-steps-to-elevate-your-mentoring/</guid><description>&lt;p>In academia there are some common ‘good practice’ mentoring things. Many of us do the ‘typical’ activities that good mentors do: weekly group meetings, individual meetings, open door policy, practice presentations, intellectual engagement, iterative writing feedback on theses, grants, and papers, collaborative interactions, and promoting work-life balance. But we can do more –much more– than the basics, without it taking a ton of time. Here are some innovative ways to up your mentoring game.&lt;/p>
&lt;p>Get more out of group meetings. Like many labs, we meet each week. But we rotate what we do, each in approximately equal measure: standard journal article discussion, discussion of a research article on Equity/Diversity/Inclusion (EDI), “Slide Improv”, and Fact or Fiction.&lt;/p>
&lt;p>EDI articles are chosen on a rotating basis by students. They are usually primary research articles. We conscientiously choose papers from diverse areas of EDI. These discussions have been fantastic, and have led to changes in how we do and discuss things. An added benefit is that this is a visible way to show the group that EDI is important to me as their supervisor.&lt;/p>
&lt;p>Slide improv gives experience thinking on the fly. One of the greatest fears students have in presenting is “what if I screw up” or “what if I forget what to say,” and slide improv gives them actual practice in how to respond to, and be more comfortable with, those moments. To do slide improv, a student makes a five-slide presentation (no animations). Another student gives it. The topic is supposed to be on something that isn’t our main research area, but does need to be something in science. They typically are a presentation of the background and results of a single publication. The student who is presenting doesn’t have to be accurate, but what they say has to be believable. Students are nervous doing this the first few times, but over time I’ve seen a marked improvement in confidence and presenting skills.&lt;/p>
&lt;p>Fact or fiction gives experience in critical thinking. A student gives (brief) details and results for three papers. But one of them is completely fabricated. As a group, we try to figure out which is the fake one. This is fun, and seeing the gears turn as people sort things out is great.&lt;/p>
&lt;p>&lt;img src="fig1.png" alt="">&lt;/p>
&lt;p>To get a handle on how my students are doing, and if there are issues in the lab that need addressing, I do an anonymous poll once per year. The poll covers a range of topics on the quality of life, what is working, and what isn’t. This has been VERY HELPFUL in identifying things that need fixing (and some surprises of things that I thought were issues but are fine). I use a variation of this:&lt;/p>
&lt;iframe src="https://docs.google.com/forms/d/e/1FAIpQLScGCi7iACgmVBhFcE7G90oPwuTs-g9CQkrDmOUoQ4FvoT9CfA/viewform?embedded=true" width="100%" height="700px" frameborder="0" marginheight="0" marginwidth="0">Loading...&lt;/iframe>
&lt;p>&lt;br>&lt;br>&lt;/p>
&lt;p>If you would the direct link to the google forms,
&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLScGCi7iACgmVBhFcE7G90oPwuTs-g9CQkrDmOUoQ4FvoT9CfA/viewform" target="_blank" rel="noopener">please follow this link.&lt;/a>&lt;/p>
&lt;p>Over time, I forget which new students I’ve given ‘key advice’ and expectations. So I made a document that I give to all new students. There is a different document for undergraduate Honours Thesis, MSc, and Ph.D. students, since my advice and expectations for those students differ. The document has basic things such as how many weeks ahead to give me drafts and that all students are expected to attend group meetings, and life things like you will work long hours sometimes, but this should be the exception, not the rule.&lt;/p>
&lt;p>Reading papers is important but not urgent, so gets delayed. Every 6 months I require a list of papers the students have read, annotating why they might cite it in their thesis. The expected number of papers is scaled over time. The annotations are really helpful to keep on top of reading, as a searchable document when writing, and for me to see what they are reading. Plus, with a large lab studying diverse topics, this really helps me see some papers I otherwise may miss, too! Every single student I have had make these annotations has said this was incredibly useful when writing their thesis and that they were glad they had done it.&lt;/p>
&lt;p>Lastly, don&amp;rsquo;t be afraid to try out new ways of mentoring, and toss things that don&amp;rsquo;t work. I&amp;rsquo;ve tried a lot of things that just didn&amp;rsquo;t work for my group, or didn&amp;rsquo;t work for &lt;em>this&lt;/em> group. I touch base frequently to see what works and doesn&amp;rsquo;t, and student&amp;rsquo;s like that I ask and it&amp;rsquo;s adaptable.&lt;/p>
&lt;br>
&lt;hr>
&lt;p>&lt;em>Editor&amp;rsquo;s note&lt;/em>: The present text is an adapted version of a widely shared
&lt;a href="https://twitter.com/FlyBehaviour/status/1435285335743864835" target="_blank" rel="noopener">Twitter thread&lt;/a> that resonated with so many of us. We thought it was of general interest and deserved to be memorialized, and hence we approached Amanda to adapt the thread to post it here.&lt;/p></description></item><item><title>Qualitative Open Science Practices</title><link>https://forrt.org/educators-corner/006-qualitative-os-practices/</link><pubDate>Mon, 05 Jul 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/006-qualitative-os-practices/</guid><description>&lt;h3 id="starting-with-qualitative-open-science-practices">Starting with Qualitative Open Science Practices&lt;/h3>
&lt;p>As a person who was trained primarily in research using quantitative methods but needed to do qualitative research to answer the next most pressing question, I was increasingly learning about qualitative research and how to conduct it properly. However, I had not seen much information about how to conduct qualitative research using open science practices. During my PhD, I had been introduced to open science practices as a way to improve educational research, but almost everything I saw did not seem to align with qualitative research. I asked colleagues what existed with regard to open qualitative research resources. Answer: no clue.&lt;/p>
&lt;h3 id="call-to-action">Call to action&lt;/h3>
&lt;p>We thus gathered people interested in qualitative open science research in education at the
&lt;a href="https://www.cos.io/education-reseach-2021-virtual-unconference#:~:text=February%208%2D9%2C%202021&amp;amp;text=The%20unconference%20included%20engaging%20plenary,detailed%20guidance%20for%20education%20researchers" target="_blank" rel="noopener">Virtual Unconference on Open Scholarship Practices in Education Research&lt;/a> sponsored by the
&lt;a href="https://www.cos.io/" target="_blank" rel="noopener">Center for Open Science&lt;/a>. At the conference, we brought other educational researchers and open science fans together to debate what open science qualitative research might look like, put together a list of publicly available publications and tools, and figure out what to do with this information. By the end of a few of these hackathon sessions, we had a list of videos, websites, and publications to help the community understand how to do this work. The full list is located on the
&lt;a href="https://www.oercommons.org/courseware/lesson/80058" target="_blank" rel="noopener">Open Educational Resources website&lt;/a> but will be expanded upon here in this blog. This blog is intended to be a soft entry into this space of qualitative open science research, not a comprehensive journey; take the thoughts below as suggestions &lt;em>if&lt;/em> they align with your philosophy, project, and Institutional Review Board (IRB).&lt;/p>
&lt;h3 id="output">Output&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>We started the resource list with articles that focus on the &lt;strong>basics of open science qualitative research&lt;/strong>. These articles (and Twitter threads) dive into some of the reasons why open science work is important, such as opening the ‘Black box’ of research or helping replication in later studies. And others also touch upon some of the murky issues of doing this work, like the fact that _quant _and _qual _researchers often have different ways of viewing the world and what truth is or can be. This is a good starting point so that you know that there will likely not be consensus on how to do this work well. However, if you read those and still want to try to incorporate open science into your qualitative projects, you can try this in any or all of the following areas: transparency/rigor, open materials, open access, and ethics.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transparency &amp;amp; Rigor&lt;/strong>. For transparency and rigor in qual research, this revolves around having enough information in your research so that other researchers A) know about the researcher(s) and their positionality and B) could do a similar study in the future, also known as replicating the study. For example, in the
&lt;a href="https://academic.oup.com/view-large/27217733" target="_blank" rel="noopener">COREQ guidelines&lt;/a>, there is an entire domain dedicated to transparency regarding the researchers and their backgrounds (see picture below). Researchers must also describe the context, questions, use of theory, sampling method, interview techniques, and analysis in a way that someone could imagine themselves performing those tasks. One open science practice that qualitative researchers could use to some degree before even conducting the study is preregistration. Essentially it’s like the dissertation proposal where you lay out your plan in advance. Preregistration (and registered reports, the preregistration done with a specific journal with a publication agreement) helps to ensure that a researcher does not change their stated methods after the study is completed. Explaining every detail of the study might be difficult if you are under space constraints (as with publication length requirements), which brings us to #3: open materials.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="Fig1.png" alt="Criteria for Reporting Qualitative Studies" title="Criteria for Reporting Qualitative Studies">&lt;/p>
&lt;ol start="3">
&lt;li>&lt;strong>Open Materials.&lt;/strong> Thanks to the internet, researchers have websites and repositories where they can upload the tools for others to access. In qualitative research, this might mean interview protocols, memos, coding notebooks, tools (such as Nvivo or R packages), or even the data itself. This provides a sort of audit trail so others can verify the results of the research. There is no all or nothing here; open materials, much like the rest of these open science practices, exist along a spectrum. Not only what researchers share is on a spectrum; researchers can also dictate who may access the open materials. Perhaps it’s the entire public, but it could just be people who want to verify findings (i.e., dissertation committees, participants, reviewers). Below you can see how
&lt;a href="https://www.tandfonline.com/doi/pdf/10.1080/08824096.2018.1513273" target="_blank" rel="noopener">Bowman and Keene (2018)&lt;/a> described open science practices as a layered onion with the innermost layer being the most transparent. However, no matter what or to whom materials are shared, researchers must include their plan within their consent procedures and IRB protocols to not violate any ethical boundaries.&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="Fig2.png" alt="Conceptual Onion of Open Science Practices" title="Conceptual Onion of Open Science Practices">&lt;/p>
&lt;ol start="4">
&lt;li>
&lt;p>&lt;strong>Ethics.&lt;/strong> Ethics must be considered with any research, but given the often close relationships with participants, potentially sensitive data revealed, and the fact that large amounts of data could reveal participants’ identity, ethics are huge when it comes to qualitative research. Resources both for abstract and practical purposes can be found in each section of the resources document (i.e., ethics specific to data management) and general ethical considerations are only within this section.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Open Access.&lt;/strong> Finally, researchers can consider how to share their research study. Publishing within traditional academic journals can limit who can read their work, so journals have begun providing open access tiers where researchers can pay the publisher so that the article is available to the public. Alternatively, researchers can “publish” their work online in a preprint server before it is published in a traditional publication outlet. Pre-prints can help researchers get their work out and get community feedback, although certain publications will not accept articles that have been put in a preprint server or require authors to change the pre-print or the settings on it. Open access as an open science practice appears to be generally the same for both quantitative and qualitative work, so fewer resources are here as they can be found on most open science pages.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="contact-us">Contact us&lt;/h3>
&lt;p>Our team who created this (Rachel Renbarger, Sondra Stegenga, Thomas Lösch, Sebastian Karcher, &amp;amp; Crystal Steltenpohl) hopes that you’ll find this helpful for doing this work! We are continuing to explore this area further, so you can reach out to me at rachelrenbarger (at) gmail.com if you are interested in contributing to the conversation.&lt;/p></description></item><item><title>Making lemonade out of remote teaching</title><link>https://forrt.org/educators-corner/005-remote-teaching-platform/</link><pubDate>Mon, 24 May 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/005-remote-teaching-platform/</guid><description>&lt;h2 id="making-lemonade-out-of-remote-teaching">Making lemonade out of remote teaching&lt;/h2>
&lt;p>2020 was a year of big changes for the whole world. For the academic community, it was not different. The need to rapidly switch from in-person to online teaching represented a big challenge for most educators. However, with new challenges come also new and big opportunities. Assistant Professor of Economics at Stockholm University,
&lt;a href="https://haushofer.ne.su.se/" target="_blank" rel="noopener">Johannes Haushofer&lt;/a>, saw in remote teaching the opportunity to open classes to students from low and middle-income countries.&lt;/p>
&lt;p>&lt;em>Remote Student Exchange&lt;/em> was then created as a volunteer and non-profit initiative to match professors willing to offer spots in their classes with interested students from low and middle-income countries. To facilitate the matching process, a
&lt;a href="https://remotestudentexchange.org/" target="_blank" rel="noopener">website&lt;/a> was launched. It has been a great success so far. Two weeks after its launch, there were 1701 students and 88 professors registered and more than 30 courses offered in varied disciplines such as Economics, Business, Psychology, Political Science, Neuroscience, and many others. You can browse the available courses
&lt;a href="https://remotestudentexchange.org/courses?subject_area=10" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>At FORRT, we believe that one of the most overlooked benefits of integrating open and reproducible scholarship into higher education is that of social justice. Academia is still a place of privileges that many cannot afford. We highly commend this initiative and in the hopes of helping it grow even further, we have invited Johannes Haushoffer to explain a bit more how this idea came to be and to share his initial experiences with the community.&lt;/p>
&lt;p>&lt;strong>The Remote Student Exchange in a nutshell&lt;/strong>&lt;/p>
&lt;p>If you are teaching a remote course in the next few months, we highly encourage you to consider taking part in this initiative. Students can sign up free of charge, but they do not receive official grades or credits. This means that this initiative is informal and in most cases, it should not require permission from universities or department chairs.&lt;/p>
&lt;p>To participate, visit the website
&lt;a href="https://remotestudentexchange.org/" target="_blank" rel="noopener">https://remotestudentexchange.org/&lt;/a>. In the home page (see figure below) you can sign up as a professor.&lt;/p>
&lt;p>&lt;img src="Fig1.png" alt="Remote Student Exchange" title="Remote Student Exchange">&lt;/p>
&lt;p>After confirming your email account, you will be able to set up the details of the course you want to offer. As shown in the figure below, you will be asked to indicate the subject area, the level of the course (e.g., bachelor, master, Ph.D. level), and any prerequisites for attending the course (e.g., specific courses and areas of knowledge). You should also provide the link to where the classes take place (e.g., Zoom).&lt;/p>
&lt;p>&lt;img src="Fig2.png" alt="Remote Student Exchange: New Course" title="Remote Student Exchange: New Course">&lt;/p>
&lt;p>Importantly, you are flexible to decide how many students you can host and how they can participate (see the figure below showing the settings for course availability). You can accept students to actively participate with questions, discussions, and assignments, and/or you can accept students to audit silently only. You can also decide to review applications to your course and choose which students to accept or to admit enrolled students on a first-come-first-served basis.&lt;/p>
&lt;p>&lt;img src="Fig3.png" alt="Remote Student Exchange: Availability" title="Remote Student Exchange: Availability">&lt;/p>
&lt;p>Interested students also have to sign up on the website. They will be able to browse the courses being currently offered and apply to take part in a class, provided it still has free spots and that they fulfill the prerequisites (if any).&lt;/p>
&lt;p>If you have more questions, make sure to access the
&lt;a href="https://remotestudentexchange.org/help" target="_blank" rel="noopener">FAQ&lt;/a> and watch the video below where Johannes explains a bit more about this initiative. We hope that many more scholars consider joining it. Share this idea widely with other educators and with students that may be interested. You can find a link to the countries contemplated by this initiative
&lt;a href="https://data.worldbank.org/?locations=XM-XP" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;br>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/5kyjnPFSmog" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;center>
&lt;p>
&lt;a href="https://www.youtube.com/watch?v=5kyjnPFSmog" target="_blank" rel="noopener">Video Interview Direct Link to YouTube&lt;/a>&lt;/p>
&lt;/center></description></item><item><title>Teaching the why and how of replication studies</title><link>https://forrt.org/educators-corner/004-teaching-why-how-replication/</link><pubDate>Tue, 04 May 2021 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/004-teaching-why-how-replication/</guid><description>&lt;p>Psychological science is in the midst of a “credibility crisis” in which its practitioners re-examine their practices and re-define what constitutes study rigor. Replication studies have formed a critical role in motivating this sense of crisis – a sense of crisis that has led directly to the current movement to improve psychological science through a “credibility revolution”.&lt;/p>
&lt;p>Despite this important role, when I was invited to hold a virtual two-day, 10-hour workshop on replication studies for the students and faculty of the Department of Social and Organizational Psychology at ISCTE in Lisbon, I realized that I did not have any ready-made teaching materials on this important topic. This blog shares the guiding principles of the workshop and my finished materials so that you, the reader, can learn from my experiences.&lt;/p>
&lt;p>My workshop materials, including a &lt;strong>syllabus&lt;/strong>, &lt;strong>suggested readings&lt;/strong>, and &lt;strong>exercises&lt;/strong>, are freely available at
&lt;a href="https://osf.io/m9bzh/" target="_blank" rel="noopener">https://osf.io/m9bzh/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Workshop overview&lt;/strong>&lt;/p>
&lt;p>My workshop describes the &lt;em>why&lt;/em> and &lt;em>how&lt;/em> of replication studies: &lt;em>why&lt;/em> a researcher might want to conduct a replication study and &lt;em>how&lt;/em> a researcher should go about conducting a replication study. It also emphasizes some issues that are often neglected in discussions of replication studies, at least in my experience, including the importance of choosing good replication targets, the importance of resource constraints in doing good sample size planning, and the use of simulation studies in sample size planning.&lt;/p>
&lt;p>The workshop proceeded in four modules, as shown in this workshop slide:&lt;/p>
&lt;p>&lt;img src="fig1.png" alt="Workshop Organization" title="Workshop Organization">&lt;/p>
&lt;p>Each module is structured around one or two learning goals, or big-picture takeaway points that I wanted the students to understand at the end of the module. Each module also breaks up lecture sections with independent or guided exercises. The exercises are intended to both reinforce the content of the lecture and give the students hands-on experience with a broad swathe of the skills that go into replication research.&lt;/p>
&lt;p>The remaining sections of the blog will describe the content of each module, how this content reinforces the module’s learning goals, and the exercises I used for each module.&lt;/p>
&lt;p>&lt;strong>Module 1: The credibility crisis&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals:&lt;/em> &lt;em>The credibility crisis revealed weaknesses in research; these weaknesses are caused by hidden processes that don’t show up in published reports&lt;/em>&lt;/p>
&lt;p>This module is framed around a schematic version of how empirical psychological science works (adapted from
&lt;a href="https://www.nature.com/articles/s41562-016-0021" target="_blank" rel="noopener">Munafo et al., 2017&lt;/a>).&lt;/p>
&lt;p>&lt;img src="fig2.png" alt="Sometimes your hypothesis will be wrong, Figuring out why helps our theories improve." title="Sometimes your hypothesis will be wrong, Figuring out why helps our theories improve.">&lt;/p>
&lt;p>In the schematic, you generate a hypothesis from theory, design a study to test the hypothesis, collect data based on the study design, analyze the data to test the hypothesis, interpret the results, publish the data, and begin the cycle anew. By using this process to compare discrepancies between your hypothesis and the data, you can identify flaws in your theoretical assumptions, which allows you to revise the theories and improve them.&lt;/p>
&lt;p>However, a variety of events made psychologists aware that something about this cycle wasn’t working. First was the observation that only about 8% of the results published in psychology journals are negative (
&lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0010068" target="_blank" rel="noopener">Fanelli, 2010&lt;/a>) – yet these negative results are necessary to identify flaws in theoretical assumptions. Second was the publication of a paper by the well-respected social psychologist Daryl Bem, who, in 2011, published a somewhat unusual paper in the world’s top journal for social psychology, the &lt;em>Journal of Personality and Social Psychology&lt;/em> (
&lt;a href="https://psycnet.apa.org/record/2011-01894-001" target="_blank" rel="noopener">Bem, 2011&lt;/a>). This paper used methods that met or exceeded the standards of rigor that were typical for the time, but advanced a claim that was patently absurd: that college students (and, by extension, everyday people) could be influenced by future events.&lt;/p>
&lt;p>&lt;img src="fig3.png" alt="Daryl&amp;rsquo;s Bem &amp;ldquo;Feeling the Future&amp;rdquo;" title="Daryl's Bem Feeling the Future">&lt;/p>
&lt;p>This paper suggested either that everything we knew about physics was wrong or (perhaps more likely) that the research methods in social psychology that we used to think were rigorous were somehow flawed.&lt;/p>
&lt;p>I then describe how these observations spurred a &lt;em>credibility crisis&lt;/em> (not a “replication crisis”, as the crisis is broader than just a lack of replicability) in which researchers investigated whether and how research methods in social psychology are flawed. I use two exercises to illustrate some of the problems.&lt;/p>
&lt;p>In
&lt;a href="https://osf.io/58hdp/" target="_blank" rel="noopener">the first&lt;/a>, the students use a
&lt;a href="https://jeanmoneger.shinyapps.io/SizeMatters/" target="_blank" rel="noopener">free shiny app&lt;/a> to simulate how the combination of the selective publication of positive results and low statistical precision create huge distortions in our understanding of the evidence supporting a particular psychological theory. This exercise demonstrates the concepts of statistical power, precision, and publication bias and demonstrates the general method of using simulation studies to understand what happens when some quantity (in the context of a simulation, a &lt;em>parameter&lt;/em>) varies.&lt;/p>
&lt;p>In
&lt;a href="https://osf.io/y3467/" target="_blank" rel="noopener">the second&lt;/a>, the students use FiveThirtyEight’s
&lt;a href="https://projects.fivethirtyeight.com/p-hacking/" target="_blank" rel="noopener">p-hacking app&lt;/a> to illustrate what makes p-hacking possible. I randomly assigned students to either the Republican party or the Democratic party and to either make their assigned party look good or bad. This exercise illustrates how p-hacking can emerge from the combination of flexible definitions / measurement and a desire to obtain a certain result.&lt;/p>
&lt;p>I close the module by describing how published research reports only constitute a subset of what goes into creating a certain research funding and how processes like p-hacking and publication bias, while hidden, can undermine a finding’s credibility. Thus, one way we can uncover the credibility of a finding is to make visible more aspects of the research process. The next module describes one way to achieve this greater level of visibility.&lt;/p>
&lt;p>&lt;img src="fig4.png" alt="What we see and what we don&amp;rsquo;t see" title="What we see and what we don't see">&lt;/p>
&lt;p>&lt;strong>Module 2: Replications as a way of highlighting what is known&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals:&lt;/em> &lt;em>Close replications test the credibility of a finding. They work best with good documentation &amp;amp; structured ways of choosing replication targets&lt;/em>&lt;/p>
&lt;p>This module starts with the question of how to determine whether a particular finding is “credible”. One way is to fix in place the &lt;em>hypothesis&lt;/em> and try to do the study again. When you do the next study, you can either vary certain aspects of the method or duplicate the past method as carefully as possible. Although I don’t yet introduce this terminology, these two sets of scenarios illustrate the ideas behind a &lt;em>close replication&lt;/em> and a &lt;em>distant replication&lt;/em>.&lt;/p>
&lt;p>I then ask the students to complete
&lt;a href="https://osf.io/n243q/" target="_blank" rel="noopener">an exercise&lt;/a> to think about the conclusions that are reasonable in close and distant replications. The goal of this exercise is to illustrate how close replications (where you keep the method similar) are particularly informative when they give you results that differ from a set of past results because they call into question the credibility of the original results. However, they are less informative when you get results that are similar to the original.&lt;/p>
&lt;p>In contrast, distant replications (where you vary some aspect of the method) are particularly informative when you get results similar to the original results because they allow you to generalize across the methodological feature that you varied. However, they are less informative when you get results that differ from the original because, in addition to all the explanations that apply when you do a close replication, the features that you intentionally varied could also have produced the different results.&lt;/p>
&lt;p>&lt;img src="fig5.png" alt="Close vs Distant Replication" title="Close vs Distant Replication">&lt;/p>
&lt;p>I also use this exercise to highlight the importance of minimizing sampling error and fully documenting procedures; both sampling error and undocumented differences in procedure (“hidden moderators”) provide possible explanations for why replication results differ from original results. This highlights a somewhat hidden side benefit of replications: they force you to very carefully document a particular procedure.&lt;/p>
&lt;p>To illustrate how to document the procedure behind a replication study, I introduce the students to the “replication recipe” (
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0022103113001819" target="_blank" rel="noopener">Brandt et al., 2014&lt;/a>). The replication recipe provides a structured set of questions to guide the process of creating a method section for a replication study. As
&lt;a href="https://osf.io/j3pna/" target="_blank" rel="noopener">an exercise&lt;/a>, I ask students to fill out the first section of the replication recipe with an article that I assign (I pre-selected two articles that are short and have a relatively simple research design). After the exercise, we discuss the process of using the replication recipe and identify issues that came up – including the poor reporting standards of most (but not all) psychology articles.&lt;/p>
&lt;p>In the last part of this module, we discuss a way to choose replication targets. I teach a somewhat informal version of a framework developed by
&lt;a href="https://osf.io/preprints/metaarxiv/2gurz/" target="_blank" rel="noopener">Isager and colleagues (2020)&lt;/a>. As
&lt;a href="https://osf.io/zjwcg/" target="_blank" rel="noopener">an exercise&lt;/a>, the students use the framework to rate the value, uncertainty, and cost of doing the replication study that I assigned them.&lt;/p>
&lt;p>&lt;img src="fig6.png" alt="Choosing an effect to replicate" title="Choosing an effect to replicate">&lt;/p>
&lt;p>&lt;strong>Module 3: Resource planning and piloting&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals: Resources are critical for making your replication precise; you should think through the sample your resources allow &amp;amp; use those to calculate your power&lt;/em>&lt;/p>
&lt;p>This module subsumes most of the content that would normally be taught as “power analysis”. The reason I frame power analysis as “resource planning” is to emphasize the critical, and often unrecognized, role that resources (time, money, skills) play in the number of observations a replication study achieves. I teach two workflows for planning resources: a &lt;strong>resource-first workflow&lt;/strong> based on identifying the practical constraints to one’s resources and determining the power those constraints allow to detect different effect sizes, and &lt;strong>smallest-effect-size-of-interest workflow&lt;/strong> based on identifying a smallest effect size of interest and the number of observations (i.e., resources) required to achieve different levels of power to detect that effect.&lt;/p>
&lt;p>&lt;img src="fig7.png" alt="We Live in a Resource-Constrained World" title="We Live in a Resource-Constrained World">&lt;/p>
&lt;p>The module relies heavily on &lt;em>
&lt;a href="https://debruine.github.io/faux/" target="_blank" rel="noopener">faux&lt;/a>&lt;/em>, an R package for simulating fake data that fits a specific set of constraints. I link the idea of simulation studies back to the first module and tell the students that I am giving them a powerful set of tools to conduct their own simulation studies. I do not assume that students know how to use R, but rather wrote two different scripts that make simulating
&lt;a href="https://osf.io/x7upv/" target="_blank" rel="noopener">two-group&lt;/a> and
&lt;a href="https://osf.io/wdqem/" target="_blank" rel="noopener">four-group&lt;/a> designs easy, even for a complete R novice. My goal is to give the students some tools to do basic tasks in R, as well as resources to learn more about simulations in R if they have the time and interest.&lt;/p>
&lt;p>A hidden goal of this module is to demonstrate how under-resourced most past research really is. For example, when I illustrate the resource-first workflow, I assume that we have enough resources to achieve 80 observations per cell in a two-group design – a number of resources that meets or exceeds the sample sizes used during the 2000s in social psychology (
&lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0109019" target="_blank" rel="noopener">Fraley &amp;amp; Vazire, 2014&lt;/a>). This design yields abysmal power to detect most reasonably-sized effects.&lt;/p>
&lt;p>&lt;img src="fig8.png" alt="SESOI smallest-effect-size-of-interest workflow" title="SESOI smallest-effect-size-of-interest workflow">&lt;/p>
&lt;p>As another example, when I illustrate the smallest-effect-size-of-interest workflow, I assume that the target effect is part of an interaction. Interactions require about
&lt;a href="https://statmodeling.stat.columbia.edu/2018/03/15/need-16-times-sample-size-estimate-interaction-estimate-main-effect/" target="_blank" rel="noopener">16 times&lt;/a> the sample size to detect than main effects, a fact that is illustrated vividly in the simulation-based power curve from this part of the module.&lt;/p>
&lt;p>&lt;img src="fig9.png" alt="Notes" title="Notes">&lt;/p>
&lt;p>One last issue that comes out of the simulations is the number of assumptions that one must make in the process of doing a simulation study. This includes both statistical assumptions, such as the size of the standard deviation of the outcome measure, and non-statistical assumptions, such as the length of time it takes for a typical participate in the study (a fact that is necessary to accurately estimate the number of participants who can participate in a lab-based study, for example). I argue that pilot studies are useful for developing good values for these assumptions. Pilot studies are &lt;em>not&lt;/em> useful for directly estimating the value of the target effect size itself (
&lt;a href="https://www.sciencedirect.com/science/article/pii/S002210311630230X?casa_token=OETt_Sm5VFEAAAAA:-9rK8QScds9e0A1siznusvdtvl0-yC2WpBVWe7ztdGkZ8eVILbyqWMC5WmcsAxHWp6X7X7voPeA" target="_blank" rel="noopener">Albers &amp;amp; Lakens, 2018&lt;/a>); in any case it is better to power to a smallest effect size of interest than the expected effect size.&lt;/p>
&lt;p>&lt;img src="fig10.png" alt="Workflow 2" title="Workflow 2">&lt;/p>
&lt;p>&lt;strong>Module 4: Preregistration&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals: To preregister something, create an OSF project &amp;amp; put the replication recipe in the registry. There’s evidence this helps make research more credible&lt;/em>&lt;/p>
&lt;p>The bulk of this module is focused around completing a pre-registration for the article assigned to the students in the previous modules. Because the workshop participants have already completed the first part of the replication recipe (
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0022103113001819" target="_blank" rel="noopener">Brandt et al., 2014&lt;/a>) for this article, they are already familiar with the article’s purpose and materials. For the first part of this module, the students complete the remainder of the replication recipe (or at least, as much as they can) as part of
&lt;a href="https://osf.io/w35fp/" target="_blank" rel="noopener">the last exercise&lt;/a> of the workshop.&lt;/p>
&lt;p>The replication recipe in hand, the students can complete a replication recipe-based preregistration on the Open Science Framework (
&lt;a href="https://osf.io" target="_blank" rel="noopener">OSF&lt;/a>). I walk the students through this process and introduce them to the basics of uploading materials on an OSF page. But the students already completed hard parts of preregistration as part of the previous exercises.&lt;/p>
&lt;p>&lt;img src="fig11.png" alt="Preregistration on the Open Science Framework" title="Preregistration on the Open Science Framework">&lt;/p>
&lt;p>I spend the remainder of this module reviewing evidence of what a well-planned and well-executed preregistration can do for the credibility of research.&lt;/p>
&lt;p>&lt;img src="fig12.png" alt="Preregistration can help on a wide variety of research problems." title="Preregistration can help on a wide variety of research problems.">&lt;/p>
&lt;p>I also briefly cover Registered Reports, which circumvent publication bias through a staged review process. At stage 1, a proposal is reviewed prior to any data collection. At stage 2, the proposal is reviewed again, and as long as the researcher executes their accepted study protocol, published regardless of results. I give the students a
&lt;a href="https://www.cos.io/initiatives/registered-reports" target="_blank" rel="noopener">list of journals&lt;/a> that accepts registered reports if they’re interested in conducting a study with this publication format.&lt;/p>
&lt;p>&lt;img src="fig13.png" alt="Registered Reports" title="Registered Reports">&lt;/p>
&lt;p>&lt;strong>Conclusion: Use my materials!&lt;/strong>&lt;/p>
&lt;p>Replications have played a critical, though I think sometimes misunderstood, role in spurring the credibility revolution: they are one way of investigating the credibility of a particular research finding. The primary way they do this, I think, is by serving as a tool to highlight previously unknown pieces of information, either during the process of documenting the procedure (so it can be successfully executed) or via the results themselves. This role deserves to be underscored in teaching materials. I also think replications can be a useful venue to highlight other parts of the research process, such as decisions about what to research and resource planning. The structure of my finished workshop reflects this general outlook.&lt;/p>
&lt;p>If you find my materials useful, please use them! The materials are freely available in
&lt;a href="https://osf.io/m9bzh/" target="_blank" rel="noopener">this repository&lt;/a>. Let’s use our teaching to pass the lessons of the credibility revolution on to the next generation of behavioral scientists.&lt;/p></description></item><item><title>Developing a comprehensive directory of tools and technologies for social science research methods</title><link>https://forrt.org/educators-corner/003-developing-tools/</link><pubDate>Mon, 04 Jan 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/003-developing-tools/</guid><description>&lt;h2 id="developing-a-comprehensive-directory-of-tools-and-technologies-for-social-science-research-methods">Developing a comprehensive directory of tools and technologies for social science research methods&lt;/h2>
&lt;p>Often the search and exploration of tools and technologies in social science research is not part of the class curriculum in the same way as the systematic review of literature is. This, sadly, leaves the becoming researcher in a place of disadvantage, in my opinion. In their early research career, students will mostly rely on their supervisor or peers to advise on the tools they use, which is still a very limited sample. However, with strides in technological development, researchers could choose from a growing number of multivariate tools for social science methods rising from within the discipline itself, as well as borrowed from other disciplines or coming from the commercial sector.&lt;/p>
&lt;p>Starting from this premise, we decided to build a
&lt;a href="https://ocean.sagepub.com/research-tools-directory#categories" target="_blank" rel="noopener">tools directory&lt;/a> for social scientists, a simple solution for a place where any researcher or student can come and find the right tool for what they need. In this piece, I explain how the tools directory was developed and how it can be used by educators, researchers and students.&lt;/p>
&lt;h3 id="developing-the-tools-directory">Developing the tools directory&lt;/h3>
&lt;p>The initial list was based on software tools and tech platforms that we knew were popular among social science researchers because we’ve commissioned books about them, or they have been prominent within the community. We continued to ask academics, look through papers and other lists like the
&lt;a href="http://dirtdirectory.org/" target="_blank" rel="noopener">DiRT Directory&lt;/a> from the Digital Humanities, the
&lt;a href="https://wiki.digitalmethods.net/Dmi/ToolDatabase" target="_blank" rel="noopener">Digital Methods Initiative&lt;/a> and
&lt;a href="https://sourceforge.net/" target="_blank" rel="noopener">SourceForge&lt;/a>. Soon enough, the directory was growing out of control. What we thought would be a simple scroll down page, organised in a few basic categories, was not serving its purpose any longer.&lt;/p>
&lt;p>With around three hundred different software packages and tools that we knew were used by some or many social science researchers in their work, a new challenge was becoming apparent. It was a paradox-of-choice situation. On one hand, it was increasingly clear why academics often rely solely on recommendations from their peers when choosing a tool. And on the other hand, we knew we needed to explore how one would choose the right tool from a list, and ultimately how to teach others to find the tool that fits their own purposes rather than simply recommending a tool they’ve used.&lt;/p>
&lt;p>As the list grew, we enlisted the help of a few master students, and started collecting more data: who built these tools, were they free or paid, what cluster of similar tools would they belong to, when were they built, based on the information available could we tell whether they were up to date, scaling, or failed, could we find papers that cited these tools, were the creators recommending a citation etc.&lt;/p>
&lt;p>When we hit 400 software packages/tools, we knew we had to promote this list and share it in a way that researchers would actually stumble upon it and have the opportunity to reference it in a lecture or paper. So we wrote a
&lt;a href="https://uk.sagepub.com/en-gb/eur/technologies-for-social-science-research" target="_blank" rel="noopener">whitepaper summarizing the big trends on the development of tools and tech for social science research&lt;/a>. We learned that both commercial and non-commercial tools are popular within the social sciences, but the ones that last longer and are more successful focus beyond the discipline and almost always have a person or teams of people dedicated to raising funds or expanding the community of users and contributors.&lt;/p>
&lt;p>At 400 software packages/tools, we were still not sure the list was big enough. We then focused on specific methods and researched all the tools available to carry out that method or task within the research process. We looked at the evolution of technologies for that method in particular, as well as how it fits within the development of the method itself. We call these ‘deep dives’. We’ve done deep dives on tools for annotation, or tools for transcription, surveying tools, tools for studying social media data, and we kept finding more software applications within each of these areas. We concluded these deep dives to be quite useful, as they enabled sharing slightly more comprehensive sub-lists of tools that could be used in different modules. We have now 543 tools on the list, and the number keeps growing.&lt;/p>
&lt;h3 id="how-to-use-the-tools-directory">How to use the tools directory&lt;/h3>
&lt;p>The full directory is currently available on our
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/" target="_blank" rel="noopener">GitHub repository&lt;/a> as a csv file. We decided to host it on GitHub, in order to be able to update the directory when we come across new tools or after deep dives; ensure it’s always available for others to reuse in its most up-to-date form, and enable instructors, students and researchers to add tools that might be missing.&lt;/p>
&lt;p>Educators teaching research methods or preparatory courses for students’ theses could present the full tools directory to students, so they are more flexible in finding the right tools for their needs and future projects.Students can browse through the list and filter for tools to find a tool that is most appropriate for a research project they are initiating. For example, a student transcribing interviews might look at the transcription tools to find alternatives. Similarly, educators that are teaching a more specialized course, such as introduction to text mining, data visualization, or social data mining, or running online experiments could filter out a sub-list of tools focusing on the explicit method. They could then share this sub-list as part of the course reference materials or assignments.&lt;/p>
&lt;p>&lt;img src="featured.png" alt="Fig. 1. The spread of 543 tools and technologies across methods and techniques." title="Fig. 1. The spread of 543 tools and technologies across methods and techniques.">&lt;figcaption>Fig. 1. The spread of 543 tools and technologies across methods and techniques.&lt;/figcaption>&lt;/p>
&lt;p>&lt;img src="fig2.png" alt="Fig. 2. Filtering to find transcription tools. A student or instructor could filter by column F (the Competitive cluster which contains the method/technique/task/area that we used to categorize the tool) to get a sub-list of tools that could be broadly used for a particular process. If the cluster is too broad, the student can look through the technique (column E), that breaks it down further. For example for social media tools, the technique would include analysis, collection, visualisation etc. If looking for more recent tools, one can filter by the year the tool was launched (column M); or if the student is interested in something that is free, they can check the charges (column N)." title="Fig. 2. The spread of 543 tools and technologies across methods and techniques.">&lt;figcaption>Fig. 2. Filtering to find transcription tools. A student or instructor could filter by column F (the Competitive cluster which contains the method/technique/task/area that we used to categorize the tool) to get a sub-list of tools that could be broadly used for a particular process. If the cluster is too broad, the student can look through the technique (column E), that breaks it down further. For example for social media tools, the technique would include analysis, collection, visualisation etc. If looking for more recent tools, one can filter by the year the tool was launched (column M); or if the student is interested in something that is free, they can check the charges (column N).&lt;/figcaption>&lt;/p>
&lt;p>While the csv file that contains the tools directory might be easy to update and share, we acknowledge that it might not be that easy to use within a classroom. We are experimenting with a variety of ways that would enable a better display and navigation of the directory, without losing from the ease of updating it.&lt;/p>
&lt;p>In 2019 we did our first deep dive into the tools for social data science to support our
&lt;a href="https://campus.sagepub.com/collecting-social-media-data" target="_blank" rel="noopener">SAGE Campus course on collecting social media data&lt;/a>. We created a sublist to share for this course to help learners find the software that might be most appropriate for their own project, especially given the variety of social media platforms available. To render
&lt;a href="https://airtable.com/shrux4hYwNG1cOyjK/tbl9NiGq87agePZ2M?backgroundColor=cyan&amp;amp;viewControls=on" target="_blank" rel="noopener">the sub-list&lt;/a> in a more friendly way, we used the free version of airtable, which is a no-code app for relational databases with a colorful and modern interface. Students would navigate to this page (Fig 3) to see the sub-list on a single table. They can then find the right tool for their social media project by selecting the platform they want to collect their data from (twitter, instagram, facebook etc), whether they are happy to pay or looking for something that’s free, and the type of task they want to perform: whether they need the tool for collecting the data, analysis, or visualization. Once they have a filtered list, they can also look through the academic papers we’ve linked where each tool has been used, to explore further the potential of the tools.&lt;/p>
&lt;p>&lt;img src="fig3.png" alt="Fig. 3. Screenshot of the sub-list containing social media tools via the free version of airtable. Similar to working with a csv file (as in Fig. 2), this interface lets the student filter the list down to narrow the choices for a tool they could use to either collect or analyse their data. This interface is web-based, and has a more inviting user experience than working with a csv file. A student can easily see the categories of tools, filter by multiple terms or concepts linked within each of the columns." title="Fig. 3. Screenshot of the sub-list containing social media tools via the free version of airtable. Similar to working with a csv file (as in Fig. 2), this interface lets the student filter the list down to narrow the choices for a tool they could use to either collect or analyse their data. This interface is web-based, and has a more inviting user experience than working with a csv file. A student can easily see the categories of tools, filter by multiple terms or concepts linked within each of the columns.">&lt;figcaption>Fig. 3. Screenshot of the sub-list containing social media tools via the free version of airtable. Similar to working with a csv file (as in Fig. 2), this interface lets the student filter the list down to narrow the choices for a tool they could use to either collect or analyse their data. This interface is web-based, and has a more inviting user experience than working with a csv file. A student can easily see the categories of tools, filter by multiple terms or concepts linked within each of the columns.&lt;/figcaption>&lt;/p>
&lt;p>We envision this sub-list of social media tools to be a starting point, as it helps the learner filter down based on a limited number of criteria, such as: the task that can be achieved (collection, analysis), the social media platform that’s integrated, and the fees.&lt;/p>
&lt;p>We’ve reused the same
&lt;a href="https://socialmediatools.pory.app/" target="_blank" rel="noopener">sub-list of social media tools with a different interface&lt;/a> (pory.io, currently in beta) to render this list of tools more akin to a catalogue of records, that the student can search and filter. This rendering was used in a bootcamp on starting off with social media research. Similar to the airtable rendering, a student could filter based on the task they want to achieve and then click into the tool to get more information and explore which one would work better.&lt;/p>
&lt;p>&lt;img src="fig4.png" alt="Fig. 4: Screenshot of the sub-list of social media tools rendered into a catalogue via the pory.io app. The user experience on this interface is friendlier than working with a table as in Fig. 2 &amp; 3. A student can filter the list by the type of tool, which is immediately visible; for example they might be looking for tools to support their data collection. They can then use the search box to enter key terms and narrow down the list further, a process that is more familiar. The student can also browse the list of tools by opening the individual cards to find more information (see next figure)." title="Fig. 4: Screenshot of the [sub-list of social media tools](https://socialmediatools.pory.app/) rendered into a catalogue via the pory.io app. The user experience on this interface is friendlier than working with a table as in Fig. 2 &amp;amp; 3. A student can filter the list by the type of tool, which is immediately visible; for example they might be looking for tools to support their data collection. They can then use the search box to enter key terms and narrow down the list further, a process that is more familiar. The student can also browse the list of tools by opening the individual cards to find more information (see next figure).">&lt;figcaption>Fig. 4: Screenshot of the
&lt;a href="https://socialmediatools.pory.app/" target="_blank" rel="noopener">sub-list of social media tools&lt;/a> rendered into a catalogue via the pory.io app. The user experience on this interface is friendlier than working with a table as in Fig. 2 &amp;amp; 3. A student can filter the list by the type of tool, which is immediately visible; for example they might be looking for tools to support their data collection. They can then use the search box to enter key terms and narrow down the list further, a process that is more familiar. The student can also browse the list of tools by opening the individual cards to find more information (see next figure).&lt;/figcaption>&lt;/p>
&lt;p>&lt;img src="fig5.png" alt="Fig. 5. Fig. 5: Once the student filters a list of tools, they can click one each card to get further information about each tool. Currently this includes a brief description, the platform supported, whether it’s free or not, and several academic papers that have used this tool." title="Fig. 5: Once the student filters a list of tools, they can click one each card to get further information about each tool. Currently this includes a brief description, the platform supported, whether it’s free or not, and several academic papers that have used this tool.">&lt;figcaption>Fig. 5: Once the student filters a list of tools, they can click one each card to get further information about each tool. Currently this includes a brief description, the platform supported, whether it’s free or not, and several academic papers that have used this tool.&lt;/figcaption>&lt;/p>
&lt;p>Airtable and pory.io have different affordances for rendering the sub-lists of tools, and our experience so far is that both have been useful. We are hoping to learn more from these experiments, to understand the student’s journey as well as the data that would inform their exploration process.&lt;/p>
&lt;p>The social media tools sub-list was part of a deep dive that we carried out in 2019. Since then, we dived into
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/2019/11/11/surveying-tools.html" target="_blank" rel="noopener">surveying tools&lt;/a> and
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/2020/01/20/text-mining.html" target="_blank" rel="noopener">text mining&lt;/a>. We have not created separate sub-lists for these, and encourage instructors to try other ways of representing these tools within their courses. If you are teaching text mining in the social sciences, for example, you can point your students to this
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/2020/01/20/text-mining.html" target="_blank" rel="noopener">overview of the text mining tools available&lt;/a> (Fig. 6 &amp;amp; Fig. 7) and share a sub-list of the tools directory filtered for text mining with your students.&lt;/p>
&lt;p>&lt;img src="fig6.png" alt="Fig. 6: Screenshot of the Text Mining section, an overview of tools available." title="Fig. 6: Screenshot of the Text Mining section, an overview of tools available.">&lt;figcaption>Fig. 6: Screenshot of the Text Mining section, an overview of tools available.&lt;/figcaption>&lt;/p>
&lt;p>&lt;img src="fig7.png" alt="Fig. 7: Text mining tools and technologies based on the process they support." title="Fig. 7: Text mining tools and technologies based on the process they support.">&lt;figcaption>Fig. 7: Text mining tools and technologies based on the process they support.&lt;/figcaption>&lt;/p>
&lt;h3 id="going-forward">Going forward&lt;/h3>
&lt;p>Going forward, we are quite interested in finding out what are the criteria people often use to filter down to their top tools, so we can build this list forward and continuously add the data that helps academics and students find the tools that fit their project best.&lt;/p>
&lt;p>We understand that lists follow some form of a hype cycle, where there is a lot of work done at the start and some engagement from the community, and then the whole project slowly dies and it is forgotten. It becomes pretty unusable, because with the pace of research and technology, a lot of the tools are out of date and many new ones have popped up. A person must be dedicated to updating the list and for now we have that covered. Since the publication of the whitepaper in November 2019, we’ve added at least 100 more tools, mostly focusing on text and data mining. While it’s relatively easy to come across new tools, the hardest bit is updating the ones that are already on the list, and that’s where we are open for suggestions from the community. The list with updates to the whitepaper are available in this
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/" target="_blank" rel="noopener">GitHub repository&lt;/a>.&lt;/p>
&lt;p>Finally, the &lt;em>locus&lt;/em> of software tools and technologies within the research ecosystem remains a big challenge. Software tools are yet to gain the credit of research output. And that is why, among other reasons, software tools are rarely cited or referenced in papers. This is not only bad for
&lt;a href="https://www.slideshare.net/danielskatz/citation-and-reproducibility-in-software" target="_blank" rel="noopener">reproducibility of research, but it also makes it difficult to help other researchers weigh in and compare different tools&lt;/a> used for similar studies. We aim to promote and include the suggested citation of the tools in our list, and strongly encourage anyone to use
&lt;a href="https://citeas.org" target="_blank" rel="noopener">https://citeas.org&lt;/a> when unsure how to give credit to these.&lt;/p>
&lt;p>We remain active and are continuously thinking of better ways to present and re-architecture the information about software tools and technologies we’ve gathered, to make it easier to navigate and explore. We hope these materials will help you and your students become more aware of the diversity of tools and technologies and will open new and potentially easier avenues to decide on the best software tool to use for your research.&lt;/p></description></item><item><title>Using the 'Transparency Checklist Guidelines' as an Educational tool</title><link>https://forrt.org/educators-corner/002-transparencychecklist-balazsaczel/</link><pubDate>Sun, 04 Oct 2020 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/002-transparencychecklist-balazsaczel/</guid><description>&lt;h1 id="transparency-checklist-guideline-for-education">Transparency Checklist Guideline for Education&lt;/h1>
&lt;h2 id="what-is-it-for">What is it for?&lt;/h2>
&lt;p>As an educational tool, the Checklist can be used to teach and improve the standards of transparency and credibility in research reports made by students. The aim is that students are embedded in transparent and open practices from the beginning of their training.&lt;/p>
&lt;p>
&lt;a href="https://docs.google.com/spreadsheets/d/1NxJG5ccRAhvLKngosRVjT8IO2OZ0UDZMN86FW5qGf0Q/edit?usp=sharing" target="_blank" rel="noopener">See here for an adapted version of the original checklist for educational purposes.&lt;/a>&lt;/p>
&lt;p>&lt;img src="Checklist_v2.png" alt="">&lt;/p>
&lt;h2 id="how-to-use-it">How to use it?&lt;/h2>
&lt;p>Supervisors and instructors can require students to create a Transparency Report along with any empirical research assignment.&lt;/p>
&lt;h3 id="steps-to-follow">Steps to follow&lt;/h3>
&lt;ul>
&lt;li>Inform the students about the Transparency Checklist.&lt;/li>
&lt;li>Add the completion of the checklist to the requirements.&lt;/li>
&lt;li>
&lt;a href="http://www.shinyapps.org/apps/TransparencyChecklist/" target="_blank" rel="noopener">Make the checklist app available to students&lt;/a>&lt;/li>
&lt;li>Be ready to answer questions if the students are uncertain about a checklist item.&lt;/li>
&lt;li>Read the Transparency Report along with the manuscript.&lt;/li>
&lt;/ul>
&lt;h3 id="optional-steps">Optional steps&lt;/h3>
&lt;ul>
&lt;li>Explain each item why it is important for transparency.&lt;/li>
&lt;li>In the classroom, ask the students to evaluate some (weakly and strongly transparent) published research papers. This can help them get familiar with the checklist and realize the importance of transparent reporting.&lt;/li>
&lt;/ul>
&lt;h2 id="how-to-evaluate-the-transparency-report">How to evaluate the Transparency Report&lt;/h2>
&lt;ul>
&lt;li>In the requirements, indicate which items should have a “yes” response. Should you want to make it easier for the students, you can require only the Short (12-item) Checklist:
&lt;a href="http://www.shinyapps.org/apps/ShortTransparencyChecklist/" target="_blank" rel="noopener">http://www.shinyapps.org/apps/ShortTransparencyChecklist/&lt;/a>&lt;/li>
&lt;li>When possible, check whether the manuscript is in line with the checklist answers.&lt;/li>
&lt;/ul>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>The following paper introduces the Transparency Checklist and describes how an initial set of items was iteratively evaluated by 45 journal editors, as well as 18 open-science advocates until a consensus was reached about the content and form of the checklist.&lt;/p>
&lt;p>Aczel, B., Szaszi, B., Sarafoglou, A. et al. A consensus-based transparency checklist. Nat Hum Behav 4, 4–6 (2020).
&lt;a href="https://www.nature.com/articles/s41562-019-0772-6" target="_blank" rel="noopener">https://www.nature.com/articles/s41562-019-0772-6&lt;/a>&lt;/p></description></item><item><title>Addressing the issue of representation in an undergraduate psych class</title><link>https://forrt.org/educators-corner/001-representation-heatherurry/</link><pubDate>Sat, 03 Oct 2020 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/001-representation-heatherurry/</guid><description>&lt;p>I want to tell y’all about one of my most meaningful teaching experiences. Pull up a chair.&lt;/p>
&lt;p>I’ve been teaching experimental psychology since 2006. It’s the flagship research methods course for undergraduate psychology majors at my institution. We now enroll 120 students each semester and, with the amazing help of 5 TAs, we offer lectures twice per week and a 2.5-hour lab once per week.&lt;/p>
&lt;p>As many of you know, the shit hit the fan when it comes to psychology research during my time teaching this class. I felt pretty dizzy for a while during and after 2011, the year that marks scales falling from my eyes.&lt;/p>
&lt;p>I didn’t really make many substantial changes to my course right away. I needed to feel like I was on firmer ground first. (I expressed that sentiment
&lt;a href="https://twitter.com/HeatherUrry/status/968638314608721921?s=20" target="_blank" rel="noopener">in this tweet thread below.&lt;/a>)&lt;/p>
&lt;p>But then, I came to realize that if I didn’t make changes to my teaching in addition to changes to my research, I was complicit. So, I got to work. Standing on the shoulders of the smart people who brought issues to light and modeled pathways to improvement, I shifted my content.&lt;/p>
&lt;p>Building on traditional topics like internal, external, &amp;amp; construct validity, reliability, measurement, hypothesis testing, etc., I started teaching about transparency, openness, questionable research practices, and effect sizes.&lt;/p>
&lt;p>We started to do IRB-approved, preregistered replication research some of which has seen or will see the light of day in published form (
&lt;a href="https://twitter.com/HeatherUrry/status/1289013799828090880?s=20" target="_blank" rel="noopener">like the example in this tweet).&lt;/a>&lt;/p>
&lt;p>We also started discussing efforts like the ManyLabs studies, the Psychological Science Accelerator (
&lt;a href="http://twitter.com/@PsySciAcc" target="_blank" rel="noopener">@PsySciAcc&lt;/a>), &amp;amp; the Collaborative Replications and Education Project (
&lt;a href="https://twitter.com/CREP_psych" target="_blank" rel="noopener">@CREP_psych&lt;/a>).&lt;/p>
&lt;p>This has all reinvigorated my love of teaching in general and this class specifically. I honestly feel like I’m fulfilling a real need. We need people in our society to have the tools to consume research responsibly, whether they go on to produce research themselves or not.&lt;/p>
&lt;p>But then 2020 happened. After centuries of oppression of Black, Indigenous, People of Color (BIPOC) in the United States, and seeing the disproportionate impact that the coronavirus is having on BIPOC folks, it finally clicked.&lt;/p>
&lt;p>My students need more from me than validity and reliability and transparency and openness. They need to feel they belong. All of them. Every one of them needs to see themselves in psychological science if that’s how they want to spend their time.&lt;/p>
&lt;p>So, this semester I introduced a single class session focused on the importance of representation in science. I borrowed ideas from Jessica Remedios (
&lt;a href="https://twitter.com/jdremedios/status/1303700486277812226?s=20" target="_blank" rel="noopener">see her terrific Twitter thread, which ends with her slides&lt;/a>).&lt;/p>
&lt;p>I had them read this work about
&lt;a href="https://www.pnas.org/content/117/17/9284" target="_blank" rel="noopener">the diversity-innovation paradox by Hofstra and colleagues&lt;/a>.&lt;/p>
&lt;p>I also invited them to watch the
&lt;a href="https://www.pictureascientist.com/" target="_blank" rel="noopener">Picture a Scientist film&lt;/a> and/or listen to the Everything Hertz podcast (
&lt;a href="https://twitter.com/hertzpodcast" target="_blank" rel="noopener">@hertzpodcast&lt;/a>) about Diversity in science
&lt;a href="https://everythinghertz.com/114" target="_blank" rel="noopener">with Jess Wade&lt;/a>.&lt;/p>
&lt;p>I talked about psychology’s positivist tradition of believing there’s some sort of objective reality that we can discover if we cleave to principles like empiricism, transparency, &amp;amp; falsifiability and how that position is marred by biases (e.g., confirmation bias, availability).&lt;/p>
&lt;p>It’s also marred by the fact that scientists are humans with standpoints that affect the questions they ask. And that power structures dominated by men and white people guide what we think is “normal” science. Such ideas aren’t commonly discussed in quantitative research circles.&lt;/p>
&lt;p>I showed them clips from
&lt;a href="https://www.pictureascientist.com/" target="_blank" rel="noopener">Picture a Scientist&lt;/a> so they could appreciate what it’s like to be a woman in science, and the progress that’s been made to remediate gender bias (e.g.,
&lt;a href="http://web.mit.edu/fnl/women/women.html" target="_blank" rel="noopener">the MIT report from 1999&lt;/a>).&lt;/p>
&lt;p>&lt;img src="iceberg.png" alt="">&lt;/p>
&lt;p>We also talked about the idea that some seem to have been left out, women of color, in particular, but also disabled, LGBTQ, first generation, indigenous people, and all their intersections.&lt;/p>
&lt;p>We talked about the loss to science, especially when innovative ideas put forward by women, people of color, and women of color are devalued (Hofstra et al., 2020).&lt;/p>
&lt;p>I showed them powerful clips of one woman of color’s experience as a scientist, professor of chemistry, Raychelle Burks (
&lt;a href="https://twitter.com/DrRubidium" target="_blank" rel="noopener">@DrRubidium&lt;/a>). Dr. Burks captured so perfectly the importance of representation.&lt;/p>
&lt;p>&lt;img src="her1.png" alt=""> &lt;img src="her2.png" alt="">&lt;/p>
&lt;p>I talked about how these problems are not limited to male-dominated sciences but that these issues pervade psychological science too.&lt;/p>
&lt;p>I showed them data from APA demonstrating the move from roughly 78% undergrad psychology majors being female to less than 50% of full professors being female. Lots of factors at play, including gender bias.&lt;/p>
&lt;p>I shared with them an email that a female colleague of color received recently that illustrated the gendered racism she faces in our field. It referenced the hardships faced by white men. (Sorry, what now?)&lt;/p>
&lt;p>I talked about my own standpoint as an educated white woman, a full professor with lots of mentorship from family members and powerful colleagues through the years. I had a lot of help getting where I am in part because of intersecting identities tied to systems of power.&lt;/p>
&lt;p>I expressed my hope that they’ll think about their own intersecting identities and if science is something they love and psychology specifically they should go for it and make room for everybody’s voices.&lt;/p>
&lt;p>I’d never talked about these ideas in my class before this week. I have also never received so much positive feedback from students. They felt seen. I don’t think I’d ever made them feel seen before, not quite like that. I feel good about that.&lt;/p>
&lt;p>I also feel sad. Students feel these things so hard, especially those we’ve marginalized in so many ways. I’ve been in undergrad classrooms for 15 years. I’ve worked with literally hundreds of students. So many missed opportunities.&lt;/p>
&lt;p>I can’t change that. But I can keep it up in future semesters. Urry is ON.&lt;/p>
&lt;p>Meanwhile,
&lt;a href="https://osf.io/597ut/" target="_blank" rel="noopener">here are some of my slides minus film clips and the email&lt;/a>. Maybe they’ll help you or someone you know address representation as a foundational idea of science at one of the earliest career stages.&lt;/p>
&lt;hr>
&lt;br>
&lt;p>&lt;em>Editor&amp;rsquo;s note: The present text is an adapted version of widely shared
&lt;a href="https://twitter.com/HeatherUrry/status/1312104732308115457?s=20" target="_blank" rel="noopener">Twitter thread&lt;/a> which resonated with so many of us. We thought it is of general interest and deserved to be immortalized, and hence we approached Heather to adapt the thread to post it here. Importantly, in addition to writing extremely current and relevant threads, Heather has also inspired the creation of FORRT. Indeed, FORRT was initiated at the 2018 meeting of the
&lt;a href="https://improvingpsych.org/" target="_blank" rel="noopener">Society for the Improvement of Psychological Science (SIPS)&lt;/a> in Heather&amp;rsquo;s
&lt;a href="https://osf.io/x7d45/" target="_blank" rel="noopener">“Teaching replicable and reproducible science”&lt;/a> hackathon with Kristen Lane.&lt;/em>&lt;/p></description></item></channel></rss>