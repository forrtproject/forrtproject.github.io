<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Educators' Corner | FORRT - Framework for Open and Reproducible Research Training</title><link>https://forrt.org/educators-corner/</link><atom:link href="https://forrt.org/educators-corner/index.xml" rel="self" type="application/rss+xml"/><description>Educators' Corner</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2022 - FORRT Framework for Open and Reproducible Research Training</copyright><image><url>https://forrt.org/media/FORRT_banner.svg</url><title>Educators' Corner</title><link>https://forrt.org/educators-corner/</link></image><item><title>Navigating Open scholarship for neurodivergent researchers</title><link>https://forrt.org/educators-corner/010-neurodiversity/</link><pubDate>Sun, 23 Jan 2022 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/010-neurodiversity/</guid><description>&lt;br>
&lt;h2 id="navigating-open-scholarship-for-neurodivergent-researchers">Navigating Open scholarship for neurodivergent researchers&lt;/h2>
&lt;h3 id="who-we-are-and-why-is-this-important">Who we are and why is this important?&lt;/h3>
&lt;p>In academia, there has been much discussion about how open scholarship can benefit marginalised voices (e.g. Robertson, 2020; Pownall et al., 2020). However, neurodivergent individuals (e.g. dyslexic, autistic, ADHD) have received little attention. According to the
&lt;a href="https://www.hesa.ac.uk/data-and-analysis" target="_blank" rel="noopener">Higher Education Statistics Agency&lt;/a>, only 2.2% in 2003/04, 3.9% in 2012/13 to 5.5% in 2019/2020 of staff at universities in the UK disclosed having a physical or neurological disability. However, the true figures are likely to be higher. Despite increased coverage and interest regarding disability issues in academia, concerns regarding negative perceptions of disability disclosure remain. More open discussions are taking place about the lived experiences of disabilities and chronic illnesses, as people with disability are becoming less stigmatised, leading to more disclosures being discussed. However, there is still a question being asked: ‘where are the disabled academics?’ (We are here but you don’t see us!).&lt;/p>
&lt;br>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/L-B8YasT-UE" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;p>Disability? How do you have a disability? You do not have a deficit with your body, you can still function in society, earn a living and participate in community life. Disability is portrayed as a personal tragedy, with some heroic individuals “overcoming” their terrible handicap. So how are you disabled? The answer is that not all disabilities are visible. The relative proportion of disabled academics is widely underestimated (e.g. Farahar, 2021), likely due to the stigma attached to the concept of disability (Mellifont, 2021). In addition, there are too many assumptions about disability being a physical or intellectual impairment with no discussion on difficulties regarding cognition and mental health. This discussion also fails to encapsulate that the range of difficulties people face may be connected to an individual’s neurodevelopmental characteristics (Singer, 2017). This is in spite of the fact that there are conditions that are described by psychologists as disabling but people with these conditions are treated as if they are not disabled. This is the ‘neurodiverse’ group.&lt;/p>
&lt;p>Neurodiversity is the non-pathological variation in the human brain regarding sociability, learning, attention, mood and other mental functions at a group level (Singer, 2017). An individual is neurodivergent if their neurology diverges from that of the neurological majority. Neurodiversity is critically relevant to the social sciences as it discusses the diverse cognitive behaviours forming the foundations of what it means to be unique and human. Importantly, the neurodiversity movement questions the assumption that all humans must conform to the same expectations in order to flourish.&lt;/p>
&lt;p>&lt;img src="fig1.png" alt="Neurodiversity" title="Neurodiversity">&lt;/p>
&lt;p>So, you may still be wondering how neurodivergent individuals are disabled? The labelling of disability is a personal matter. It depends on what models we use to interpret it. Under the medical model, disability is portrayed as a flaw, weakness or a biological limitation of the individual. Put simply, it is a personal tragedy that was inflicted on you. Disability under the social theory of disability is defined not as a personal tragedy but as the result of barriers – environmental and social practices that disable, as opposed to enabling, the individual. In addition, the social model makes the distinction that an impairment is a property of an individual body, while disability is a social process. However, it is important to remember that both models are not mutually exclusive, but are required to be used together to open a constructive dialogue between able-bodied and disabled individuals, even among disabled individuals. The important message is that disabilities are &lt;strong>dynamic&lt;/strong> and reasonable adjustments should be made for all groups.&lt;/p>
&lt;p>In today’s academic environment, the economic and political system of universities, among many other industries, focus on productivity and profit. As a result, measures that focus on productivity and profit such as standards, norms, league tables, achievements and publications are becoming more and more important. Health and wellbeing and slow science are becoming less important, despite the fact that slow science and resting are important for creativity, critical thinking and understanding data, three crucial components to help accumulate knowledge. As a result of this development, burnout becomes more common and this is more prevalent among people with disabilities (Burns et al., 2021).&lt;/p>
&lt;p>People with disabilities are more likely to be excluded from the academic workforce with its demands for speed, efficiency and productivity, leading to normalised, ingrained and internalised ableism to an extent that they desire to be able-bodied. As a result of this exclusion, able-bodied individuals may believe that disabled individuals do not contribute to the productivity of the community and argue that their unemployment is the ‘fate of the idle’ (Singer, 2017). This means that in academia and industry, people with disabilities become oppressed, mocked, ridiculed and perceived as a nuisance.&lt;/p>
&lt;p>Many gatekeepers determine whether an individual is neurodivergent and these processes are driven by individuals who are neurotypical. As a result, referral time for these services vary widely, from 4 weeks to 201 weeks within the UK (Lloyd, 2019) and if a person does not fit the criteria, the individual can be ignored and may not receive the much-needed help that they require. This can lead to poor self-esteem, unemployment (e.g. around 22% in autistic people are in any type of employment; see Figure 2 in
&lt;a href="https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/disability/articles/outcomesfordisabledpeopleintheuk/2020" target="_blank" rel="noopener">fact sheet&lt;/a>). As a result, neurodivergent individuals may blame themselves for the difficulties they encounter, as opposed to the barriers that society has placed on them.&lt;/p>
&lt;p>Despite this, people of different neurodivergent conditions or families of the people with the conditions have begun meeting and talking to each other about their experiences and one common shared experience is a history of misinterpretation and mistreatment by the dominant neurotypical cultures and its institutions such as academia. As a result of centuries of oppression of disabled people worldwide and a hyper-normalised environment, in addition to seeing the disproportionate impact of the coronavirus pandemic on disabled students (see this amazing
&lt;a href="https://link.springer.com/article/10.1007/s10639-021-10559-3" target="_blank" rel="noopener">paper &lt;/a>by Dr Joanna Zawadka), many neurodivergent and disabled staff feel discouraged in an environment that should aim to support them. They do not feel like they belong, their differences are seen as an impairment and their voice does not seem to matter. They do not see themselves represented in psychological science, academia, business, teaching or elsewhere.&lt;/p>
&lt;p>We are a group of early-career neurotypical and neurodivergent researchers that are a part of the Framework of Open Reproducible Research and Training (FORRT) community, aiming to make academia and the open scholarship community more open to neurodiversity. Everyone, no matter what they identify with, is welcome in this group. We aim to discuss how open scholarship can be intersected with the neurodiversity movement, and emphasise how differences should be highlighted and accepted, whilst supporting the idea of accessibility. Our neurodiversity team is a group that currently consists of individuals that have autism, dyspraxia/DCD, speech-language differences, ADHD, dyslexia, or are neurotypical allies. If you have these or other neurominorities and wish to be part of the team, you are more than welcome to join!&lt;/p>
&lt;h3 id="what-do-we-want">What do we want?&lt;/h3>
&lt;p>We want academia and open scholarship not to be covertly homophobic, racist, sexist and ableist. However, by attempting to adapt and work within the existing defined rules of academia and its power structures, what we do is reinforce that system, irrespective of intentions. Lorde (2018) illustrates this well in the metaphor: the master’s tools (i.e. the dynamics, language, and conceptual framework that create and maintain social inequities) never serve to dismantle the master’s house, but somehow end up building another extension of that mansion. Similarly, the fundamental assumption under the medical model of disability serves to both disempower the individual and strengthen societal perception that the neurodivergent person is the problem. Thus, we need lasting, sustainable, and widespread empowerment that can be obtained by making and propagating the shift from the medical to the social model, or use both in order to encourage a constructive dialogue. Put simply, in order to fulfil our potential, we as neurodivergent people cannot say that there is something wrong with us, and we must use the tools of the social model to temper or remove barriers provided by the medical model.&lt;/p>
&lt;p>According to Feminist Standpoint theory (Harding, 1992; Pohlhaus, 2002), it is important that we empower under-represented and marginalised voices in knowledge production, and draw upon the lived experience when designing for under-represented voices. However, this is not possible, as we still follow psychology&amp;rsquo;s positivist (i.e., all authentic knowledge is scientific knowledge) tradition; this assumes that there is a fundamental truth of human diversity and that scientists should be objective. However, the research conducted on neurominorities is marred by the fact scientists are like everyone else. We are humans with different political views and lived experiences as well as biases (e.g. confirmation bias), which affect the questions that are asked and influence researchers’ degrees of freedom. Therefore, studies into neurodiversity are undertaken within structures that are characterised by power relationships, where colour, gender and neurological makeup are in no way neutral. This leads to neurodivergent individuals being treated as an _object _of the conversation, rather than the &lt;em>subject&lt;/em>. This is analogous to the way the Eastern Societies and their members were treated by Western Researchers in the mid and late 20th Century (see Said&amp;rsquo;s Orientalism for further discussion; Said, 1976). &amp;ldquo;The Orient&amp;rdquo; was othered, misunderstood and seen as inferior, which led to a very skewed depiction which reflected Western biases. In post-colonial times, our awareness of power relations is, at least in some academic publications, greater than before. However, in the case of neurodiversity, there has been little change as most studies in the area are still conducted by those in possession of greater social power, with little input from neurodivergent researchers. This approach is not only patronising, but very dangerous as it will take centuries to counteract the discrimination it produces.&lt;/p>
&lt;p>The power structure that dominates psychology and social sciences is from white, male and able-bodied people who treat neurodivergent people as an &lt;em>object&lt;/em> of the conversation, not the &lt;em>subject&lt;/em>. As argued by Jackson (1998, p.8), &amp;ldquo;Each person is at once a subject for himself or herself - a _who _- and an object for others - a &lt;em>what&lt;/em>. And though individuals speak, act, and work toward belonging to a world of others, they simultaneously strive to experience themselves as world makers&amp;rdquo;. Once we consider that scientists are human, and neurodivergent people can be included in this research, then we can co-create projects that allow us to discover the truth about diversity from different perspectives. This is more commonly discussed in qualitative research but rarely even considered in quantitative research. In addition, with different perspectives, there is an emphasis on moving away from the typical White, Educated, Industrial, Rich, Democratic (WEIRD) samples that account for 80% of study samples but only 12% of the world population, despite the fact that this movement does not acknowledge the neurodiversity movement or neurominorities (e.g. autistic, ADHD, dyslexic). In addition, there is a lack of patient involvement in how to make the research more likely to improve the quality of life of neurodivergent people. The need to address this issue and to ensure disabled and marginalised individuals are directly included in research and policy-making decisions that affect them can be expressed by the commonly used slogan “Nothing about us without us”. Emancipatory and/or participatory approaches such as participatory action research (e.g. Bertilsdotter-Rosqvist et al., 2019; Fletcher-Watson et al., 2018; Grant &amp;amp; Kara, 2021; Leadbitter et al., 2021; Strang et al., 2019; Strang et al., 2021) have considerable potential for facilitating this type of collective knowledge creation and driving social change that benefits neurodivergent people in areas that may contrast with many mainstream research approaches.&lt;/p>
&lt;p>A recent movement has become important in education: open scholarship. This reflects the idea that knowledge of all kinds should be openly shared, transparent, rigorous, reproducible, replicable, accumulative, and inclusive (allowing for all knowledge systems). Open scholarship includes all activities that are not solely limited to research such as teaching and pedagogy. One key foundation of open scholarship is accessibility, a key facet that also belongs to the neurodiverse movement (e.g. Brown &amp;amp; Leigh, 2018; Brown et al., 2018). Accessibility and inclusion is where your content, activities and all their components are accessible to all people with disabilities, learning differences, mental health conditions or other health conditions that may affect their learning or engagement with the materials and activities, research activities, clinical training, and teaching (Victor et al., 2021a). It highlights the importance of embracing diversity and making everyone feel welcome and valued (see
&lt;a href="http://www.bristol.ac.uk/digital-education/inclusion/neurodiversity/" target="_blank" rel="noopener">information sheet&lt;/a>). Discussions have been, however, scarce regarding not only how open scholarship can advance the neurodiverse movement, but also how it can benefit from it. It is thus a priority to build community to discuss how the neurodiversity movement can be included in open scholarship, as the lived experience of neurodivergent individuals (including encountered barriers) may help to enhance accessibility, allowing open scholarship to be truly open (Whitaker &amp;amp; Guest, 2020). This in turn may help to dismantle the harmful stereotypes about disabled individuals (Devendorf et al., 2021), providing more specific provisions for neurodivergent and/or disabled researchers (e.g. virtual conferences; see Levitis et al., 2021). Furthermore, including this population in academia will help promote work-life balance, by denormalising overwork and practices that lead to burnout.&lt;/p>
&lt;p>There has been a recent shift towards the use of Universal Design for Learning (UDL) (i.e., an approach to teaching highlighting that academics/tutors should be proactively, not reactively, inclusive by making adjustments to their teaching without students having to disclose their disability to student disability services) in higher education (Burgstahler &amp;amp; Cory, 2010). UDL has several benefits: by offering a more flexible and inclusive practice, there is no need to disclose one’s disability, irrespective of student status (Clouder et al., 2020). In addition, making the assumption about the student’s intention based on your interpretation of their behaviour can be damaging for neurodivergent students’ self-esteem. University staff should recognise the different manners in which students may communicate and contribute, whilst being open to collaborating with students to find suitable approaches. Put simply, it can be described as neurodiversity involvement for pedagogy.&lt;/p>
&lt;p>In addition, UDL allows students to engage in the material that best suits their learning. Traditionally, university students are assessed through essays/ dissertations, group/individual presentations or examinations with very little discussion but neurodivergent students may find these types of assignments challenging that otherwise may succeed. UDL encourages educators to examine the students’ strengths, as opposed to weaknesses and allows students to have more choice. Learners could do a recorded presentation, as opposed to presenting in a group or present the skills they have acquired on the course in a different form that may suit them better. This would benefit the students in terms of better preparation for employment, by focusing on the student’s ability and professional values, as opposed to the challenges. This approach is also fully aligned with the UK Professional Standards Framework in Higher Education (UKPSF) as it facilitates educators' continuous development (A5), focuses on respecting individual learners and diverse learning communities (V1), promotes participation in higher education and equality of opportunity for learners (V2) and acknowledges the wider context in which higher education operates recognising the implications for recognising the implications for professional practice (V4). Another example is that attendance should not be used as a marker of class engagement, as there are several variables that predict class attendance (e.g. keeping pace with other students, attentional demands, and attendance being socially impossible). At the start of class, educators should signpost the expected outline and inform students before an activity is finished or changed. This lack of physical attendance and/or inability to follow attentional cues is not evidence of a lack of engagement but that students may engage in ways that are not expected and we should meet them where they are now, as opposed to where we expect them to be.&lt;/p>
&lt;p>An important core property of UDL is to provide choice to allow students to develop agency in their own learning. Lecturers may feel that academic standards will not be maintained or students will not learn the learning outcomes but this choice aims to remove structural barriers that are faced when perhaps making a specific activity unnecessarily difficult, as opposed to reducing the academic level. For instance, lecture capture allows the student to learn in an environment that suits them and to learn at their own pace. Over decades, lecturers have questioned the effectiveness of lecture capture (Nordmann et al., 2021), but students such as dyslexic students, who otherwise struggled, may engage with learning and develop at their own speed (Nightingale et al., 2019). Rather than develop concerns on whether students will continue to engage, UDL offers students an opportunity to develop agency in their learning, a goal that lecturers should encourage. And applied more broadly to the academic employees’ relationships, UDL can also improve the academic culture, providing academic workers with opportunities to engage in their trade in a way that fits their neurocognitive style. Last but not least, UDL promotes and facilitates social justice and equality.&lt;/p>
&lt;p>Finally, we want academia to approach neurodiversity in the same way that true cosmopolitans approach cultural diversity. We want academics to reject the idea that the lived experiences of neurominorities such as dyslexia, autism, ADHD, which differs from the neuromajority, should be pathologised. Rather, these experiences should be accepted as fundamental to the human experience, to allow us to have different perspectives to understand what it means to be human. As a result, by considering this perspective, ‘‘our strengths and deficits will shape, not deny, our humanity’ (Grinker, 2010, p.173).&lt;/p>
&lt;p>Put simply, our team wants people in academia and the open scholarship community to understand that: “Being disabled does not make a person any less of a scientist. Actively listen to your students and/or peers if they disclose their disabilities, as they have entrusted you with sharing this important part about themselves. **If you are in a position of power and a disabled person asks for accommodations, give it to them. **Learn to recognise that disabilities are unique and dynamic. Ultimately, we should strive for universal design, of both our workspaces and pedagogy, as this gives everybody the best chance to fully be themselves and blossom in science” (
&lt;a href="https://ecoevocommunity.nature.com/posts/disability-pride-month-at-communications-biology" target="_blank" rel="noopener">Middleton, 2021&lt;/a>).&lt;/p>
&lt;h3 id="our-plans">Our plans&lt;/h3>
&lt;p>Our overall aims are to: reduce the stigma neurodivergent individuals face by raising awareness of the contributions neurodivergent researchers have made, encourage neurodivergent researchers that there is no need to mask or hide our differences, and show that neurodiversity is an asset to open scholarship and academia. Open scholarship, like psychological science, benefits from neurodiversity and disabled perspectives, which have been growing in the past decade (e.g. Chown et al., 2017; Gillespie-Lynch et al., 2017; Grant &amp;amp; Kara, 2021; Kapp, 2020).&lt;/p>
&lt;p>Currently, we are in the initial stages of creating a database of papers written by neurodivergent researchers. This will be a comprehensive crowd-sourced database of research written by neurodivergent researchers with the aim to allow educators to diversify their syllabi to include neurodivergent researchers to help counteract the bias towards able-bodied researchers. This database will help students feel that they can belong in academia, and that neurodivergent or disabled people can have some important strengths in research contexts (Grant &amp;amp; Kara, 2021). This project aims to be a “living“ resource, which will be regularly updated to include new studies authored by neurodivergent researchers.&lt;/p>
&lt;p>In addition, we will engender a survey which will be similar to Victor et al. (2021b) and Devendorf et al. (2021). Their surveys investigated prevalence of lived experience, discussed the lived experiences and stigma (e.g. attitudes towards self-relevant research, help-seeking, disclosure) of mental health challenges among applied psychology researchers. The neurodiversity survey will detail the proportion of neurodivergent students and researchers (e.g. undergraduate students, graduate students, post-doctoral researchers) from different countries and different disciplines. It will investigate experiences in academia, possible concerns and barriers (e.g. external stigma, self stigma and difficulties in help-seeking) of neurodivergent students and researchers. In addition, we will discuss attitudes towards the neurodiversity movement, open scholarship, and the intersectionality between neurodiversity and open scholarship. We believe our work will improve neurodiverse representation and awareness. More importantly, we hope our work will also promote the inclusion of neurodiversity within the scientific community and the next generation of neurodivergent scientists. By including a neurodiverse population, “we have a huge opportunity to not only advance our science but also to equitably serve all of humanity” (Ghai, 2021, p2). Thus, we can encourage ourselves to broaden our minds and to truly be “open” in open scholarship.&lt;/p>
&lt;p>Finally, we are also currently planning a manuscript that will take the form of a position statement, detailing how neurodiversity and open scholarship can benefit from each other. With these additional resources to combat the biases, prejudices and misconceptions of disability, you may be surprised what we can bring to the table and we hope these resources can enable us to do just that.&lt;/p>
&lt;h3 id="join-us">Join us!&lt;/h3>
&lt;p>We need to discuss the challenges faced by neurodivergent people, so they can feel seen. It is a wonderful experience to be seen and heard. We feel sad that not all neurodivergent people will encounter the same privileges that we have encountered. They feel these things so hard and this impacts their mental health, and in turn, leads to very upsetting ends. Neurodivergent people have been marginalised in so many ways that we have missed so many opportunities to make their lives that much better. We cannot change what has happened in the past; however, we hope that the resources we create will help improve representation early in students’ careers, so then they can hold their head high and smile, knowing they do not need to mask anymore. Also, they can feel proud that they can be themselves, achieve things with the correct reasonable adjustments and be treated as an equal, not an inferior. Put simply, we would like ally neurotypical academics of the neurodiverse movement and disabled academics to
&lt;a href="https://forrt.org/about/get-involved/" target="_blank" rel="noopener">join us&lt;/a> at FORRT, so we can provide &amp;ldquo;more effective support…[including] specific provisions for disabled researchers, online conferences and the ability to work from home&amp;rdquo; (Niedernhuber et al., 2021 p.34). These provisions need to continue post-COVID-19 pandemic because we cannot return back to normalcy. Not because it is not possible, but because the conversation about disability, race and gender has truly started and we are not letting this conversation end until everyone feels included in their environment. We want everyone not to just survive, but to thrive and flourish in their respective environment.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>Bertilsdotter Rosqvist, H., Kourti, M., Jackson-Perry, D., Brownlow, C., Fletcher, K., Bendelman, D., &amp;amp; O&amp;rsquo;Dell, L. (2019). Doing it differently: emancipatory autism studies within a neurodiverse academic space. Disability &amp;amp; Society, 34(7-8), 1082-1101. &lt;a href="https://doi.org/10.1080/09687599.2019.1603102">https://doi.org/10.1080/09687599.2019.1603102&lt;/a>&lt;/p>
&lt;p>Botha M. (2021). Academic, Activist, or Advocate? Angry, Entangled, and Emerging: A Critical Reflection on Autism Knowledge Production. Frontiers in psychology, 12, 727542. &lt;a href="https://doi.org/10.3389/fpsyg.2021.727542">https://doi.org/10.3389/fpsyg.2021.727542&lt;/a>&lt;/p>
&lt;p>Brown, N., &amp;amp; Leigh, J. (2018). Ableism in academia: where are the disabled and ill academics?. Disability &amp;amp; Society, 33(6), 985-989. https:/doi.org/10.1080/09687599.2018.1455627&lt;/p>
&lt;p>Brown, N., Thompson, P., &amp;amp; Leigh, J. S. (2018). Making academia more accessible. Journal of Perspectives in Applied Academic Practice, 6(2), 82-90. &lt;a href="https://doi.org/10.14297/jpaap.v6i2.348">https://doi.org/10.14297/jpaap.v6i2.348&lt;/a>&lt;/p>
&lt;p>Burns, K. E., Pattani, R., Lorens, E., Straus, S. E., &amp;amp; Hawker, G. A. (2021). The impact of organizational culture on professional fulfillment and burnout in an academic department of medicine. PloS one, 16(6), e0252778. &lt;a href="https://doi.org/10.1371/journal.pone.0252778">https://doi.org/10.1371/journal.pone.0252778&lt;/a>&lt;/p>
&lt;p>Burgstahler, S. E., &amp;amp; Cory, R. C. (2010). Universal design in higher education: From principles to practice. Harvard Education Press.&lt;/p>
&lt;p>Chown, N., Robinson, J., Beardon, L., Downing, J., Hughes, L., Leatherland, J., &amp;hellip; &amp;amp; MacGregor, D. (2017). Improving research about us, with us: a draft framework for inclusive autism research. Disability &amp;amp; society, 32(5), 720-734.https://doi.org/10.1080/09687599.2017.1320273&lt;/p>
&lt;p>Clouder, L., Karakus, M., Cinotti, A., Ferreyra, M. V., Fierros, G. A., &amp;amp; Rojo, P. (2020). Neurodiversity in higher education: A narrative synthesis. Higher Education, 80(4), 757-778. &lt;a href="https://doi.org/10.1007/s10734-020-00513-6">https://doi.org/10.1007/s10734-020-00513-6&lt;/a>&lt;/p>
&lt;p>Devendorf, A., Victor, S. E., Rottenberg, J., Miller, R., Lewis, S., Muehlenkamp, J. J., &amp;amp; Stage, D. L. (2021, November 7). Stigmatizing our own: Self-relevant research is common but frowned upon in clinical, counseling, and school psychology. &lt;a href="https://doi.org/10.31234/osf.io/szg5d">https://doi.org/10.31234/osf.io/szg5d&lt;/a>&lt;/p>
&lt;p>Farahar, C. (2021, May 13) How can we enable neurodivergent academics to thrive? LSE Higher Education Blog.&lt;/p>
&lt;p>Fletcher-Watson, S., Adams, J., Brook, K., Charman, T., Crane, L., Cusack, J., &amp;hellip; &amp;amp; Pellicano, E. (2019). Making the future together: Shaping autism research through meaningful participation. Autism, 23(4), 943-953. &lt;a href="https://doi.org/10.1177/1362361318786721">https://doi.org/10.1177/1362361318786721&lt;/a>&lt;/p>
&lt;p>Gillespie-Lynch, K., Kapp, S. K., Brooks, P. J., Pickens, J., &amp;amp; Schwartzman, B. (2017). Whose expertise is it? Evidence for autistic adults as critical autism experts. Frontiers in psychology, 8, 438. &lt;a href="https://doi.org/10.3389/fpsyg.2017.00438">https://doi.org/10.3389/fpsyg.2017.00438&lt;/a>&lt;/p>
&lt;p>Grant, A., &amp;amp; Kara, H. (2021). Considering the Autistic advantage in qualitative research: the strengths of Autistic researchers. Contemporary Social Science, 16(5), 589-603. &lt;a href="https://doi.org/10.1080/21582041.2021.1998589">https://doi.org/10.1080/21582041.2021.1998589&lt;/a>&lt;/p>
&lt;p>Grinker R R. (2010). Commentary: On being autistic and social. Ethos, 38 (1), 172-8.&lt;/p>
&lt;p>Harding, S. (1992). Rethinking standpoint epistemology: What is&amp;quot; strong objectivity?&amp;quot;. The Centennial Review, 36(3), 437-470. &lt;a href="https://www.jstor.org/stable/23739232">https://www.jstor.org/stable/23739232&lt;/a>&lt;/p>
&lt;p>Jackson, M. (1998) Minima Ethnographica: Intersubjectivity and the Anthropological Project. Chicago: University of Chicago Press.&lt;/p>
&lt;p>Kapp, S. K. (2020). Autistic community and the neurodiversity movement: Stories from the frontline. Springer Nature.&lt;/p>
&lt;p>Leadbitter, K., Buckle, K. L., Ellis, C., &amp;amp; Dekker, M. (2021). Autistic self-advocacy and the neurodiversity movement: Implications for autism early intervention research and practice. Frontiers in Psychology, 782.https://doi.org/10.3389/fpsyg.2021.635690&lt;/p>
&lt;p>Levitis, E., Van Praag, C. D. G., Gau, R., Heunis, S., DuPre, E., Kiar, G., &amp;hellip; &amp;amp; Maumet, C. (2021). Centering inclusivity in the design of online conferences—An OHBM–Open Science perspective. GigaScience, 10(8), giab051.https://doi.org/10.1093/gigascience/giab051&lt;/p>
&lt;p>Lloyd, T. (2019). An audit of ADHD service provision for adults in England. &lt;a href="https://www.adhdfoundation.org.uk/wp-content/uploads/2019/07/Takeda_Will-the-doctor-see-me-now_ADHD-Report.pdf">https://www.adhdfoundation.org.uk/wp-content/uploads/2019/07/Takeda_Will-the-doctor-see-me-now_ADHD-Report.pdf&lt;/a>&lt;/p>
&lt;p>Lorde, A. (2018). The master&amp;rsquo;s tools will never dismantle the master&amp;rsquo;s house. Penguin UK.&lt;/p>
&lt;p>Mellifont, D. (2021). Ableist ivory towers: a narrative review informing about the lived experiences of neurodivergent staff in contemporary higher education. Disability &amp;amp; Society, 1-22. &lt;a href="https://doi.org/10.1080/09687599.2021.1965547">https://doi.org/10.1080/09687599.2021.1965547&lt;/a>&lt;/p>
&lt;p>Niedernhuber, M., Haroon, H., &amp;amp; Brown, N. (2021). Disabled scientists’ networks call for more support. Nature, 591(7848), 34-34. &lt;a href="https://doi.org/10.1038/d41586-021-00544-8">https://doi.org/10.1038/d41586-021-00544-8&lt;/a>&lt;/p>
&lt;p>Nightingale, K. P., Anderson, V., Onens, S., Fazil, Q., &amp;amp; Davies, H. (2019). Developing the inclusive curriculum: Is supplementary lecture recording an effective approach in supporting students with Specific Learning Difficulties (SpLDs)?. Computers &amp;amp; Education, 130, 13-25. &lt;a href="https://doi.org/10.1016/j.compedu.2018.11.006">https://doi.org/10.1016/j.compedu.2018.11.006&lt;/a>.&lt;/p>
&lt;p>Nordmann, E., Clark, A., Spaeth, E., &amp;amp; MacKay, J. R. (2021). Lights, camera, active! appreciation of active learning predicts positive attitudes towards lecture capture. Higher Education, 1-22. &lt;a href="https://doi.org/10.1007/s10734-020-00674-4">https://doi.org/10.1007/s10734-020-00674-4&lt;/a>&lt;/p>
&lt;p>Pohlhaus, G. (2002). Knowing communities: An investigation of Harding&amp;rsquo;s standpoint epistemology. Social epistemology, 16(3), 283-293. &lt;a href="https://doi.org/10.1080/0269172022000025633">https://doi.org/10.1080/0269172022000025633&lt;/a>&lt;/p>
&lt;p>Said, E.W. (1978). Orientalism. New York: Pantheon&lt;/p>
&lt;p>Singer, J. (2017). NeuroDiversity: The Birth of an Idea. Amazon Kindle eBook, self-published.&lt;/p>
&lt;p>Strang, J. F., Klomp, S. E., Caplan, R., Griffin, A. D., Anthony, L. G., Harris, M. C., &amp;hellip; &amp;amp; van der Miesen, A. I. (2019). Community-based participatory design for research that impacts the lives of transgender and/or gender-diverse autistic and/or neurodiverse people. Clinical practice in pediatric psychology, 7(4), 396 .https://doi.org/10.1037/cpp0000310&lt;/p>
&lt;p>Strang, J. F., Knauss, M., van der Miesen, A., McGuire, J. K., Kenworthy, L., Caplan, R., &amp;hellip; &amp;amp; Anthony, L. G. (2021). A clinical program for transgender and gender-diverse neurodiverse/autistic adolescents developed through community-based participatory design. Journal of Clinical Child &amp;amp; Adolescent Psychology, 50(6), 730-745. &lt;a href="https://doi.org/10.1080/15374416.2020.1731817">https://doi.org/10.1080/15374416.2020.1731817&lt;/a>&lt;/p>
&lt;p>Victor, S. E., Schleider, J. L., Ammerman, B. A., Bradford, D. E., Devendorf, A., Gruber, J., … Stage, D. L. (2021a, July 12). Leveraging the Strengths of Psychologists with Lived Experience of Psychopathology. &lt;a href="https://doi.org/10.31234/osf.io/ksnfd">https://doi.org/10.31234/osf.io/ksnfd&lt;/a>&lt;/p>
&lt;p>Victor, S. E., Devendorf, A., Lewis, S., ROTTENBERG, J., Muehlenkamp, J. J., Stage, D. L., &amp;amp; Miller, R. (2021b, July 12). Only human: Mental health difficulties among clinical, counseling, and school psychology faculty and trainees. &lt;a href="https://doi.org/10.31234/osf.io/xbfr6">https://doi.org/10.31234/osf.io/xbfr6&lt;/a>&lt;/p>
&lt;br></description></item><item><title>The PaPOR TRaIL Course</title><link>https://forrt.org/educators-corner/009-papor-trail/</link><pubDate>Mon, 10 Jan 2022 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/009-papor-trail/</guid><description>&lt;br>
&lt;p>Open research is an umbrella term incorporating a range of principles and practices that make research more transparent, reproducible and accessible to everyone in the society. Open and transparent research practices, including research conduct and dissemination of findings, are essential to both those who produce and those who engage with research can access knowledge. Such principles and practices are relevant at all stages of the research cycle and are applicable to all disciplines, though it has been predominantly highlighted in the sciences and medicine. Further, though the principles of open research are consistent across disciplines, open research practices can be implemented differently across disciplines, thereby enhancing the transparency and robustness of research within and across disciplines&lt;/p>
&lt;p>There are benefits of open research for individual researchers, including improved research quality and discoverability, shorter publication embargo periods, and reduced engagement in questionable research practices (QRPs). Open research practices also support the democratisation of scientific knowledge, and enables a greater number of people to engage with research. Training and education in open research principles and practices at early stages of individuals research journey is essential to maximise use of open research practices contributing the aforementioned benefits. Undergraduate and postgraduate students in particular can benefit significantly from training and education in open research at these formative stages. To date, open research educational resources have typically been aimed at PhD students, postdoctoral and more senior researchers, rather than undergraduate and master’s-level students, despite this learning period serving as the foundation to everything that follows.&lt;/p>
&lt;p>The Principles and Practices in Open Research: Teaching, Research, Impact and Learning (PaPOR TRaIL) course was developed to provide a foundation in best scientific practice that benefits students, universities, and research as a whole. Our focus was to develop an open educational resource that would provide a comprehensive introduction to open research, and to help students incorporate open research in their research projects.&lt;/p>
&lt;p>PaPOR TRaIL is a freely available online course that was developed with students and research supervisors and funded by a National Forum for the Enhancement of Teaching and Learning in Higher Education award. Though primarily designed for undergraduate and Masters level students, the course is also applicable for PhD students and researchers looking for an introduction to open research. The course includes text-based materials, visuals, videos, templates, real-world examples, and activities for students to complete.&lt;/p>
&lt;p>The course is comprised of an introductory module that introduces students to what open research is, why it is important, and how to do it. This introductory module can be completed by students as a standalone self-directed module that they complete in their own time. The introductory module is also designed so that it can be used as a Lecture that can be integrated into existing research courses by educators. The introductory module sections are shown below&lt;/p>
&lt;p>&lt;img src="Picture1.jpg" alt="The introductory module sections" width="700" >&lt;/p>
&lt;p>Once students complete the introductory module they can complete any or all of the six practice-based modules that provide a more hands-on approach to _doing _open research Students do not need to complete all six modules, some modules may be more or less relevant to the stage of their research project and they can always come back to do other modules at a later date. When students complete the introductory and all practice modules, they receive a certificate of completion. The six practice-based modules are shown below:&lt;/p>
&lt;p>&lt;img src="Picture2.jpg" alt="The six practice-based modules" width="700" >&lt;/p>
&lt;p>The course is openly available to anyone who is interested, and is open for free enrolment here:
&lt;a href="https://open.ucc.ie/browse/all/cpd/courses/papor-trail-principles-and-practices-of-open-research-003cpd" target="_blank" rel="noopener">PaPOR TRaIL&lt;/a>&lt;/p>
&lt;p>The course also has an open licence (CC BY), which means the course content can be re-used and remixed to suit different educator and institutional/organisation needs, provided attribution is given to the PaPOR TRaIL team.&lt;/p>
&lt;p>To download course content, please enrol at the
&lt;a href="https://open.ucc.ie/browse/all/cpd/courses/papor-trail-principles-and-practices-of-open-research-003cpd" target="_blank" rel="noopener">PaPOR TRaIL&lt;/a> site.&lt;/p>
&lt;p>All course materials will be made available on our OSF page in 2022, following any refinements required in the course based on initial student feedback.&lt;/p>
&lt;p>Details of the course development can be found here:
&lt;a href="https://hrbopenresearch.org/articles/3-84" target="_blank" rel="noopener">https://hrbopenresearch.org/articles/3-84&lt;/a>&lt;/p>
&lt;p>Further information, including our PaPOR TRaIL video, can be found here:
&lt;a href="https://osf.io/863ks/" target="_blank" rel="noopener">https://osf.io/863ks/&lt;/a>&lt;/p>
&lt;br>
&lt;p>&lt;strong>Contact information&lt;/strong>&lt;/p>
&lt;hr>
&lt;p>
&lt;a href="https://open.ucc.ie/browse/all/cpd/courses/papor-trail-principles-and-practices-of-open-research-003cpd" target="_blank" rel="noopener">The PaPOR TRaIL Course&lt;/a>&lt;/p>
&lt;p>
&lt;a href="mailto:karen.msikar@ucc.ie">Dr Karen Matvienko-Sikar&lt;/a>, , School of Public Health, University College Cork, on behalf of the PaPOR TRaIL team.&lt;/p></description></item><item><title>The Open Research Toolkit</title><link>https://forrt.org/educators-corner/008-open-research-toolkit/</link><pubDate>Sat, 13 Nov 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/008-open-research-toolkit/</guid><description>&lt;p>Open research helps increase the visibility of important discoveries and extend them to new places. It also helps to increase participation in research by underrepresented and underfunded groups. The open research ecosystem extends beyond just open access to data and publications. The principles of openness in research should extend to the entire research lifecycle, including education. I have chosen the term ecosystem because open research is an interconnected system. This system consists of philosophies, concepts, principles, practices, tools, and resources which when taken together are intended to make the research process open, transparent, accessible, and reusable by anyone.&lt;/p>
&lt;p>I have been the Data Curation Librarian at
&lt;a href="https://www.lib.utk.edu/" target="_blank" rel="noopener">University of Tennessee, Knoxville, Libraries&lt;/a> since 2013. During this time, I have helped hundreds of researchers meet the requirements of research funders and publishers to make their research data openly accessible. I have taught countless webinars and workshops on data management best practices, FAIR data principles, and open data. While open data is a major pillar of open research, it is only one component of the broad landscape of open research. I felt it would be a disservice to the research community I served if I did not situate my work within the larger context of open research and embrace the principles and practices in my own work. This began my quest to learn more about the open research landscape. To have the focused time to learn and to develop a resource for others, I applied and was approved for faculty development leave to devote one full semester to developing a series of training modules on various topics within open research. They were partly for my own benefit to learn the landscape and partly for the benefit of others who I was sure would be interested in learning more about the topic. The resulting product is the
&lt;a href="https://doi.org/10.17605/OSF.IO/A4FTW" target="_blank" rel="noopener">Open Research Toolkit&lt;/a> (ORT).&lt;/p>
&lt;p>Feedback on the ORT has been positive. My primary goal in creating this was to help librarians skill up on open research principles and practices. The feedback from this audience has been especially positive and grateful. Colleagues have indicated that the ORT’s publication is timely as they are teaching a course on open research or are implementing internal training in their library next semester. I have also heard from domain specialist scientists who have noted it would be helpful as a first introduction to open research concepts for non-academic audiences or early career researchers. My hope for the ORT is that it could be used as a continuing education resource or supplemental materials in courses across a wide range of sciences and social sciences disciplines. To encourage adoption and reuse, I decided to assign it the least restrictive Creative Commons License (CC-By) to all original materials.&lt;/p>
&lt;p>The process of creating the ORT spanned about a year. I initially began reading and collecting resources on myriad open research topics around January of 2021. All resources were added to an EndNote library organized by topic. I then methodically went through these resources and created a list of main topics I wanted to cover. Once my faculty development leave officially began, I actively created the modules on the identified topics. The first step was creating an outline for each module which pulled in content from all the resources gathered. Next, I created PowerPoint slides for each module. Then I created a script for the modules for someone to follow if they wanted to deliver the module. Then I created a narrated YouTube video of the content of each module to which I added subtitles for accessibility. Finally, I created Google Slides of each module and narration files in PDF and Word formats. All these materials are available on the Open Science Framework.&lt;/p>
&lt;blockquote>
&lt;p>Each module contains a slide deck in both PowerPoint and Google Slides, presentation notes in docx and pdf, a narrated video of the slides, and a bibliography of resources related to the topic.&lt;/p>
&lt;/blockquote>
&lt;p>All videos are publicly accessible on
&lt;a href="http://doi.org/10.7290/ORT_Videos" target="_blank" rel="noopener">YouTube&lt;/a>, and the video files are available for download from the
&lt;a href="https://doi.org/10.17605/OSF.IO/A4FTW" target="_blank" rel="noopener">Open Science Framework&lt;/a>. Videos on YouTube contain both English and Spanish subtitles. ORT has been assigned a Creative Commons 4.0 Attribution (
&lt;a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener">CC-By&lt;/a>) license to all original work in the ORT, so anyone can use and adapt however they like with attribution to the author.&lt;/p>
&lt;p>The modules in the Open Research Toolkit currently cover the following topics. Links to each module’s materials are provided.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Module 1: The Open Research Ecosystem [
&lt;a href="https://youtu.be/XnI3HmiJ_TU" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/cmh2r/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/gqwta/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/ahvxd/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 2: Principles &amp;amp; Practices of Open Research [
&lt;a href="https://youtu.be/6eV6YHgvpSk" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/q439h/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/v9g7q/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/qw5mk/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 3: The Philosophical Underpinning of Open Research [
&lt;a href="https://youtu.be/i6_RRYBH7uc" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/2mgkr/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/ak682/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/hp7n5/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 4: Open Access to Published Research [
&lt;a href="https://youtu.be/9UUGv93-hTA" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/vhmnz/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/prenk/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/pektx/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 5: Open Access to Research Data [
&lt;a href="https://youtu.be/LW849Rqf8hg" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/am49n/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/y754z/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/v6jk2/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 6: FAIR Data Principles [
&lt;a href="https://youtu.be/XPhIgL5phFo" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/xchjp/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/szxav/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/9un5c/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 7: Reproducibility of Research [
&lt;a href="https://youtu.be/MyzQSe6KiLs" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/9t8xm/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/xazqr/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/x65dh/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 8: The Five Rs of Open Research [
&lt;a href="https://youtu.be/AcKBNPPNgp0" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/kywpx/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/tcky6/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/84mex/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 9: Open Peer Review [
&lt;a href="https://youtu.be/GHVoVHV1xyk" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/q6bpz/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/68agv/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/tnjk8/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 10: Open Licensing of Data &amp;amp; Software [
&lt;a href="https://youtu.be/_gnIAejr_js" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/52nyk/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/avpme/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/ekygv/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 11: Open Advocacy [
&lt;a href="https://youtu.be/pCxb2wgZZEI" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/p798v/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/5d78q/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/zac8p/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 12: Citizen Science [
&lt;a href="https://youtu.be/kj053ov8Qfg" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/s8z5c/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/z26e3/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/kymwe/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 13: Open Policies [
&lt;a href="https://youtu.be/pw6faLOdTdc" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/zpje3/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/zqc3t/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/27xuv/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Module 14: Open Education Resources [
&lt;a href="https://youtu.be/_BlrPmtM938" target="_blank" rel="noopener">YouTube&lt;/a>,
&lt;a href="https://osf.io/v83rg/" target="_blank" rel="noopener">PowerPoint&lt;/a>,
&lt;a href="https://osf.io/qm82w/" target="_blank" rel="noopener">gSlides&lt;/a>,
&lt;a href="https://osf.io/5pv86/" target="_blank" rel="noopener">Notes&lt;/a>]&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>More resources and additional modules may be added over time. Future resources and modules may include topics such as open research ethics, open source software and collaborative platforms, and creating more detailed curricula for those interested in using the ORT for a course. Please let me know how you use the material so I can track its adoption and use.&lt;/p>
&lt;p>In the spirit of openness, if you have ideas for additions or would like to collaborate on new modules, please contact me (info below).&lt;/p>
&lt;p>All resources in the ORT can be found at the following DOI:
&lt;a href="https://doi.org/10.17605/OSF.IO/A4FTW" target="_blank" rel="noopener">https://doi.org/10.17605/OSF.IO/A4FTW&lt;/a>.&lt;/p>
&lt;p>All videos are on the ORT channel on YouTube at the following DOI:
&lt;a href="http://doi.org/10.7290/ORT_Videos" target="_blank" rel="noopener">http://doi.org/10.7290/ORT_Videos&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Contact information&lt;/strong>:&lt;/p>
&lt;hr>
&lt;p>
&lt;a href="mailto:OpenResearch@utk.edu">Open Research Toolkit&lt;/a>&lt;/p>
&lt;p>
&lt;a href="mailto:ceaker@utk.edu">Christopher Eaker&lt;/a>&lt;/p>
&lt;p>Data Curation Librarian, University of Tennessee Libraries&lt;/p></description></item><item><title>Innovative Mentoring</title><link>https://forrt.org/educators-corner/007-easy-steps-to-elevate-your-mentoring/</link><pubDate>Mon, 13 Sep 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/007-easy-steps-to-elevate-your-mentoring/</guid><description>&lt;p>In academia there are some common ‘good practice’ mentoring things. Many of us do the ‘typical’ activities that good mentors do: weekly group meetings, individual meetings, open door policy, practice presentations, intellectual engagement, iterative writing feedback on theses, grants, and papers, collaborative interactions, and promoting work-life balance. But we can do more –much more– than the basics, without it taking a ton of time. Here are some innovative ways to up your mentoring game.&lt;/p>
&lt;p>Get more out of group meetings. Like many labs, we meet each week. But we rotate what we do, each in approximately equal measure: standard journal article discussion, discussion of a research article on Equity/Diversity/Inclusion (EDI), “Slide Improv”, and Fact or Fiction.&lt;/p>
&lt;p>EDI articles are chosen on a rotating basis by students. They are usually primary research articles. We conscientiously choose papers from diverse areas of EDI. These discussions have been fantastic, and have led to changes in how we do and discuss things. An added benefit is that this is a visible way to show the group that EDI is important to me as their supervisor.&lt;/p>
&lt;p>Slide improv gives experience thinking on the fly. One of the greatest fears students have in presenting is “what if I screw up” or “what if I forget what to say,” and slide improv gives them actual practice in how to respond to, and be more comfortable with, those moments. To do slide improv, a student makes a five-slide presentation (no animations). Another student gives it. The topic is supposed to be on something that isn’t our main research area, but does need to be something in science. They typically are a presentation of the background and results of a single publication. The student who is presenting doesn’t have to be accurate, but what they say has to be believable. Students are nervous doing this the first few times, but over time I’ve seen a marked improvement in confidence and presenting skills.&lt;/p>
&lt;p>Fact or fiction gives experience in critical thinking. A student gives (brief) details and results for three papers. But one of them is completely fabricated. As a group, we try to figure out which is the fake one. This is fun, and seeing the gears turn as people sort things out is great.&lt;/p>
&lt;p>&lt;img src="fig1.png" alt="">&lt;/p>
&lt;p>To get a handle on how my students are doing, and if there are issues in the lab that need addressing, I do an anonymous poll once per year. The poll covers a range of topics on the quality of life, what is working, and what isn’t. This has been VERY HELPFUL in identifying things that need fixing (and some surprises of things that I thought were issues but are fine). I use a variation of this:&lt;/p>
&lt;iframe src="https://docs.google.com/forms/d/e/1FAIpQLScGCi7iACgmVBhFcE7G90oPwuTs-g9CQkrDmOUoQ4FvoT9CfA/viewform?embedded=true" width="100%" height="700px" frameborder="0" marginheight="0" marginwidth="0">Loading...&lt;/iframe>
&lt;p>&lt;br>&lt;br>&lt;/p>
&lt;p>If you would the direct link to the google forms,
&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLScGCi7iACgmVBhFcE7G90oPwuTs-g9CQkrDmOUoQ4FvoT9CfA/viewform" target="_blank" rel="noopener">please follow this link.&lt;/a>&lt;/p>
&lt;p>Over time, I forget which new students I’ve given ‘key advice’ and expectations. So I made a document that I give to all new students. There is a different document for undergraduate Honours Thesis, MSc, and Ph.D. students, since my advice and expectations for those students differ. The document has basic things such as how many weeks ahead to give me drafts and that all students are expected to attend group meetings, and life things like you will work long hours sometimes, but this should be the exception, not the rule.&lt;/p>
&lt;p>Reading papers is important but not urgent, so gets delayed. Every 6 months I require a list of papers the students have read, annotating why they might cite it in their thesis. The expected number of papers is scaled over time. The annotations are really helpful to keep on top of reading, as a searchable document when writing, and for me to see what they are reading. Plus, with a large lab studying diverse topics, this really helps me see some papers I otherwise may miss, too! Every single student I have had make these annotations has said this was incredibly useful when writing their thesis and that they were glad they had done it.&lt;/p>
&lt;p>Lastly, don&amp;rsquo;t be afraid to try out new ways of mentoring, and toss things that don&amp;rsquo;t work. I&amp;rsquo;ve tried a lot of things that just didn&amp;rsquo;t work for my group, or didn&amp;rsquo;t work for &lt;em>this&lt;/em> group. I touch base frequently to see what works and doesn&amp;rsquo;t, and student&amp;rsquo;s like that I ask and it&amp;rsquo;s adaptable.&lt;/p>
&lt;br>
&lt;hr>
&lt;p>&lt;em>Editor&amp;rsquo;s note&lt;/em>: The present text is an adapted version of a widely shared
&lt;a href="https://twitter.com/FlyBehaviour/status/1435285335743864835" target="_blank" rel="noopener">Twitter thread&lt;/a> that resonated with so many of us. We thought it was of general interest and deserved to be memorialized, and hence we approached Amanda to adapt the thread to post it here.&lt;/p></description></item><item><title>Qualitative Open Science Practices</title><link>https://forrt.org/educators-corner/006-qualitative-os-practices/</link><pubDate>Mon, 05 Jul 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/006-qualitative-os-practices/</guid><description>&lt;h3 id="starting-with-qualitative-open-science-practices">Starting with Qualitative Open Science Practices&lt;/h3>
&lt;p>As a person who was trained primarily in research using quantitative methods but needed to do qualitative research to answer the next most pressing question, I was increasingly learning about qualitative research and how to conduct it properly. However, I had not seen much information about how to conduct qualitative research using open science practices. During my PhD, I had been introduced to open science practices as a way to improve educational research, but almost everything I saw did not seem to align with qualitative research. I asked colleagues what existed with regard to open qualitative research resources. Answer: no clue.&lt;/p>
&lt;h3 id="call-to-action">Call to action&lt;/h3>
&lt;p>We thus gathered people interested in qualitative open science research in education at the
&lt;a href="https://www.cos.io/education-reseach-2021-virtual-unconference#:~:text=February%208%2D9%2C%202021&amp;amp;text=The%20unconference%20included%20engaging%20plenary,detailed%20guidance%20for%20education%20researchers" target="_blank" rel="noopener">Virtual Unconference on Open Scholarship Practices in Education Research&lt;/a> sponsored by the
&lt;a href="https://www.cos.io/" target="_blank" rel="noopener">Center for Open Science&lt;/a>. At the conference, we brought other educational researchers and open science fans together to debate what open science qualitative research might look like, put together a list of publicly available publications and tools, and figure out what to do with this information. By the end of a few of these hackathon sessions, we had a list of videos, websites, and publications to help the community understand how to do this work. The full list is located on the
&lt;a href="https://www.oercommons.org/courseware/lesson/80058" target="_blank" rel="noopener">Open Educational Resources website&lt;/a> but will be expanded upon here in this blog. This blog is intended to be a soft entry into this space of qualitative open science research, not a comprehensive journey; take the thoughts below as suggestions &lt;em>if&lt;/em> they align with your philosophy, project, and Institutional Review Board (IRB).&lt;/p>
&lt;h3 id="output">Output&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>We started the resource list with articles that focus on the &lt;strong>basics of open science qualitative research&lt;/strong>. These articles (and Twitter threads) dive into some of the reasons why open science work is important, such as opening the ‘Black box’ of research or helping replication in later studies. And others also touch upon some of the murky issues of doing this work, like the fact that _quant _and _qual _researchers often have different ways of viewing the world and what truth is or can be. This is a good starting point so that you know that there will likely not be consensus on how to do this work well. However, if you read those and still want to try to incorporate open science into your qualitative projects, you can try this in any or all of the following areas: transparency/rigor, open materials, open access, and ethics.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Transparency &amp;amp; Rigor&lt;/strong>. For transparency and rigor in qual research, this revolves around having enough information in your research so that other researchers A) know about the researcher(s) and their positionality and B) could do a similar study in the future, also known as replicating the study. For example, in the
&lt;a href="https://academic.oup.com/view-large/27217733" target="_blank" rel="noopener">COREQ guidelines&lt;/a>, there is an entire domain dedicated to transparency regarding the researchers and their backgrounds (see picture below). Researchers must also describe the context, questions, use of theory, sampling method, interview techniques, and analysis in a way that someone could imagine themselves performing those tasks. One open science practice that qualitative researchers could use to some degree before even conducting the study is preregistration. Essentially it’s like the dissertation proposal where you lay out your plan in advance. Preregistration (and registered reports, the preregistration done with a specific journal with a publication agreement) helps to ensure that a researcher does not change their stated methods after the study is completed. Explaining every detail of the study might be difficult if you are under space constraints (as with publication length requirements), which brings us to #3: open materials.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="Fig1.png" alt="Criteria for Reporting Qualitative Studies" title="Criteria for Reporting Qualitative Studies">&lt;/p>
&lt;ol start="3">
&lt;li>&lt;strong>Open Materials.&lt;/strong> Thanks to the internet, researchers have websites and repositories where they can upload the tools for others to access. In qualitative research, this might mean interview protocols, memos, coding notebooks, tools (such as Nvivo or R packages), or even the data itself. This provides a sort of audit trail so others can verify the results of the research. There is no all or nothing here; open materials, much like the rest of these open science practices, exist along a spectrum. Not only what researchers share is on a spectrum; researchers can also dictate who may access the open materials. Perhaps it’s the entire public, but it could just be people who want to verify findings (i.e., dissertation committees, participants, reviewers). Below you can see how
&lt;a href="https://www.tandfonline.com/doi/pdf/10.1080/08824096.2018.1513273" target="_blank" rel="noopener">Bowman and Keene (2018)&lt;/a> described open science practices as a layered onion with the innermost layer being the most transparent. However, no matter what or to whom materials are shared, researchers must include their plan within their consent procedures and IRB protocols to not violate any ethical boundaries.&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="Fig2.png" alt="Conceptual Onion of Open Science Practices" title="Conceptual Onion of Open Science Practices">&lt;/p>
&lt;ol start="4">
&lt;li>
&lt;p>&lt;strong>Ethics.&lt;/strong> Ethics must be considered with any research, but given the often close relationships with participants, potentially sensitive data revealed, and the fact that large amounts of data could reveal participants’ identity, ethics are huge when it comes to qualitative research. Resources both for abstract and practical purposes can be found in each section of the resources document (i.e., ethics specific to data management) and general ethical considerations are only within this section.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Open Access.&lt;/strong> Finally, researchers can consider how to share their research study. Publishing within traditional academic journals can limit who can read their work, so journals have begun providing open access tiers where researchers can pay the publisher so that the article is available to the public. Alternatively, researchers can “publish” their work online in a preprint server before it is published in a traditional publication outlet. Pre-prints can help researchers get their work out and get community feedback, although certain publications will not accept articles that have been put in a preprint server or require authors to change the pre-print or the settings on it. Open access as an open science practice appears to be generally the same for both quantitative and qualitative work, so fewer resources are here as they can be found on most open science pages.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="contact-us">Contact us&lt;/h3>
&lt;p>Our team who created this (Rachel Renbarger, Sondra Stegenga, Thomas Lösch, Sebastian Karcher, &amp;amp; Crystal Steltenpohl) hopes that you’ll find this helpful for doing this work! We are continuing to explore this area further, so you can reach out to me at rachelrenbarger (at) gmail.com if you are interested in contributing to the conversation.&lt;/p></description></item><item><title>Making lemonade out of remote teaching</title><link>https://forrt.org/educators-corner/005-remote-teaching-platform/</link><pubDate>Mon, 24 May 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/005-remote-teaching-platform/</guid><description>&lt;h2 id="making-lemonade-out-of-remote-teaching">Making lemonade out of remote teaching&lt;/h2>
&lt;p>2020 was a year of big changes for the whole world. For the academic community, it was not different. The need to rapidly switch from in-person to online teaching represented a big challenge for most educators. However, with new challenges come also new and big opportunities. Assistant Professor of Economics at Stockholm University,
&lt;a href="https://haushofer.ne.su.se/" target="_blank" rel="noopener">Johannes Haushofer&lt;/a>, saw in remote teaching the opportunity to open classes to students from low and middle-income countries.&lt;/p>
&lt;p>&lt;em>Remote Student Exchange&lt;/em> was then created as a volunteer and non-profit initiative to match professors willing to offer spots in their classes with interested students from low and middle-income countries. To facilitate the matching process, a
&lt;a href="https://remotestudentexchange.org/" target="_blank" rel="noopener">website&lt;/a> was launched. It has been a great success so far. Two weeks after its launch, there were 1701 students and 88 professors registered and more than 30 courses offered in varied disciplines such as Economics, Business, Psychology, Political Science, Neuroscience, and many others. You can browse the available courses
&lt;a href="https://remotestudentexchange.org/courses?subject_area=10" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>At FORRT, we believe that one of the most overlooked benefits of integrating open and reproducible scholarship into higher education is that of social justice. Academia is still a place of privileges that many cannot afford. We highly commend this initiative and in the hopes of helping it grow even further, we have invited Johannes Haushoffer to explain a bit more how this idea came to be and to share his initial experiences with the community.&lt;/p>
&lt;p>&lt;strong>The Remote Student Exchange in a nutshell&lt;/strong>&lt;/p>
&lt;p>If you are teaching a remote course in the next few months, we highly encourage you to consider taking part in this initiative. Students can sign up free of charge, but they do not receive official grades or credits. This means that this initiative is informal and in most cases, it should not require permission from universities or department chairs.&lt;/p>
&lt;p>To participate, visit the website
&lt;a href="https://remotestudentexchange.org/" target="_blank" rel="noopener">https://remotestudentexchange.org/&lt;/a>. In the home page (see figure below) you can sign up as a professor.&lt;/p>
&lt;p>&lt;img src="Fig1.png" alt="Remote Student Exchange" title="Remote Student Exchange">&lt;/p>
&lt;p>After confirming your email account, you will be able to set up the details of the course you want to offer. As shown in the figure below, you will be asked to indicate the subject area, the level of the course (e.g., bachelor, master, Ph.D. level), and any prerequisites for attending the course (e.g., specific courses and areas of knowledge). You should also provide the link to where the classes take place (e.g., Zoom).&lt;/p>
&lt;p>&lt;img src="Fig2.png" alt="Remote Student Exchange: New Course" title="Remote Student Exchange: New Course">&lt;/p>
&lt;p>Importantly, you are flexible to decide how many students you can host and how they can participate (see the figure below showing the settings for course availability). You can accept students to actively participate with questions, discussions, and assignments, and/or you can accept students to audit silently only. You can also decide to review applications to your course and choose which students to accept or to admit enrolled students on a first-come-first-served basis.&lt;/p>
&lt;p>&lt;img src="Fig3.png" alt="Remote Student Exchange: Availability" title="Remote Student Exchange: Availability">&lt;/p>
&lt;p>Interested students also have to sign up on the website. They will be able to browse the courses being currently offered and apply to take part in a class, provided it still has free spots and that they fulfill the prerequisites (if any).&lt;/p>
&lt;p>If you have more questions, make sure to access the
&lt;a href="https://remotestudentexchange.org/help" target="_blank" rel="noopener">FAQ&lt;/a> and watch the video below where Johannes explains a bit more about this initiative. We hope that many more scholars consider joining it. Share this idea widely with other educators and with students that may be interested. You can find a link to the countries contemplated by this initiative
&lt;a href="https://data.worldbank.org/?locations=XM-XP" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;br>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/5kyjnPFSmog" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;br>
&lt;center>
&lt;p>
&lt;a href="https://www.youtube.com/watch?v=5kyjnPFSmog" target="_blank" rel="noopener">Video Interview Direct Link to YouTube&lt;/a>&lt;/p>
&lt;/center></description></item><item><title>Teaching the why and how of replication studies</title><link>https://forrt.org/educators-corner/004-teaching-why-how-replication/</link><pubDate>Tue, 04 May 2021 01:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/004-teaching-why-how-replication/</guid><description>&lt;p>Psychological science is in the midst of a “credibility crisis” in which its practitioners re-examine their practices and re-define what constitutes study rigor. Replication studies have formed a critical role in motivating this sense of crisis – a sense of crisis that has led directly to the current movement to improve psychological science through a “credibility revolution”.&lt;/p>
&lt;p>Despite this important role, when I was invited to hold a virtual two-day, 10-hour workshop on replication studies for the students and faculty of the Department of Social and Organizational Psychology at ISCTE in Lisbon, I realized that I did not have any ready-made teaching materials on this important topic. This blog shares the guiding principles of the workshop and my finished materials so that you, the reader, can learn from my experiences.&lt;/p>
&lt;p>My workshop materials, including a &lt;strong>syllabus&lt;/strong>, &lt;strong>suggested readings&lt;/strong>, and &lt;strong>exercises&lt;/strong>, are freely available at
&lt;a href="https://osf.io/m9bzh/" target="_blank" rel="noopener">https://osf.io/m9bzh/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Workshop overview&lt;/strong>&lt;/p>
&lt;p>My workshop describes the &lt;em>why&lt;/em> and &lt;em>how&lt;/em> of replication studies: &lt;em>why&lt;/em> a researcher might want to conduct a replication study and &lt;em>how&lt;/em> a researcher should go about conducting a replication study. It also emphasizes some issues that are often neglected in discussions of replication studies, at least in my experience, including the importance of choosing good replication targets, the importance of resource constraints in doing good sample size planning, and the use of simulation studies in sample size planning.&lt;/p>
&lt;p>The workshop proceeded in four modules, as shown in this workshop slide:&lt;/p>
&lt;p>&lt;img src="fig1.png" alt="Workshop Organization" title="Workshop Organization">&lt;/p>
&lt;p>Each module is structured around one or two learning goals, or big-picture takeaway points that I wanted the students to understand at the end of the module. Each module also breaks up lecture sections with independent or guided exercises. The exercises are intended to both reinforce the content of the lecture and give the students hands-on experience with a broad swathe of the skills that go into replication research.&lt;/p>
&lt;p>The remaining sections of the blog will describe the content of each module, how this content reinforces the module’s learning goals, and the exercises I used for each module.&lt;/p>
&lt;p>&lt;strong>Module 1: The credibility crisis&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals:&lt;/em> &lt;em>The credibility crisis revealed weaknesses in research; these weaknesses are caused by hidden processes that don’t show up in published reports&lt;/em>&lt;/p>
&lt;p>This module is framed around a schematic version of how empirical psychological science works (adapted from
&lt;a href="https://www.nature.com/articles/s41562-016-0021" target="_blank" rel="noopener">Munafo et al., 2017&lt;/a>).&lt;/p>
&lt;p>&lt;img src="fig2.png" alt="Sometimes your hypothesis will be wrong, Figuring out why helps our theories improve." title="Sometimes your hypothesis will be wrong, Figuring out why helps our theories improve.">&lt;/p>
&lt;p>In the schematic, you generate a hypothesis from theory, design a study to test the hypothesis, collect data based on the study design, analyze the data to test the hypothesis, interpret the results, publish the data, and begin the cycle anew. By using this process to compare discrepancies between your hypothesis and the data, you can identify flaws in your theoretical assumptions, which allows you to revise the theories and improve them.&lt;/p>
&lt;p>However, a variety of events made psychologists aware that something about this cycle wasn’t working. First was the observation that only about 8% of the results published in psychology journals are negative (
&lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0010068" target="_blank" rel="noopener">Fanelli, 2010&lt;/a>) – yet these negative results are necessary to identify flaws in theoretical assumptions. Second was the publication of a paper by the well-respected social psychologist Daryl Bem, who, in 2011, published a somewhat unusual paper in the world’s top journal for social psychology, the &lt;em>Journal of Personality and Social Psychology&lt;/em> (
&lt;a href="https://psycnet.apa.org/record/2011-01894-001" target="_blank" rel="noopener">Bem, 2011&lt;/a>). This paper used methods that met or exceeded the standards of rigor that were typical for the time, but advanced a claim that was patently absurd: that college students (and, by extension, everyday people) could be influenced by future events.&lt;/p>
&lt;p>&lt;img src="fig3.png" alt="Daryl&amp;rsquo;s Bem &amp;ldquo;Feeling the Future&amp;rdquo;" title="Daryl's Bem Feeling the Future">&lt;/p>
&lt;p>This paper suggested either that everything we knew about physics was wrong or (perhaps more likely) that the research methods in social psychology that we used to think were rigorous were somehow flawed.&lt;/p>
&lt;p>I then describe how these observations spurred a &lt;em>credibility crisis&lt;/em> (not a “replication crisis”, as the crisis is broader than just a lack of replicability) in which researchers investigated whether and how research methods in social psychology are flawed. I use two exercises to illustrate some of the problems.&lt;/p>
&lt;p>In
&lt;a href="https://osf.io/58hdp/" target="_blank" rel="noopener">the first&lt;/a>, the students use a
&lt;a href="https://jeanmoneger.shinyapps.io/SizeMatters/" target="_blank" rel="noopener">free shiny app&lt;/a> to simulate how the combination of the selective publication of positive results and low statistical precision create huge distortions in our understanding of the evidence supporting a particular psychological theory. This exercise demonstrates the concepts of statistical power, precision, and publication bias and demonstrates the general method of using simulation studies to understand what happens when some quantity (in the context of a simulation, a &lt;em>parameter&lt;/em>) varies.&lt;/p>
&lt;p>In
&lt;a href="https://osf.io/y3467/" target="_blank" rel="noopener">the second&lt;/a>, the students use FiveThirtyEight’s
&lt;a href="https://projects.fivethirtyeight.com/p-hacking/" target="_blank" rel="noopener">p-hacking app&lt;/a> to illustrate what makes p-hacking possible. I randomly assigned students to either the Republican party or the Democratic party and to either make their assigned party look good or bad. This exercise illustrates how p-hacking can emerge from the combination of flexible definitions / measurement and a desire to obtain a certain result.&lt;/p>
&lt;p>I close the module by describing how published research reports only constitute a subset of what goes into creating a certain research funding and how processes like p-hacking and publication bias, while hidden, can undermine a finding’s credibility. Thus, one way we can uncover the credibility of a finding is to make visible more aspects of the research process. The next module describes one way to achieve this greater level of visibility.&lt;/p>
&lt;p>&lt;img src="fig4.png" alt="What we see and what we don&amp;rsquo;t see" title="What we see and what we don't see">&lt;/p>
&lt;p>&lt;strong>Module 2: Replications as a way of highlighting what is known&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals:&lt;/em> &lt;em>Close replications test the credibility of a finding. They work best with good documentation &amp;amp; structured ways of choosing replication targets&lt;/em>&lt;/p>
&lt;p>This module starts with the question of how to determine whether a particular finding is “credible”. One way is to fix in place the &lt;em>hypothesis&lt;/em> and try to do the study again. When you do the next study, you can either vary certain aspects of the method or duplicate the past method as carefully as possible. Although I don’t yet introduce this terminology, these two sets of scenarios illustrate the ideas behind a &lt;em>close replication&lt;/em> and a &lt;em>distant replication&lt;/em>.&lt;/p>
&lt;p>I then ask the students to complete
&lt;a href="https://osf.io/n243q/" target="_blank" rel="noopener">an exercise&lt;/a> to think about the conclusions that are reasonable in close and distant replications. The goal of this exercise is to illustrate how close replications (where you keep the method similar) are particularly informative when they give you results that differ from a set of past results because they call into question the credibility of the original results. However, they are less informative when you get results that are similar to the original.&lt;/p>
&lt;p>In contrast, distant replications (where you vary some aspect of the method) are particularly informative when you get results similar to the original results because they allow you to generalize across the methodological feature that you varied. However, they are less informative when you get results that differ from the original because, in addition to all the explanations that apply when you do a close replication, the features that you intentionally varied could also have produced the different results.&lt;/p>
&lt;p>&lt;img src="fig5.png" alt="Close vs Distant Replication" title="Close vs Distant Replication">&lt;/p>
&lt;p>I also use this exercise to highlight the importance of minimizing sampling error and fully documenting procedures; both sampling error and undocumented differences in procedure (“hidden moderators”) provide possible explanations for why replication results differ from original results. This highlights a somewhat hidden side benefit of replications: they force you to very carefully document a particular procedure.&lt;/p>
&lt;p>To illustrate how to document the procedure behind a replication study, I introduce the students to the “replication recipe” (
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0022103113001819" target="_blank" rel="noopener">Brandt et al., 2014&lt;/a>). The replication recipe provides a structured set of questions to guide the process of creating a method section for a replication study. As
&lt;a href="https://osf.io/j3pna/" target="_blank" rel="noopener">an exercise&lt;/a>, I ask students to fill out the first section of the replication recipe with an article that I assign (I pre-selected two articles that are short and have a relatively simple research design). After the exercise, we discuss the process of using the replication recipe and identify issues that came up – including the poor reporting standards of most (but not all) psychology articles.&lt;/p>
&lt;p>In the last part of this module, we discuss a way to choose replication targets. I teach a somewhat informal version of a framework developed by
&lt;a href="https://osf.io/preprints/metaarxiv/2gurz/" target="_blank" rel="noopener">Isager and colleagues (2020)&lt;/a>. As
&lt;a href="https://osf.io/zjwcg/" target="_blank" rel="noopener">an exercise&lt;/a>, the students use the framework to rate the value, uncertainty, and cost of doing the replication study that I assigned them.&lt;/p>
&lt;p>&lt;img src="fig6.png" alt="Choosing an effect to replicate" title="Choosing an effect to replicate">&lt;/p>
&lt;p>&lt;strong>Module 3: Resource planning and piloting&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals: Resources are critical for making your replication precise; you should think through the sample your resources allow &amp;amp; use those to calculate your power&lt;/em>&lt;/p>
&lt;p>This module subsumes most of the content that would normally be taught as “power analysis”. The reason I frame power analysis as “resource planning” is to emphasize the critical, and often unrecognized, role that resources (time, money, skills) play in the number of observations a replication study achieves. I teach two workflows for planning resources: a &lt;strong>resource-first workflow&lt;/strong> based on identifying the practical constraints to one’s resources and determining the power those constraints allow to detect different effect sizes, and &lt;strong>smallest-effect-size-of-interest workflow&lt;/strong> based on identifying a smallest effect size of interest and the number of observations (i.e., resources) required to achieve different levels of power to detect that effect.&lt;/p>
&lt;p>&lt;img src="fig7.png" alt="We Live in a Resource-Constrained World" title="We Live in a Resource-Constrained World">&lt;/p>
&lt;p>The module relies heavily on &lt;em>
&lt;a href="https://debruine.github.io/faux/" target="_blank" rel="noopener">faux&lt;/a>&lt;/em>, an R package for simulating fake data that fits a specific set of constraints. I link the idea of simulation studies back to the first module and tell the students that I am giving them a powerful set of tools to conduct their own simulation studies. I do not assume that students know how to use R, but rather wrote two different scripts that make simulating
&lt;a href="https://osf.io/x7upv/" target="_blank" rel="noopener">two-group&lt;/a> and
&lt;a href="https://osf.io/wdqem/" target="_blank" rel="noopener">four-group&lt;/a> designs easy, even for a complete R novice. My goal is to give the students some tools to do basic tasks in R, as well as resources to learn more about simulations in R if they have the time and interest.&lt;/p>
&lt;p>A hidden goal of this module is to demonstrate how under-resourced most past research really is. For example, when I illustrate the resource-first workflow, I assume that we have enough resources to achieve 80 observations per cell in a two-group design – a number of resources that meets or exceeds the sample sizes used during the 2000s in social psychology (
&lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0109019" target="_blank" rel="noopener">Fraley &amp;amp; Vazire, 2014&lt;/a>). This design yields abysmal power to detect most reasonably-sized effects.&lt;/p>
&lt;p>&lt;img src="fig8.png" alt="SESOI smallest-effect-size-of-interest workflow" title="SESOI smallest-effect-size-of-interest workflow">&lt;/p>
&lt;p>As another example, when I illustrate the smallest-effect-size-of-interest workflow, I assume that the target effect is part of an interaction. Interactions require about
&lt;a href="https://statmodeling.stat.columbia.edu/2018/03/15/need-16-times-sample-size-estimate-interaction-estimate-main-effect/" target="_blank" rel="noopener">16 times&lt;/a> the sample size to detect than main effects, a fact that is illustrated vividly in the simulation-based power curve from this part of the module.&lt;/p>
&lt;p>&lt;img src="fig9.png" alt="Notes" title="Notes">&lt;/p>
&lt;p>One last issue that comes out of the simulations is the number of assumptions that one must make in the process of doing a simulation study. This includes both statistical assumptions, such as the size of the standard deviation of the outcome measure, and non-statistical assumptions, such as the length of time it takes for a typical participate in the study (a fact that is necessary to accurately estimate the number of participants who can participate in a lab-based study, for example). I argue that pilot studies are useful for developing good values for these assumptions. Pilot studies are &lt;em>not&lt;/em> useful for directly estimating the value of the target effect size itself (
&lt;a href="https://www.sciencedirect.com/science/article/pii/S002210311630230X?casa_token=OETt_Sm5VFEAAAAA:-9rK8QScds9e0A1siznusvdtvl0-yC2WpBVWe7ztdGkZ8eVILbyqWMC5WmcsAxHWp6X7X7voPeA" target="_blank" rel="noopener">Albers &amp;amp; Lakens, 2018&lt;/a>); in any case it is better to power to a smallest effect size of interest than the expected effect size.&lt;/p>
&lt;p>&lt;img src="fig10.png" alt="Workflow 2" title="Workflow 2">&lt;/p>
&lt;p>&lt;strong>Module 4: Preregistration&lt;/strong>&lt;/p>
&lt;p>&lt;em>Learning goals: To preregister something, create an OSF project &amp;amp; put the replication recipe in the registry. There’s evidence this helps make research more credible&lt;/em>&lt;/p>
&lt;p>The bulk of this module is focused around completing a pre-registration for the article assigned to the students in the previous modules. Because the workshop participants have already completed the first part of the replication recipe (
&lt;a href="https://www.sciencedirect.com/science/article/pii/S0022103113001819" target="_blank" rel="noopener">Brandt et al., 2014&lt;/a>) for this article, they are already familiar with the article’s purpose and materials. For the first part of this module, the students complete the remainder of the replication recipe (or at least, as much as they can) as part of
&lt;a href="https://osf.io/w35fp/" target="_blank" rel="noopener">the last exercise&lt;/a> of the workshop.&lt;/p>
&lt;p>The replication recipe in hand, the students can complete a replication recipe-based preregistration on the Open Science Framework (
&lt;a href="https://osf.io" target="_blank" rel="noopener">OSF&lt;/a>). I walk the students through this process and introduce them to the basics of uploading materials on an OSF page. But the students already completed hard parts of preregistration as part of the previous exercises.&lt;/p>
&lt;p>&lt;img src="fig11.png" alt="Preregistration on the Open Science Framework" title="Preregistration on the Open Science Framework">&lt;/p>
&lt;p>I spend the remainder of this module reviewing evidence of what a well-planned and well-executed preregistration can do for the credibility of research.&lt;/p>
&lt;p>&lt;img src="fig12.png" alt="Preregistration can help on a wide variety of research problems." title="Preregistration can help on a wide variety of research problems.">&lt;/p>
&lt;p>I also briefly cover Registered Reports, which circumvent publication bias through a staged review process. At stage 1, a proposal is reviewed prior to any data collection. At stage 2, the proposal is reviewed again, and as long as the researcher executes their accepted study protocol, published regardless of results. I give the students a
&lt;a href="https://www.cos.io/initiatives/registered-reports" target="_blank" rel="noopener">list of journals&lt;/a> that accepts registered reports if they’re interested in conducting a study with this publication format.&lt;/p>
&lt;p>&lt;img src="fig13.png" alt="Registered Reports" title="Registered Reports">&lt;/p>
&lt;p>&lt;strong>Conclusion: Use my materials!&lt;/strong>&lt;/p>
&lt;p>Replications have played a critical, though I think sometimes misunderstood, role in spurring the credibility revolution: they are one way of investigating the credibility of a particular research finding. The primary way they do this, I think, is by serving as a tool to highlight previously unknown pieces of information, either during the process of documenting the procedure (so it can be successfully executed) or via the results themselves. This role deserves to be underscored in teaching materials. I also think replications can be a useful venue to highlight other parts of the research process, such as decisions about what to research and resource planning. The structure of my finished workshop reflects this general outlook.&lt;/p>
&lt;p>If you find my materials useful, please use them! The materials are freely available in
&lt;a href="https://osf.io/m9bzh/" target="_blank" rel="noopener">this repository&lt;/a>. Let’s use our teaching to pass the lessons of the credibility revolution on to the next generation of behavioral scientists.&lt;/p></description></item><item><title>Developing a comprehensive directory of tools and technologies for social science research methods</title><link>https://forrt.org/educators-corner/003-developing-tools/</link><pubDate>Mon, 04 Jan 2021 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/003-developing-tools/</guid><description>&lt;h2 id="developing-a-comprehensive-directory-of-tools-and-technologies-for-social-science-research-methods">Developing a comprehensive directory of tools and technologies for social science research methods&lt;/h2>
&lt;p>Often the search and exploration of tools and technologies in social science research is not part of the class curriculum in the same way as the systematic review of literature is. This, sadly, leaves the becoming researcher in a place of disadvantage, in my opinion. In their early research career, students will mostly rely on their supervisor or peers to advise on the tools they use, which is still a very limited sample. However, with strides in technological development, researchers could choose from a growing number of multivariate tools for social science methods rising from within the discipline itself, as well as borrowed from other disciplines or coming from the commercial sector.&lt;/p>
&lt;p>Starting from this premise, we decided to build a
&lt;a href="https://ocean.sagepub.com/research-tools-directory#categories" target="_blank" rel="noopener">tools directory&lt;/a> for social scientists, a simple solution for a place where any researcher or student can come and find the right tool for what they need. In this piece, I explain how the tools directory was developed and how it can be used by educators, researchers and students.&lt;/p>
&lt;h3 id="developing-the-tools-directory">Developing the tools directory&lt;/h3>
&lt;p>The initial list was based on software tools and tech platforms that we knew were popular among social science researchers because we’ve commissioned books about them, or they have been prominent within the community. We continued to ask academics, look through papers and other lists like the
&lt;a href="http://dirtdirectory.org/" target="_blank" rel="noopener">DiRT Directory&lt;/a> from the Digital Humanities, the
&lt;a href="https://wiki.digitalmethods.net/Dmi/ToolDatabase" target="_blank" rel="noopener">Digital Methods Initiative&lt;/a> and
&lt;a href="https://sourceforge.net/" target="_blank" rel="noopener">SourceForge&lt;/a>. Soon enough, the directory was growing out of control. What we thought would be a simple scroll down page, organised in a few basic categories, was not serving its purpose any longer.&lt;/p>
&lt;p>With around three hundred different software packages and tools that we knew were used by some or many social science researchers in their work, a new challenge was becoming apparent. It was a paradox-of-choice situation. On one hand, it was increasingly clear why academics often rely solely on recommendations from their peers when choosing a tool. And on the other hand, we knew we needed to explore how one would choose the right tool from a list, and ultimately how to teach others to find the tool that fits their own purposes rather than simply recommending a tool they’ve used.&lt;/p>
&lt;p>As the list grew, we enlisted the help of a few master students, and started collecting more data: who built these tools, were they free or paid, what cluster of similar tools would they belong to, when were they built, based on the information available could we tell whether they were up to date, scaling, or failed, could we find papers that cited these tools, were the creators recommending a citation etc.&lt;/p>
&lt;p>When we hit 400 software packages/tools, we knew we had to promote this list and share it in a way that researchers would actually stumble upon it and have the opportunity to reference it in a lecture or paper. So we wrote a
&lt;a href="https://uk.sagepub.com/en-gb/eur/technologies-for-social-science-research" target="_blank" rel="noopener">whitepaper summarizing the big trends on the development of tools and tech for social science research&lt;/a>. We learned that both commercial and non-commercial tools are popular within the social sciences, but the ones that last longer and are more successful focus beyond the discipline and almost always have a person or teams of people dedicated to raising funds or expanding the community of users and contributors.&lt;/p>
&lt;p>At 400 software packages/tools, we were still not sure the list was big enough. We then focused on specific methods and researched all the tools available to carry out that method or task within the research process. We looked at the evolution of technologies for that method in particular, as well as how it fits within the development of the method itself. We call these ‘deep dives’. We’ve done deep dives on tools for annotation, or tools for transcription, surveying tools, tools for studying social media data, and we kept finding more software applications within each of these areas. We concluded these deep dives to be quite useful, as they enabled sharing slightly more comprehensive sub-lists of tools that could be used in different modules. We have now 543 tools on the list, and the number keeps growing.&lt;/p>
&lt;h3 id="how-to-use-the-tools-directory">How to use the tools directory&lt;/h3>
&lt;p>The full directory is currently available on our
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/" target="_blank" rel="noopener">GitHub repository&lt;/a> as a csv file. We decided to host it on GitHub, in order to be able to update the directory when we come across new tools or after deep dives; ensure it’s always available for others to reuse in its most up-to-date form, and enable instructors, students and researchers to add tools that might be missing.&lt;/p>
&lt;p>Educators teaching research methods or preparatory courses for students’ theses could present the full tools directory to students, so they are more flexible in finding the right tools for their needs and future projects.Students can browse through the list and filter for tools to find a tool that is most appropriate for a research project they are initiating. For example, a student transcribing interviews might look at the transcription tools to find alternatives. Similarly, educators that are teaching a more specialized course, such as introduction to text mining, data visualization, or social data mining, or running online experiments could filter out a sub-list of tools focusing on the explicit method. They could then share this sub-list as part of the course reference materials or assignments.&lt;/p>
&lt;p>&lt;img src="featured.png" alt="Fig. 1. The spread of 543 tools and technologies across methods and techniques." title="Fig. 1. The spread of 543 tools and technologies across methods and techniques.">&lt;figcaption>Fig. 1. The spread of 543 tools and technologies across methods and techniques.&lt;/figcaption>&lt;/p>
&lt;p>&lt;img src="fig2.png" alt="Fig. 2. Filtering to find transcription tools. A student or instructor could filter by column F (the Competitive cluster which contains the method/technique/task/area that we used to categorize the tool) to get a sub-list of tools that could be broadly used for a particular process. If the cluster is too broad, the student can look through the technique (column E), that breaks it down further. For example for social media tools, the technique would include analysis, collection, visualisation etc. If looking for more recent tools, one can filter by the year the tool was launched (column M); or if the student is interested in something that is free, they can check the charges (column N)." title="Fig. 2. The spread of 543 tools and technologies across methods and techniques.">&lt;figcaption>Fig. 2. Filtering to find transcription tools. A student or instructor could filter by column F (the Competitive cluster which contains the method/technique/task/area that we used to categorize the tool) to get a sub-list of tools that could be broadly used for a particular process. If the cluster is too broad, the student can look through the technique (column E), that breaks it down further. For example for social media tools, the technique would include analysis, collection, visualisation etc. If looking for more recent tools, one can filter by the year the tool was launched (column M); or if the student is interested in something that is free, they can check the charges (column N).&lt;/figcaption>&lt;/p>
&lt;p>While the csv file that contains the tools directory might be easy to update and share, we acknowledge that it might not be that easy to use within a classroom. We are experimenting with a variety of ways that would enable a better display and navigation of the directory, without losing from the ease of updating it.&lt;/p>
&lt;p>In 2019 we did our first deep dive into the tools for social data science to support our
&lt;a href="https://campus.sagepub.com/collecting-social-media-data" target="_blank" rel="noopener">SAGE Campus course on collecting social media data&lt;/a>. We created a sublist to share for this course to help learners find the software that might be most appropriate for their own project, especially given the variety of social media platforms available. To render
&lt;a href="https://airtable.com/shrux4hYwNG1cOyjK/tbl9NiGq87agePZ2M?backgroundColor=cyan&amp;amp;viewControls=on" target="_blank" rel="noopener">the sub-list&lt;/a> in a more friendly way, we used the free version of airtable, which is a no-code app for relational databases with a colorful and modern interface. Students would navigate to this page (Fig 3) to see the sub-list on a single table. They can then find the right tool for their social media project by selecting the platform they want to collect their data from (twitter, instagram, facebook etc), whether they are happy to pay or looking for something that’s free, and the type of task they want to perform: whether they need the tool for collecting the data, analysis, or visualization. Once they have a filtered list, they can also look through the academic papers we’ve linked where each tool has been used, to explore further the potential of the tools.&lt;/p>
&lt;p>&lt;img src="fig3.png" alt="Fig. 3. Screenshot of the sub-list containing social media tools via the free version of airtable. Similar to working with a csv file (as in Fig. 2), this interface lets the student filter the list down to narrow the choices for a tool they could use to either collect or analyse their data. This interface is web-based, and has a more inviting user experience than working with a csv file. A student can easily see the categories of tools, filter by multiple terms or concepts linked within each of the columns." title="Fig. 3. Screenshot of the sub-list containing social media tools via the free version of airtable. Similar to working with a csv file (as in Fig. 2), this interface lets the student filter the list down to narrow the choices for a tool they could use to either collect or analyse their data. This interface is web-based, and has a more inviting user experience than working with a csv file. A student can easily see the categories of tools, filter by multiple terms or concepts linked within each of the columns.">&lt;figcaption>Fig. 3. Screenshot of the sub-list containing social media tools via the free version of airtable. Similar to working with a csv file (as in Fig. 2), this interface lets the student filter the list down to narrow the choices for a tool they could use to either collect or analyse their data. This interface is web-based, and has a more inviting user experience than working with a csv file. A student can easily see the categories of tools, filter by multiple terms or concepts linked within each of the columns.&lt;/figcaption>&lt;/p>
&lt;p>We envision this sub-list of social media tools to be a starting point, as it helps the learner filter down based on a limited number of criteria, such as: the task that can be achieved (collection, analysis), the social media platform that’s integrated, and the fees.&lt;/p>
&lt;p>We’ve reused the same
&lt;a href="https://socialmediatools.pory.app/" target="_blank" rel="noopener">sub-list of social media tools with a different interface&lt;/a> (pory.io, currently in beta) to render this list of tools more akin to a catalogue of records, that the student can search and filter. This rendering was used in a bootcamp on starting off with social media research. Similar to the airtable rendering, a student could filter based on the task they want to achieve and then click into the tool to get more information and explore which one would work better.&lt;/p>
&lt;p>&lt;img src="fig4.png" alt="Fig. 4: Screenshot of the sub-list of social media tools rendered into a catalogue via the pory.io app. The user experience on this interface is friendlier than working with a table as in Fig. 2 &amp; 3. A student can filter the list by the type of tool, which is immediately visible; for example they might be looking for tools to support their data collection. They can then use the search box to enter key terms and narrow down the list further, a process that is more familiar. The student can also browse the list of tools by opening the individual cards to find more information (see next figure)." title="Fig. 4: Screenshot of the [sub-list of social media tools](https://socialmediatools.pory.app/) rendered into a catalogue via the pory.io app. The user experience on this interface is friendlier than working with a table as in Fig. 2 &amp;amp; 3. A student can filter the list by the type of tool, which is immediately visible; for example they might be looking for tools to support their data collection. They can then use the search box to enter key terms and narrow down the list further, a process that is more familiar. The student can also browse the list of tools by opening the individual cards to find more information (see next figure).">&lt;figcaption>Fig. 4: Screenshot of the
&lt;a href="https://socialmediatools.pory.app/" target="_blank" rel="noopener">sub-list of social media tools&lt;/a> rendered into a catalogue via the pory.io app. The user experience on this interface is friendlier than working with a table as in Fig. 2 &amp;amp; 3. A student can filter the list by the type of tool, which is immediately visible; for example they might be looking for tools to support their data collection. They can then use the search box to enter key terms and narrow down the list further, a process that is more familiar. The student can also browse the list of tools by opening the individual cards to find more information (see next figure).&lt;/figcaption>&lt;/p>
&lt;p>&lt;img src="fig5.png" alt="Fig. 5. Fig. 5: Once the student filters a list of tools, they can click one each card to get further information about each tool. Currently this includes a brief description, the platform supported, whether it’s free or not, and several academic papers that have used this tool." title="Fig. 5: Once the student filters a list of tools, they can click one each card to get further information about each tool. Currently this includes a brief description, the platform supported, whether it’s free or not, and several academic papers that have used this tool.">&lt;figcaption>Fig. 5: Once the student filters a list of tools, they can click one each card to get further information about each tool. Currently this includes a brief description, the platform supported, whether it’s free or not, and several academic papers that have used this tool.&lt;/figcaption>&lt;/p>
&lt;p>Airtable and pory.io have different affordances for rendering the sub-lists of tools, and our experience so far is that both have been useful. We are hoping to learn more from these experiments, to understand the student’s journey as well as the data that would inform their exploration process.&lt;/p>
&lt;p>The social media tools sub-list was part of a deep dive that we carried out in 2019. Since then, we dived into
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/2019/11/11/surveying-tools.html" target="_blank" rel="noopener">surveying tools&lt;/a> and
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/2020/01/20/text-mining.html" target="_blank" rel="noopener">text mining&lt;/a>. We have not created separate sub-lists for these, and encourage instructors to try other ways of representing these tools within their courses. If you are teaching text mining in the social sciences, for example, you can point your students to this
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/2020/01/20/text-mining.html" target="_blank" rel="noopener">overview of the text mining tools available&lt;/a> (Fig. 6 &amp;amp; Fig. 7) and share a sub-list of the tools directory filtered for text mining with your students.&lt;/p>
&lt;p>&lt;img src="fig6.png" alt="Fig. 6: Screenshot of the Text Mining section, an overview of tools available." title="Fig. 6: Screenshot of the Text Mining section, an overview of tools available.">&lt;figcaption>Fig. 6: Screenshot of the Text Mining section, an overview of tools available.&lt;/figcaption>&lt;/p>
&lt;p>&lt;img src="fig7.png" alt="Fig. 7: Text mining tools and technologies based on the process they support." title="Fig. 7: Text mining tools and technologies based on the process they support.">&lt;figcaption>Fig. 7: Text mining tools and technologies based on the process they support.&lt;/figcaption>&lt;/p>
&lt;h3 id="going-forward">Going forward&lt;/h3>
&lt;p>Going forward, we are quite interested in finding out what are the criteria people often use to filter down to their top tools, so we can build this list forward and continuously add the data that helps academics and students find the tools that fit their project best.&lt;/p>
&lt;p>We understand that lists follow some form of a hype cycle, where there is a lot of work done at the start and some engagement from the community, and then the whole project slowly dies and it is forgotten. It becomes pretty unusable, because with the pace of research and technology, a lot of the tools are out of date and many new ones have popped up. A person must be dedicated to updating the list and for now we have that covered. Since the publication of the whitepaper in November 2019, we’ve added at least 100 more tools, mostly focusing on text and data mining. While it’s relatively easy to come across new tools, the hardest bit is updating the ones that are already on the list, and that’s where we are open for suggestions from the community. The list with updates to the whitepaper are available in this
&lt;a href="https://sagepublishing.github.io/sage_tools_social_science/" target="_blank" rel="noopener">GitHub repository&lt;/a>.&lt;/p>
&lt;p>Finally, the &lt;em>locus&lt;/em> of software tools and technologies within the research ecosystem remains a big challenge. Software tools are yet to gain the credit of research output. And that is why, among other reasons, software tools are rarely cited or referenced in papers. This is not only bad for
&lt;a href="https://www.slideshare.net/danielskatz/citation-and-reproducibility-in-software" target="_blank" rel="noopener">reproducibility of research, but it also makes it difficult to help other researchers weigh in and compare different tools&lt;/a> used for similar studies. We aim to promote and include the suggested citation of the tools in our list, and strongly encourage anyone to use
&lt;a href="https://citeas.org" target="_blank" rel="noopener">https://citeas.org&lt;/a> when unsure how to give credit to these.&lt;/p>
&lt;p>We remain active and are continuously thinking of better ways to present and re-architecture the information about software tools and technologies we’ve gathered, to make it easier to navigate and explore. We hope these materials will help you and your students become more aware of the diversity of tools and technologies and will open new and potentially easier avenues to decide on the best software tool to use for your research.&lt;/p></description></item><item><title>Using the 'Transparency Checklist Guidelines' as an Educational tool</title><link>https://forrt.org/educators-corner/002-transparencychecklist-balazsaczel/</link><pubDate>Sun, 04 Oct 2020 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/002-transparencychecklist-balazsaczel/</guid><description>&lt;h1 id="transparency-checklist-guideline-for-education">Transparency Checklist Guideline for Education&lt;/h1>
&lt;h2 id="what-is-it-for">What is it for?&lt;/h2>
&lt;p>As an educational tool, the Checklist can be used to teach and improve the standards of transparency and credibility in research reports made by students. The aim is that students are embedded in transparent and open practices from the beginning of their training.&lt;/p>
&lt;p>
&lt;a href="https://docs.google.com/spreadsheets/d/1NxJG5ccRAhvLKngosRVjT8IO2OZ0UDZMN86FW5qGf0Q/edit?usp=sharing" target="_blank" rel="noopener">See here for an adapted version of the original checklist for educational purposes.&lt;/a>&lt;/p>
&lt;p>&lt;img src="Checklist_v2.png" alt="">&lt;/p>
&lt;h2 id="how-to-use-it">How to use it?&lt;/h2>
&lt;p>Supervisors and instructors can require students to create a Transparency Report along with any empirical research assignment.&lt;/p>
&lt;h3 id="steps-to-follow">Steps to follow&lt;/h3>
&lt;ul>
&lt;li>Inform the students about the Transparency Checklist.&lt;/li>
&lt;li>Add the completion of the checklist to the requirements.&lt;/li>
&lt;li>
&lt;a href="http://www.shinyapps.org/apps/TransparencyChecklist/" target="_blank" rel="noopener">Make the checklist app available to students&lt;/a>&lt;/li>
&lt;li>Be ready to answer questions if the students are uncertain about a checklist item.&lt;/li>
&lt;li>Read the Transparency Report along with the manuscript.&lt;/li>
&lt;/ul>
&lt;h3 id="optional-steps">Optional steps&lt;/h3>
&lt;ul>
&lt;li>Explain each item why it is important for transparency.&lt;/li>
&lt;li>In the classroom, ask the students to evaluate some (weakly and strongly transparent) published research papers. This can help them get familiar with the checklist and realize the importance of transparent reporting.&lt;/li>
&lt;/ul>
&lt;h2 id="how-to-evaluate-the-transparency-report">How to evaluate the Transparency Report&lt;/h2>
&lt;ul>
&lt;li>In the requirements, indicate which items should have a “yes” response. Should you want to make it easier for the students, you can require only the Short (12-item) Checklist:
&lt;a href="http://www.shinyapps.org/apps/ShortTransparencyChecklist/" target="_blank" rel="noopener">http://www.shinyapps.org/apps/ShortTransparencyChecklist/&lt;/a>&lt;/li>
&lt;li>When possible, check whether the manuscript is in line with the checklist answers.&lt;/li>
&lt;/ul>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>The following paper introduces the Transparency Checklist and describes how an initial set of items was iteratively evaluated by 45 journal editors, as well as 18 open-science advocates until a consensus was reached about the content and form of the checklist.&lt;/p>
&lt;p>Aczel, B., Szaszi, B., Sarafoglou, A. et al. A consensus-based transparency checklist. Nat Hum Behav 4, 4–6 (2020).
&lt;a href="https://www.nature.com/articles/s41562-019-0772-6" target="_blank" rel="noopener">https://www.nature.com/articles/s41562-019-0772-6&lt;/a>&lt;/p></description></item><item><title>Addressing the issue of representation in an undergraduate psych class</title><link>https://forrt.org/educators-corner/001-representation-heatherurry/</link><pubDate>Sat, 03 Oct 2020 10:44:40 -0400</pubDate><guid>https://forrt.org/educators-corner/001-representation-heatherurry/</guid><description>&lt;p>I want to tell y’all about one of my most meaningful teaching experiences. Pull up a chair.&lt;/p>
&lt;p>I’ve been teaching experimental psychology since 2006. It’s the flagship research methods course for undergraduate psychology majors at my institution. We now enroll 120 students each semester and, with the amazing help of 5 TAs, we offer lectures twice per week and a 2.5-hour lab once per week.&lt;/p>
&lt;p>As many of you know, the shit hit the fan when it comes to psychology research during my time teaching this class. I felt pretty dizzy for a while during and after 2011, the year that marks scales falling from my eyes.&lt;/p>
&lt;p>I didn’t really make many substantial changes to my course right away. I needed to feel like I was on firmer ground first. (I expressed that sentiment
&lt;a href="https://twitter.com/HeatherUrry/status/968638314608721921?s=20" target="_blank" rel="noopener">in this tweet thread below.&lt;/a>)&lt;/p>
&lt;p>But then, I came to realize that if I didn’t make changes to my teaching in addition to changes to my research, I was complicit. So, I got to work. Standing on the shoulders of the smart people who brought issues to light and modeled pathways to improvement, I shifted my content.&lt;/p>
&lt;p>Building on traditional topics like internal, external, &amp;amp; construct validity, reliability, measurement, hypothesis testing, etc., I started teaching about transparency, openness, questionable research practices, and effect sizes.&lt;/p>
&lt;p>We started to do IRB-approved, preregistered replication research some of which has seen or will see the light of day in published form (
&lt;a href="https://twitter.com/HeatherUrry/status/1289013799828090880?s=20" target="_blank" rel="noopener">like the example in this tweet).&lt;/a>&lt;/p>
&lt;p>We also started discussing efforts like the ManyLabs studies, the Psychological Science Accelerator (
&lt;a href="http://twitter.com/@PsySciAcc" target="_blank" rel="noopener">@PsySciAcc&lt;/a>), &amp;amp; the Collaborative Replications and Education Project (
&lt;a href="https://twitter.com/CREP_psych" target="_blank" rel="noopener">@CREP_psych&lt;/a>).&lt;/p>
&lt;p>This has all reinvigorated my love of teaching in general and this class specifically. I honestly feel like I’m fulfilling a real need. We need people in our society to have the tools to consume research responsibly, whether they go on to produce research themselves or not.&lt;/p>
&lt;p>But then 2020 happened. After centuries of oppression of Black, Indigenous, People of Color (BIPOC) in the United States, and seeing the disproportionate impact that the coronavirus is having on BIPOC folks, it finally clicked.&lt;/p>
&lt;p>My students need more from me than validity and reliability and transparency and openness. They need to feel they belong. All of them. Every one of them needs to see themselves in psychological science if that’s how they want to spend their time.&lt;/p>
&lt;p>So, this semester I introduced a single class session focused on the importance of representation in science. I borrowed ideas from Jessica Remedios (
&lt;a href="https://twitter.com/jdremedios/status/1303700486277812226?s=20" target="_blank" rel="noopener">see her terrific Twitter thread, which ends with her slides&lt;/a>).&lt;/p>
&lt;p>I had them read this work about
&lt;a href="https://www.pnas.org/content/117/17/9284" target="_blank" rel="noopener">the diversity-innovation paradox by Hofstra and colleagues&lt;/a>.&lt;/p>
&lt;p>I also invited them to watch the
&lt;a href="https://www.pictureascientist.com/" target="_blank" rel="noopener">Picture a Scientist film&lt;/a> and/or listen to the Everything Hertz podcast (
&lt;a href="https://twitter.com/hertzpodcast" target="_blank" rel="noopener">@hertzpodcast&lt;/a>) about Diversity in science
&lt;a href="https://everythinghertz.com/114" target="_blank" rel="noopener">with Jess Wade&lt;/a>.&lt;/p>
&lt;p>I talked about psychology’s positivist tradition of believing there’s some sort of objective reality that we can discover if we cleave to principles like empiricism, transparency, &amp;amp; falsifiability and how that position is marred by biases (e.g., confirmation bias, availability).&lt;/p>
&lt;p>It’s also marred by the fact that scientists are humans with standpoints that affect the questions they ask. And that power structures dominated by men and white people guide what we think is “normal” science. Such ideas aren’t commonly discussed in quantitative research circles.&lt;/p>
&lt;p>I showed them clips from
&lt;a href="https://www.pictureascientist.com/" target="_blank" rel="noopener">Picture a Scientist&lt;/a> so they could appreciate what it’s like to be a woman in science, and the progress that’s been made to remediate gender bias (e.g.,
&lt;a href="http://web.mit.edu/fnl/women/women.html" target="_blank" rel="noopener">the MIT report from 1999&lt;/a>).&lt;/p>
&lt;p>&lt;img src="iceberg.png" alt="">&lt;/p>
&lt;p>We also talked about the idea that some seem to have been left out, women of color, in particular, but also disabled, LGBTQ, first generation, indigenous people, and all their intersections.&lt;/p>
&lt;p>We talked about the loss to science, especially when innovative ideas put forward by women, people of color, and women of color are devalued (Hofstra et al., 2020).&lt;/p>
&lt;p>I showed them powerful clips of one woman of color’s experience as a scientist, professor of chemistry, Raychelle Burks (
&lt;a href="https://twitter.com/DrRubidium" target="_blank" rel="noopener">@DrRubidium&lt;/a>). Dr. Burks captured so perfectly the importance of representation.&lt;/p>
&lt;p>&lt;img src="her1.png" alt=""> &lt;img src="her2.png" alt="">&lt;/p>
&lt;p>I talked about how these problems are not limited to male-dominated sciences but that these issues pervade psychological science too.&lt;/p>
&lt;p>I showed them data from APA demonstrating the move from roughly 78% undergrad psychology majors being female to less than 50% of full professors being female. Lots of factors at play, including gender bias.&lt;/p>
&lt;p>I shared with them an email that a female colleague of color received recently that illustrated the gendered racism she faces in our field. It referenced the hardships faced by white men. (Sorry, what now?)&lt;/p>
&lt;p>I talked about my own standpoint as an educated white woman, a full professor with lots of mentorship from family members and powerful colleagues through the years. I had a lot of help getting where I am in part because of intersecting identities tied to systems of power.&lt;/p>
&lt;p>I expressed my hope that they’ll think about their own intersecting identities and if science is something they love and psychology specifically they should go for it and make room for everybody’s voices.&lt;/p>
&lt;p>I’d never talked about these ideas in my class before this week. I have also never received so much positive feedback from students. They felt seen. I don’t think I’d ever made them feel seen before, not quite like that. I feel good about that.&lt;/p>
&lt;p>I also feel sad. Students feel these things so hard, especially those we’ve marginalized in so many ways. I’ve been in undergrad classrooms for 15 years. I’ve worked with literally hundreds of students. So many missed opportunities.&lt;/p>
&lt;p>I can’t change that. But I can keep it up in future semesters. Urry is ON.&lt;/p>
&lt;p>Meanwhile,
&lt;a href="https://osf.io/597ut/" target="_blank" rel="noopener">here are some of my slides minus film clips and the email&lt;/a>. Maybe they’ll help you or someone you know address representation as a foundational idea of science at one of the earliest career stages.&lt;/p>
&lt;hr>
&lt;br>
&lt;p>&lt;em>Editor&amp;rsquo;s note: The present text is an adapted version of widely shared
&lt;a href="https://twitter.com/HeatherUrry/status/1312104732308115457?s=20" target="_blank" rel="noopener">Twitter thread&lt;/a> which resonated with so many of us. We thought it is of general interest and deserved to be immortalized, and hence we approached Heather to adapt the thread to post it here. Importantly, in addition to writing extremely current and relevant threads, Heather has also inspired the creation of FORRT. Indeed, FORRT was initiated at the 2018 meeting of the
&lt;a href="https://improvingpsych.org/" target="_blank" rel="noopener">Society for the Improvement of Psychological Science (SIPS)&lt;/a> in Heather&amp;rsquo;s
&lt;a href="https://osf.io/x7d45/" target="_blank" rel="noopener">“Teaching replicable and reproducible science”&lt;/a> hackathon with Kristen Lane.&lt;/em>&lt;/p></description></item></channel></rss>